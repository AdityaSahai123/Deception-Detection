{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11392397,"sourceType":"datasetVersion","datasetId":7134680},{"sourceId":11377350,"sourceType":"datasetVersion","datasetId":7123186}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install llm2vec torch-geometric jsonlines","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport jsonlines\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom torch_geometric.nn import GATConv\nimport torch.nn.functional as F\n\nfrom llm2vec import LLM2Vec\nfrom torch_geometric.data import Data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load Model","metadata":{}},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Set paths for models and data\nmodel_path = \"/kaggle/input/nlp-deception/best_model.pth\"\nfile_path = \"/kaggle/input/nlp-deception/val.jsonl\"\n\nEMBEDDER_PATH = \"McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp\"\nPEFT_PATH = \"McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp-supervised\"\n\n# Set inference parameters\nthreshold = 0.5\nhidden_dim = 512","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the LLM2Vec model for generating embeddings\nllm2vec_model = LLM2Vec.from_pretrained(\n    EMBEDDER_PATH,\n    peft_model_name_or_path=PEFT_PATH,\n    device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    torch_dtype=torch.bfloat16,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the trained GNN model\ndef load_model(model_path, input_dim, hidden_dim):\n    try:\n        model = GATDeceptionClassifier(input_dim, hidden_dim).to(device)\n        model.load_state_dict(torch.load(model_path, map_location=device))\n        model.eval()\n        print(f\"Model loaded successfully from {model_path}\")\n        return model\n    except Exception as e:\n        print(f\"Error loading model: {e}\")\n        return None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset\ndef load_flattened_dataset(file_path):\n    data = []\n    with jsonlines.open(file_path) as reader:\n        for game in reader:\n            for i in range(len(game[\"messages\"])):\n                if game[\"sender_labels\"][i] == \"NOANNOTATION\":\n                    continue\n                data.append({\n                    \"message\": game[\"messages\"][i],\n                    \"sender_label\": int(game[\"sender_labels\"][i] == False) if game[\"sender_labels\"][i] != \"NOANNOTATION\" else None,\n                    \"receiver_label\": game[\"receiver_labels\"][i],\n                    \"speaker\": game[\"speakers\"][i],\n                    \"receiver\": game[\"receivers\"][i],\n                    \"abs_msg_idx\": game[\"absolute_message_index\"][i],\n                    \"rel_msg_idx\": game[\"relative_message_index\"][i],\n                    \"season\": game[\"seasons\"][i],\n                    \"year\": game[\"years\"][i],\n                    \"score\": game[\"game_score\"][i],\n                    \"score_delta\": float(game[\"game_score_delta\"][i]),\n                    \"game_id\": game[\"game_id\"],\n                    \"players\": game[\"players\"],\n                    \"message_length\": len(game[\"messages\"][i])\n                })\n    return pd.DataFrame(data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Text cleaning function\ndef soft_clean(text):\n    text = text.replace('\\n', ' ').strip()\n    return text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset\ndf = load_flattened_dataset(file_path)\nprint(f\"Loaded {len(df)} messages from {file_path}\")\nprint(df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create Embeddings","metadata":{}},{"cell_type":"code","source":"def embed_messages(df, model):\n    embeddings = []\n    for msg in tqdm(df[\"message\"], desc=\"Embedding messages\"):\n        emb = model.encode(msg)[0]  # Returns 1 vector\n        embeddings.append(torch.tensor(emb, dtype=torch.float32))\n    return torch.stack(embeddings)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_embeddings(file: str, output_path: str):\n    df = load_flattened_dataset(file)\n    x = embed_messages(df, llm2vec_model)\n    y = torch.tensor(df[\"sender_label\"].values, dtype=torch.float32)\n    torch.save((x, y), output_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"create_embeddings(file_path, '/kaggle/working/train_embeddings.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Graph from data","metadata":{}},{"cell_type":"code","source":"# Extract metadata features\ndef extract_metadata(df):\n    scaler = MinMaxScaler()\n    metadata_features = df[[\"abs_msg_idx\", \"rel_msg_idx\", \"year\", \"score\", \n                           \"score_delta\", \"message_length\"]].values\n    metadata_features = scaler.fit_transform(metadata_features)\n    return metadata_features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract player features\ndef player_features(df):\n    players = np.unique(df[[\"speaker\", \"receiver\"]].values.flatten())\n    player_node_features = np.eye(len(players))\n    return player_node_features, players","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pad player features to match message feature dimensions\ndef pad_player_features(player_features, padding_dim):\n    return np.pad(player_features, ((0, 0), (0, padding_dim)), 'constant')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build edge list for the graph\ndef build_bidirectional_edge_list(df, players):\n    from sklearn.preprocessing import LabelEncoder\n    \n    edges = []\n    num_messages = len(df)\n    player_encoder = LabelEncoder().fit(players)\n    player_offset = num_messages  # player nodes start after message nodes\n    \n    for i in range(num_messages - 1):\n        # Temporal edges: message i <-> message i+1\n        edges.append((i, i + 1))\n        edges.append((i + 1, i))\n\n    for i, row in df.iterrows():\n        speaker_id = player_offset + player_encoder.transform([row[\"speaker\"]])[0]\n        receiver_id = player_offset + player_encoder.transform([row[\"receiver\"]])[0]\n\n        # Speaker <-> message\n        edges.append((speaker_id, i))   # player → message\n        edges.append((i, speaker_id))   # message → player\n\n        # Receiver <-> message\n        edges.append((receiver_id, i))\n        edges.append((i, receiver_id))\n\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    return edge_index","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class GATDeceptionClassifier(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim=512):\n        super().__init__()\n        self.gat1 = GATConv(input_dim, hidden_dim, heads=4, dropout=0.3)\n        self.gat2 = GATConv(hidden_dim * 4, hidden_dim, heads=2, dropout=0.3)\n        self.out = torch.nn.Linear(hidden_dim * 2, 1)\n        self.out_dim = hidden_dim * 2\n\n    def forward(self, x, edge_index):\n        x = F.elu(self.gat1(x, edge_index))\n        x = F.elu(self.gat2(x, edge_index))\n        return self.out(x).squeeze()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract metadata features\nmetadata_features = extract_metadata(df)\n# Create player node features\nplayer_node_features, players = player_features(df)\n# Combine embeddings with metadata\nmessage_node_features = np.hstack([embeddings.cpu().numpy(), metadata_features])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate padding for player features\nmessage_dim = message_node_features.shape[1]\nplayer_dim = player_node_features.shape[1]\npadding_dim = message_dim - player_dim","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pad player features\nplayer_node_features_padded = pad_player_features(player_node_features, padding_dim","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine message and player features\nx = torch.tensor(np.vstack([message_node_features, player_node_features_padded]), \n                 dtype=torch.float32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build edges\nedge_index = build_bidirectional_edge_list(df, players)\n# Create the graph\ngraph_data = Data(x=x, edge_index=edge_index)\ngraph_data = graph_data.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# Load the GNN model\ninput_dim = x.shape[1]\nmodel = load_model(MODEL_PATH, input_dim, hidden_dim)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run inference\ndef predict(model, data, threshold=0.5):\n    model.eval()\n    with torch.no_grad():\n        logits = model(data.x, data.edge_index)\n        probs = torch.sigmoid(logits)\n        # Only take predictions for message nodes (not player nodes)\n        message_probs = probs[:len(df)].cpu().numpy()\n        predictions = (message_probs > threshold).astype(int)\n    return message_probs, predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get predictions\nprobabilities, predictions = predict(model, graph_data, THRESHOLD)\n\n# Add predictions to the dataframe\ndf['deception_probability'] = probabilities\ndf['predicted_deceptive'] = predictions\n\nprint(\"Inference completed\")\nprint(f\"Found {predictions.sum()} potentially deceptive messages out of {len(df)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Analyze Results","metadata":{}},{"cell_type":"code","source":"# Calculate metrics if ground truth is available\nif 'sender_label' in df.columns and not df['sender_label'].isna().all():\n    valid_idx = ~df['sender_label'].isna()\n    y_true = df.loc[valid_idx, 'sender_label'].astype(int).values\n    y_pred = df.loc[valid_idx, 'predicted_deceptive'].values\n    \n    print(\"\\nClassification Report:\")\n    print(classification_report(y_true, y_pred))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=['Truthful', 'Deceptive'], \n                yticklabels=['Truthful', 'Deceptive'])\n    plt.title('Confusion Matrix')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.tight_layout()\n    plt.savefig(f\"{output_dir}/confusion_matrix.png\")\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Distribution of deception probabilities\nplt.figure(figsize=(10, 6))\nsns.histplot(df['deception_probability'], bins=50, kde=True)\nplt.axvline(x=THRESHOLD, color='red', linestyle='--', label=f'Threshold ({THRESHOLD})')\nplt.title('Distribution of Deception Probabilities')\nplt.xlabel('Deception Probability')\nplt.ylabel('Frequency')\nplt.legend()\nplt.savefig(f\"{output_dir}/probability_distribution.png\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Deception by player\nplt.figure(figsize=(12, 6))\nplayer_deception = df.groupby('speaker')['deception_probability'].mean().sort_values(ascending=False)\nsns.barplot(x=player_deception.index, y=player_deception.values)\nplt.title('Average Deception Probability by Player')\nplt.xlabel('Player')\nplt.ylabel('Avg. Deception Probability')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.savefig(f\"{output_dir}/player_deception.png\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Message length vs deception probability\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='message_length', y='deception_probability', data=df, alpha=0.6)\nplt.title('Message Length vs. Deception Probability')\nplt.xlabel('Message Length')\nplt.ylabel('Deception Probability')\nplt.savefig(f\"{output_dir}/length_vs_deception.png\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Export predictions to CSV\noutput_path = f\"{output_dir}/deception_predictions.csv\"\ndf.to_csv(output_path, index=False)\nprint(f\"Predictions saved to {output_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Most highly deceptive messages\nprint(\"Top 10 most likely deceptive messages:\")\ntop_deceptive = df.sort_values('deception_probability', ascending=False).head(10)\nfor i, row in top_deceptive.iterrows():\n    print(f\"Player: {row['speaker']} | Prob: {row['deception_probability']:.4f} | Message: {row['message'][:100]}...\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}