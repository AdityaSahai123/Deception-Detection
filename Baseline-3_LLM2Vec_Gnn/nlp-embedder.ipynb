{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11377350,"sourceType":"datasetVersion","datasetId":7123186}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install llm2vec","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install flash-attn --no-build-isolation","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install jsonlines","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom tqdm import tqdm\nfrom llm2vec import LLM2Vec\nimport jsonlines","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"llm2vec_model = LLM2Vec.from_pretrained(\n    \"McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp\",\n    peft_model_name_or_path=\"McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp-supervised\",\n    device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    torch_dtype=torch.bfloat16,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create Embeddings","metadata":{}},{"cell_type":"code","source":"# Message Cleaning\ndef soft_clean(text):\n    text = text.replace('\\n', ' ').strip()\n    return text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset\ndef load_flattened_dataset(file_path):\n    data = []\n    with jsonlines.open(file_path) as reader:\n        for game in reader:\n            for i in range(len(game[\"messages\"])):\n                if game[\"sender_labels\"][i] == \"NOANNOTATION\":\n                    continue\n                data.append({\n                    \"message\": game[\"messages\"][i],\n                    \"sender_label\": int(game[\"sender_labels\"][i] == False),\n                    \"receiver_label\": game[\"receiver_labels\"][i],\n                    \"speaker\": game[\"speakers\"][i],\n                    \"receiver\": game[\"receivers\"][i],\n                    \"abs_msg_idx\": game[\"absolute_message_index\"][i],\n                    \"rel_msg_idx\": game[\"relative_message_index\"][i],\n                    \"season\": game[\"seasons\"][i],\n                    \"year\": game[\"years\"][i],\n                    \"score\": game[\"game_score\"][i],\n                    \"score_delta\": float(game[\"game_score_delta\"][i]),\n                    \"game_id\": game[\"game_id\"],\n                    \"players\": game[\"players\"],\n                    \"message_length\": len(game[\"messages\"][i])\n                })\n    return pd.DataFrame(data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def embed_messages(df, model):\n    embeddings = []\n    for msg in tqdm(df[\"message\"], desc=\"Embedding messages\"):\n        emb = model.encode(msg)[0]  # Returns 1 vector\n        embeddings.append(torch.tensor(emb, dtype=torch.float32))\n    return torch.stack(embeddings)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_embeddings(file: str, output_path: str):\n    df = load_flattened_dataset(file)\n    x = embed_messages(df, llm2vec_model)\n    y = torch.tensor(df[\"sender_label\"].values, dtype=torch.float32)\n    torch.save((x, y), output_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_file = '/kaggle/input/nlp-deception/test.jsonl'\ntrain_file = '/kaggle/input/nlp-deception/train.jsonl'\nval_file = '/kaggle/input/nlp-deception/validation.jsonl'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"create_embeddings(train_file, '/kaggle/working/train_embeddings.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"create_embeddings(val_file, '/kaggle/working/val_embeddings.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"create_embeddings(test_file, '/kaggle/working/test_embeddings.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"inf_file = '/kaggle/input/nlp-deception/validation.jsonl'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"create_embeddings(inf_file, '/kaggle/working/inf_embeddings.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}