{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11377350,"sourceType":"datasetVersion","datasetId":7123186},{"sourceId":11392397,"sourceType":"datasetVersion","datasetId":7134680}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install torch-geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:38:30.176952Z","iopub.execute_input":"2025-04-15T16:38:30.177184Z","iopub.status.idle":"2025-04-15T16:38:35.522198Z","shell.execute_reply.started":"2025-04-15T16:38:30.177162Z","shell.execute_reply":"2025-04-15T16:38:35.521269Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Collecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.16)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.19.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install jsonlines","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:38:49.052114Z","iopub.execute_input":"2025-04-15T16:38:49.052378Z","iopub.status.idle":"2025-04-15T16:38:52.287275Z","shell.execute_reply.started":"2025-04-15T16:38:49.052356Z","shell.execute_reply":"2025-04-15T16:38:52.286398Z"}},"outputs":[{"name":"stdout","text":"Collecting jsonlines\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines) (25.3.0)\nDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nInstalling collected packages: jsonlines\nSuccessfully installed jsonlines-4.0.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nimport copy\nfrom sklearn.metrics import classification_report, f1_score, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GATConv\nfrom torch_geometric.data import Data\nimport jsonlines\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:38:54.335599Z","iopub.execute_input":"2025-04-15T16:38:54.335874Z","iopub.status.idle":"2025-04-15T16:39:03.789044Z","shell.execute_reply.started":"2025-04-15T16:38:54.335848Z","shell.execute_reply":"2025-04-15T16:39:03.788312Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"scaler = MinMaxScaler()\nhidden_dim = 512\nthreshold = 0.5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:05.455212Z","iopub.execute_input":"2025-04-15T16:39:05.455668Z","iopub.status.idle":"2025-04-15T16:39:05.461720Z","shell.execute_reply.started":"2025-04-15T16:39:05.455643Z","shell.execute_reply":"2025-04-15T16:39:05.461050Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Files\ntrain_file = '/kaggle/input/nlp-deception/train.jsonl'\nval_file = '/kaggle/input/nlp-deception/validation.jsonl'\ntest_file = '/kaggle/input/nlp-deception/test.jsonl'\n\ntrain_embed_path = \"/kaggle/input/nlp-deception-encoded/train_embeddings.pt\"\nval_embed_path = \"/kaggle/input/nlp-deception-encoded/val_embeddings.pt\"\ntest_embed_path = \"/kaggle/input/nlp-deception-encoded/test_embeddings.pt\"","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:05.764338Z","iopub.execute_input":"2025-04-15T16:39:05.764993Z","iopub.status.idle":"2025-04-15T16:39:05.768655Z","shell.execute_reply.started":"2025-04-15T16:39:05.764966Z","shell.execute_reply":"2025-04-15T16:39:05.767903Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"# Load and clean the dataset\ndef load_flattened_dataset(file_path):\n    data = []\n    with jsonlines.open(file_path) as reader:\n        for game in reader:\n            for i in range(len(game[\"messages\"])):\n                if game[\"sender_labels\"][i] == \"NOANNOTATION\":\n                    continue\n                data.append({\n                    \"message\": game[\"messages\"][i],\n                    \"sender_label\": int(game[\"sender_labels\"][i] == False),\n                    \"receiver_label\": game[\"receiver_labels\"][i],\n                    \"speaker\": game[\"speakers\"][i],\n                    \"receiver\": game[\"receivers\"][i],\n                    \"abs_msg_idx\": game[\"absolute_message_index\"][i],\n                    \"rel_msg_idx\": game[\"relative_message_index\"][i],\n                    \"season\": game[\"seasons\"][i],\n                    \"year\": game[\"years\"][i],\n                    \"score\": game[\"game_score\"][i],\n                    \"score_delta\": float(game[\"game_score_delta\"][i]),\n                    \"game_id\": game[\"game_id\"],\n                    \"players\": game[\"players\"],\n                    \"message_length\": len(game[\"messages\"][i])\n                })\n    return pd.DataFrame(data)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:07.894802Z","iopub.execute_input":"2025-04-15T16:39:07.895503Z","iopub.status.idle":"2025-04-15T16:39:07.901322Z","shell.execute_reply.started":"2025-04-15T16:39:07.895480Z","shell.execute_reply":"2025-04-15T16:39:07.900437Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Embed messages using LLM2Vec\ndef extract_metadata(df):\n    metadata_features = df[[\"abs_msg_idx\", \"rel_msg_idx\", \"year\", \"score\", \n                             \"score_delta\", \"message_length\"]].values\n    metadata_features = scaler.fit_transform(metadata_features)\n    return metadata_features","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:09.125771Z","iopub.execute_input":"2025-04-15T16:39:09.126278Z","iopub.status.idle":"2025-04-15T16:39:09.129928Z","shell.execute_reply.started":"2025-04-15T16:39:09.126253Z","shell.execute_reply":"2025-04-15T16:39:09.129334Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Extract Player features\ndef player_features(df):\n    players = np.unique(df[[\"speaker\", \"receiver\"]].values.flatten())\n    player_node_features = np.eye(len(players))\n    return player_node_features","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:09.341182Z","iopub.execute_input":"2025-04-15T16:39:09.341769Z","iopub.status.idle":"2025-04-15T16:39:09.345593Z","shell.execute_reply.started":"2025-04-15T16:39:09.341741Z","shell.execute_reply":"2025-04-15T16:39:09.344813Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Pad with zeros\ndef pad_player_features(player_features, padding_dim):\n    return np.pad(player_features, ((0, 0), (0, padding_dim)), 'constant')","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:10.829244Z","iopub.execute_input":"2025-04-15T16:39:10.829512Z","iopub.status.idle":"2025-04-15T16:39:10.833680Z","shell.execute_reply.started":"2025-04-15T16:39:10.829492Z","shell.execute_reply":"2025-04-15T16:39:10.832697Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Load datasets\ndef load_datasets(train_file, val_file, test_file):\n    df_train = load_flattened_dataset(train_file)\n    df_val = load_flattened_dataset(val_file)\n    df_test = load_flattened_dataset(test_file)\n    return df_train, df_val, df_test","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:11.054341Z","iopub.execute_input":"2025-04-15T16:39:11.054608Z","iopub.status.idle":"2025-04-15T16:39:11.058607Z","shell.execute_reply.started":"2025-04-15T16:39:11.054588Z","shell.execute_reply":"2025-04-15T16:39:11.057945Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Load embeddings\ndef load_embeddings(train_path, val_path, test_path):\n    X_train, y_train = torch.load(train_path)\n    X_val, y_val = torch.load(val_path)\n    X_test, y_test = torch.load(test_path)\n    return (X_train, y_train), (X_val, y_val), (X_test, y_test)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:11.234114Z","iopub.execute_input":"2025-04-15T16:39:11.234596Z","iopub.status.idle":"2025-04-15T16:39:11.238530Z","shell.execute_reply.started":"2025-04-15T16:39:11.234575Z","shell.execute_reply":"2025-04-15T16:39:11.237777Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Build Graph","metadata":{}},{"cell_type":"code","source":"# Build edge list for the graph\ndef build_bidirectional_edge_list(df, player_encoder):\n    edges = []\n    num_messages = len(df)\n    player_offset = num_messages  # player nodes start after message nodes\n\n    for i in range(num_messages - 1):\n        # Temporal edges: message i <-> message i+1\n        edges.append((i, i + 1))\n        edges.append((i + 1, i))\n\n    for i, row in df.iterrows():\n        speaker_id = player_offset + player_encoder.transform([row[\"speaker\"]])[0]\n        receiver_id = player_offset + player_encoder.transform([row[\"receiver\"]])[0]\n\n        # Speaker <-> message\n        edges.append((speaker_id, i))   # player → message\n        edges.append((i, speaker_id))   # message → player\n\n        # Receiver <-> message\n        edges.append((receiver_id, i))\n        edges.append((i, receiver_id))\n\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    return edge_index","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:12.872334Z","iopub.execute_input":"2025-04-15T16:39:12.872614Z","iopub.status.idle":"2025-04-15T16:39:12.878211Z","shell.execute_reply.started":"2025-04-15T16:39:12.872595Z","shell.execute_reply":"2025-04-15T16:39:12.877470Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Prepare graph data from dataframes and embeddings.\ndef prepare_graph_data(df_train, df_val, df_test, embeddings):\n    (X_train, y_train), (X_val, y_val), (X_test, y_test) = embeddings\n    \n    # Extract metadata features\n    train_metadata_features = extract_metadata(df_train)\n    val_metadata_features = extract_metadata(df_val)\n    test_metadata_features = extract_metadata(df_test)\n\n    # Final message node features\n    train_message_node_features = np.hstack([X_train, train_metadata_features])\n    test_message_node_features = np.hstack([X_test, test_metadata_features])\n    val_message_node_features = np.hstack([X_val, val_metadata_features])\n\n    # Player node features\n    train_player_node_features = player_features(df_train)\n    val_player_node_features = player_features(df_val)\n    test_player_node_features = player_features(df_test)\n\n    message_dim = train_message_node_features.shape[1]\n    player_dim = train_player_node_features.shape[1]\n    padding_dim = message_dim - player_dim\n\n    # Pad player features\n    train_player_node_features_padded = pad_player_features(train_player_node_features, padding_dim)\n    val_player_node_features_padded = pad_player_features(val_player_node_features, padding_dim)\n    test_player_node_features_padded = pad_player_features(test_player_node_features, padding_dim)\n\n    # Concatenate features\n    train_x = torch.tensor(np.vstack([train_message_node_features, train_player_node_features_padded]), \n                           dtype=torch.float32)\n    test_x = torch.tensor(np.vstack([test_message_node_features, test_player_node_features_padded]), \n                          dtype=torch.float32)\n    val_x = torch.tensor(np.vstack([val_message_node_features, val_player_node_features_padded]), \n                         dtype=torch.float32)\n\n    # Create common player encoder\n    all_players = pd.concat([df_train[[\"speaker\", \"receiver\"]],\n                         df_val[[\"speaker\", \"receiver\"]],\n                         df_test[[\"speaker\", \"receiver\"]]]).values.flatten()\n    player_encoder = LabelEncoder().fit(all_players)\n\n    # Generate edges\n    train_edge_index = build_bidirectional_edge_list(df_train, player_encoder)\n    val_edge_index = build_bidirectional_edge_list(df_val, player_encoder)\n    test_edge_index = build_bidirectional_edge_list(df_test, player_encoder)\n\n    # Create graph data objects\n    train_data = Data(x=train_x, edge_index=train_edge_index, y=y_train).to(device)\n    val_data = Data(x=val_x, edge_index=val_edge_index, y=y_val).to(device)\n    test_data = Data(x=test_x, edge_index=test_edge_index, y=y_test).to(device)\n    \n    return train_data, val_data, test_data, train_x.shape[1]","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:29.983723Z","iopub.execute_input":"2025-04-15T16:39:29.984212Z","iopub.status.idle":"2025-04-15T16:39:29.991991Z","shell.execute_reply.started":"2025-04-15T16:39:29.984187Z","shell.execute_reply":"2025-04-15T16:39:29.991313Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"# Define the GAT model\nclass GATDeceptionClassifier(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim=256):\n        super().__init__()\n        self.gat1 = GATConv(input_dim, hidden_dim, heads=4, dropout=0.3)\n        self.gat2 = GATConv(hidden_dim * 4, hidden_dim, heads=2, dropout=0.3)\n        self.out = torch.nn.Linear(hidden_dim * 2, 1)\n        self.out_dim = hidden_dim * 2\n\n    def forward(self, x, edge_index):\n        x = F.elu(self.gat1(x, edge_index))\n        x = F.elu(self.gat2(x, edge_index))\n        return self.out(x).squeeze()  # logits","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:35.187726Z","iopub.execute_input":"2025-04-15T16:39:35.188532Z","iopub.status.idle":"2025-04-15T16:39:35.194992Z","shell.execute_reply.started":"2025-04-15T16:39:35.188500Z","shell.execute_reply":"2025-04-15T16:39:35.194179Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def BCE_loss(data):\n    labels = data.y.cpu().numpy()\n    class_weights = compute_class_weight(\"balanced\", classes=[0, 1], y=labels)\n    pos_weight = torch.tensor([class_weights[1] / class_weights[0]], dtype=torch.float32).to(device)\n\n    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n    return criterion","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:36.894665Z","iopub.execute_input":"2025-04-15T16:39:36.895390Z","iopub.status.idle":"2025-04-15T16:39:36.899649Z","shell.execute_reply.started":"2025-04-15T16:39:36.895367Z","shell.execute_reply":"2025-04-15T16:39:36.898838Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# Train the model\ndef train_model(train_data, test_data, input_dim, hidden_dim=512, \n                lr=2e-5, num_epochs=500, checkpoint_dir=\"checkpoints\"):\n    # Create directories for checkpoints\n    if not os.path.isdir(checkpoint_dir):\n        os.mkdir(checkpoint_dir)\n        \n    # Initialize model and optimizer\n    model = GATDeceptionClassifier(input_dim, hidden_dim).to(device)\n    criterion = BCE_loss(train_data)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    \n    # Training tracking variables\n    best_score = 0\n    best_model = GATDeceptionClassifier(input_dim, hidden_dim).to(device)\n    losses = []\n    macro_f1s = []\n    \n    # Training loop\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n\n        edge_index = train_data.edge_index.clone()\n        \n        # Forward pass with fresh tensors\n        logits = model(train_data.x, edge_index)\n        train_logits = logits[:len(train_data.y)]\n        loss = criterion(train_logits, train_data.y)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n\n        # Evaluation\n        model.eval()\n        with torch.no_grad():\n            eval_logits = model(test_data.x, test_data.edge_index)\n            eval_output = eval_logits[:len(test_data.y)].clone()\n            preds = torch.sigmoid(eval_output).cpu().numpy()\n            pred_labels = (preds > 0.5).astype(int)\n\n        print(f\"\\nEpoch {epoch} | Loss: {loss.item():.4f}\")\n        score_f1 = f1_score(test_data.y.cpu().numpy(), pred_labels, average='macro')\n        print(\"Test Report:\\n\", classification_report(test_data.y.cpu().numpy(), pred_labels, \n                                                     digits=4, zero_division=0))\n        print(\"Test Macro F1:\", score_f1)\n        \n        losses.append(loss.item())\n        macro_f1s.append(score_f1)\n        \n        # Save best model\n        if score_f1 > best_score:\n            best_score = score_f1\n            print(\"New Best:\", best_score, \"epoch:\", epoch)\n            best_model.load_state_dict(copy.deepcopy(model.state_dict()))\n            torch.save(model.state_dict(), f\"best_model.pth\")\n            \n        # Periodic checkpoints\n        if epoch % 10 == 0:\n            torch.save(model.state_dict(), f\"{checkpoint_dir}/model_epoch_{epoch}.pth\")\n    \n    print(\"Best Score:\", best_score)\n    \n    return best_model, losses, macro_f1s","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:39.576662Z","iopub.execute_input":"2025-04-15T16:39:39.577324Z","iopub.status.idle":"2025-04-15T16:39:39.585525Z","shell.execute_reply.started":"2025-04-15T16:39:39.577303Z","shell.execute_reply":"2025-04-15T16:39:39.584885Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Evaluate\ndef evaluate(model, data, t=0.5, output_dict=False):\n    model.eval()\n    with torch.no_grad():\n        logits = model(data.x, data.edge_index)[:len(data.y)]\n        preds = torch.sigmoid(logits).cpu().numpy()\n        pred_labels = (preds > t).astype(int)\n        cm = confusion_matrix(data.y.cpu().numpy(), pred_labels)\n        return (classification_report(data.y.cpu().numpy(), pred_labels, digits=4, \n                                     output_dict=output_dict, zero_division=0),\n               f1_score(data.y.cpu().numpy(), pred_labels, average='macro'), cm)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:43:30.668690Z","iopub.execute_input":"2025-04-15T16:43:30.669425Z","iopub.status.idle":"2025-04-15T16:43:30.674262Z","shell.execute_reply.started":"2025-04-15T16:43:30.669400Z","shell.execute_reply":"2025-04-15T16:43:30.673452Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Tune classification threshold and plot results\ndef tune_threshold(model, test_data):\n    thresholds = [0.1, 0.2, 0.3, 0.4, 0.45, 0.5, 0.55, 0.6, 0.7]\n    metrics = {\"threshold\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n\n    for t in thresholds:\n        rep, f1, _ = evaluate(model, test_data, t, True)\n        prec = rep['macro avg']['precision'] \n        rec = rep['macro avg']['recall']   \n        metrics[\"threshold\"].append(t)\n        metrics[\"f1\"].append(f1)\n        metrics[\"precision\"].append(prec)\n        metrics[\"recall\"].append(rec)\n    \n    # Plot metrics vs threshold\n    plt.figure(figsize=(8, 5))\n    plt.plot(metrics[\"threshold\"], metrics[\"f1\"], label=\"F1\", marker=\"o\")\n    plt.plot(metrics[\"threshold\"], metrics[\"precision\"], label=\"Precision\", marker=\"s\")\n    plt.plot(metrics[\"threshold\"], metrics[\"recall\"], label=\"Recall\", marker=\"^\")\n    plt.xlabel(\"Threshold\")\n    plt.ylabel(\"Score\")\n    plt.title(\"Threshold Tuning on Test Set\")\n    plt.grid(True)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n    \n    return metrics","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:41.131728Z","iopub.execute_input":"2025-04-15T16:39:41.132031Z","iopub.status.idle":"2025-04-15T16:39:41.138082Z","shell.execute_reply.started":"2025-04-15T16:39:41.131986Z","shell.execute_reply":"2025-04-15T16:39:41.137417Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Plot training loss and F1 score history.\ndef plot_training_history(losses, macro_f1s):\n    plt.figure(figsize=(10, 5))\n    plt.plot(losses, label='Loss')\n    plt.plot(macro_f1s, label='Macro F1')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Value\")\n    plt.title(\"Training Loss and Macro F1 Over Epochs\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:43.280369Z","iopub.execute_input":"2025-04-15T16:39:43.280646Z","iopub.status.idle":"2025-04-15T16:39:43.284924Z","shell.execute_reply.started":"2025-04-15T16:39:43.280626Z","shell.execute_reply":"2025-04-15T16:39:43.284108Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Start","metadata":{}},{"cell_type":"code","source":"# Load data\ndf_train, df_val, df_test = load_datasets(train_file, val_file, test_file)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:45.035113Z","iopub.execute_input":"2025-04-15T16:39:45.035609Z","iopub.status.idle":"2025-04-15T16:39:45.195542Z","shell.execute_reply.started":"2025-04-15T16:39:45.035589Z","shell.execute_reply":"2025-04-15T16:39:45.194981Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Load embeddings\nembeddings = load_embeddings(train_embed_path, val_embed_path, test_embed_path)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:47.142378Z","iopub.execute_input":"2025-04-15T16:39:47.142633Z","iopub.status.idle":"2025-04-15T16:39:48.297942Z","shell.execute_reply.started":"2025-04-15T16:39:47.142616Z","shell.execute_reply":"2025-04-15T16:39:48.297183Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1070986595.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  X_train, y_train = torch.load(train_path)\n/tmp/ipykernel_31/1070986595.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  X_val, y_val = torch.load(val_path)\n/tmp/ipykernel_31/1070986595.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  X_test, y_test = torch.load(test_path)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Prepare data\ntrain_data, val_data, test_data, input_dim = prepare_graph_data(\n    df_train, df_val, df_test, embeddings\n)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:52.180256Z","iopub.execute_input":"2025-04-15T16:39:52.180731Z","iopub.status.idle":"2025-04-15T16:39:54.634656Z","shell.execute_reply.started":"2025-04-15T16:39:52.180709Z","shell.execute_reply":"2025-04-15T16:39:54.634122Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"val_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:42:37.593300Z","iopub.execute_input":"2025-04-15T16:42:37.593552Z","iopub.status.idle":"2025-04-15T16:42:37.598787Z","shell.execute_reply.started":"2025-04-15T16:42:37.593536Z","shell.execute_reply":"2025-04-15T16:42:37.597924Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"Data(x=[1423, 2054], edge_index=[2, 8494], y=[1416])"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Train Model\nbest_model, losses, macro_f1s = train_model(\n    train_data, test_data, input_dim, hidden_dim=hidden_dim\n)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:39:55.837265Z","iopub.execute_input":"2025-04-15T16:39:55.837538Z","iopub.status.idle":"2025-04-15T16:41:09.118824Z","shell.execute_reply.started":"2025-04-15T16:39:55.837518Z","shell.execute_reply":"2025-04-15T16:41:09.118053Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1 | Loss: 1.3775\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.0000    0.0000    0.0000      2501\n         1.0     0.0876    1.0000    0.1610       240\n\n    accuracy                         0.0876      2741\n   macro avg     0.0438    0.5000    0.0805      2741\nweighted avg     0.0077    0.0876    0.0141      2741\n\nTest Macro F1: 0.08050989600805099\nNew Best: 0.08050989600805099 epoch: 1\n\nEpoch 2 | Loss: 1.3848\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.0000    0.0000    0.0000      2501\n         1.0     0.0876    1.0000    0.1610       240\n\n    accuracy                         0.0876      2741\n   macro avg     0.0438    0.5000    0.0805      2741\nweighted avg     0.0077    0.0876    0.0141      2741\n\nTest Macro F1: 0.08050989600805099\n\nEpoch 3 | Loss: 1.3635\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9167    0.1144    0.2033      2501\n         1.0     0.0881    0.8917    0.1604       240\n\n    accuracy                         0.1824      2741\n   macro avg     0.5024    0.5030    0.1819      2741\nweighted avg     0.8441    0.1824    0.1996      2741\n\nTest Macro F1: 0.18185065671518935\nNew Best: 0.18185065671518935 epoch: 3\n\nEpoch 4 | Loss: 1.3287\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9124    1.0000    0.9542      2501\n         1.0     0.0000    0.0000    0.0000       240\n\n    accuracy                         0.9124      2741\n   macro avg     0.4562    0.5000    0.4771      2741\nweighted avg     0.8325    0.9124    0.8707      2741\n\nTest Macro F1: 0.47710797405570393\nNew Best: 0.47710797405570393 epoch: 4\n\nEpoch 5 | Loss: 1.3377\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9124    1.0000    0.9542      2501\n         1.0     0.0000    0.0000    0.0000       240\n\n    accuracy                         0.9124      2741\n   macro avg     0.4562    0.5000    0.4771      2741\nweighted avg     0.8325    0.9124    0.8707      2741\n\nTest Macro F1: 0.47710797405570393\n\nEpoch 6 | Loss: 1.3442\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9124    1.0000    0.9542      2501\n         1.0     0.0000    0.0000    0.0000       240\n\n    accuracy                         0.9124      2741\n   macro avg     0.4562    0.5000    0.4771      2741\nweighted avg     0.8325    0.9124    0.8707      2741\n\nTest Macro F1: 0.47710797405570393\n\nEpoch 7 | Loss: 1.3419\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9124    1.0000    0.9542      2501\n         1.0     0.0000    0.0000    0.0000       240\n\n    accuracy                         0.9124      2741\n   macro avg     0.4562    0.5000    0.4771      2741\nweighted avg     0.8325    0.9124    0.8707      2741\n\nTest Macro F1: 0.47710797405570393\n\nEpoch 8 | Loss: 1.3267\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9245    0.3331    0.4897      2501\n         1.0     0.0935    0.7167    0.1654       240\n\n    accuracy                         0.3667      2741\n   macro avg     0.5090    0.5249    0.3275      2741\nweighted avg     0.8518    0.3667    0.4613      2741\n\nTest Macro F1: 0.32754827477049697\n\nEpoch 9 | Loss: 1.3235\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     1.0000    0.0012    0.0024      2501\n         1.0     0.0877    1.0000    0.1612       240\n\n    accuracy                         0.0887      2741\n   macro avg     0.5438    0.5006    0.0818      2741\nweighted avg     0.9201    0.0887    0.0163      2741\n\nTest Macro F1: 0.08178908373868432\n\nEpoch 10 | Loss: 1.3278\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.0000    0.0000    0.0000      2501\n         1.0     0.0876    1.0000    0.1610       240\n\n    accuracy                         0.0876      2741\n   macro avg     0.0438    0.5000    0.0805      2741\nweighted avg     0.0077    0.0876    0.0141      2741\n\nTest Macro F1: 0.08050989600805099\n\nEpoch 11 | Loss: 1.3340\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.0000    0.0000    0.0000      2501\n         1.0     0.0876    1.0000    0.1610       240\n\n    accuracy                         0.0876      2741\n   macro avg     0.0438    0.5000    0.0805      2741\nweighted avg     0.0077    0.0876    0.0141      2741\n\nTest Macro F1: 0.08050989600805099\n\nEpoch 12 | Loss: 1.3319\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9444    0.0204    0.0399      2501\n         1.0     0.0882    0.9875    0.1619       240\n\n    accuracy                         0.1051      2741\n   macro avg     0.5163    0.5039    0.1009      2741\nweighted avg     0.8695    0.1051    0.0506      2741\n\nTest Macro F1: 0.10093113779060867\n\nEpoch 13 | Loss: 1.3237\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9239    0.4706    0.6236      2501\n         1.0     0.0975    0.5958    0.1675       240\n\n    accuracy                         0.4816      2741\n   macro avg     0.5107    0.5332    0.3956      2741\nweighted avg     0.8515    0.4816    0.5836      2741\n\nTest Macro F1: 0.39556078011460405\n\nEpoch 14 | Loss: 1.3196\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9146    0.8996    0.9071      2501\n         1.0     0.1068    0.1250    0.1152       240\n\n    accuracy                         0.8318      2741\n   macro avg     0.5107    0.5123    0.5111      2741\nweighted avg     0.8439    0.8318    0.8377      2741\n\nTest Macro F1: 0.5111191671235251\nNew Best: 0.5111191671235251 epoch: 14\n\nEpoch 15 | Loss: 1.3229\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9126    0.9896    0.9495      2501\n         1.0     0.1034    0.0125    0.0223       240\n\n    accuracy                         0.9040      2741\n   macro avg     0.5080    0.5011    0.4859      2741\nweighted avg     0.8418    0.9040    0.8684      2741\n\nTest Macro F1: 0.4859270183135242\n\nEpoch 16 | Loss: 1.3243\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9122    0.9964    0.9524      2501\n         1.0     0.0000    0.0000    0.0000       240\n\n    accuracy                         0.9092      2741\n   macro avg     0.4561    0.4982    0.4762      2741\nweighted avg     0.8323    0.9092    0.8690      2741\n\nTest Macro F1: 0.4762086757118288\n\nEpoch 17 | Loss: 1.3264\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9123    0.9820    0.9459      2501\n         1.0     0.0816    0.0167    0.0277       240\n\n    accuracy                         0.8975      2741\n   macro avg     0.4970    0.4993    0.4868      2741\nweighted avg     0.8396    0.8975    0.8655      2741\n\nTest Macro F1: 0.48678517861081294\n\nEpoch 18 | Loss: 1.3218\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9169    0.8916    0.9041      2501\n         1.0     0.1230    0.1583    0.1384       240\n\n    accuracy                         0.8274      2741\n   macro avg     0.5200    0.5250    0.5213      2741\nweighted avg     0.8474    0.8274    0.8371      2741\n\nTest Macro F1: 0.5212743291988788\nNew Best: 0.5212743291988788 epoch: 18\n\nEpoch 19 | Loss: 1.3180\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9249    0.6154    0.7390      2501\n         1.0     0.1068    0.4792    0.1746       240\n\n    accuracy                         0.6034      2741\n   macro avg     0.5158    0.5473    0.4568      2741\nweighted avg     0.8532    0.6034    0.6896      2741\n\nTest Macro F1: 0.45682746902861376\n\nEpoch 20 | Loss: 1.3167\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9355    0.3131    0.4691      2501\n         1.0     0.0977    0.7750    0.1735       240\n\n    accuracy                         0.3535      2741\n   macro avg     0.5166    0.5440    0.3213      2741\nweighted avg     0.8621    0.3535    0.4433      2741\n\nTest Macro F1: 0.32132533110361916\n\nEpoch 21 | Loss: 1.3143\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9362    0.1583    0.2709      2501\n         1.0     0.0919    0.8875    0.1665       240\n\n    accuracy                         0.2222      2741\n   macro avg     0.5140    0.5229    0.2187      2741\nweighted avg     0.8622    0.2222    0.2617      2741\n\nTest Macro F1: 0.21869909481693653\n\nEpoch 22 | Loss: 1.3186\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9295    0.1371    0.2390      2501\n         1.0     0.0902    0.8917    0.1639       240\n\n    accuracy                         0.2032      2741\n   macro avg     0.5099    0.5144    0.2014      2741\nweighted avg     0.8560    0.2032    0.2324      2741\n\nTest Macro F1: 0.20144175101781647\n\nEpoch 23 | Loss: 1.3174\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9295    0.2215    0.3578      2501\n         1.0     0.0923    0.8250    0.1660       240\n\n    accuracy                         0.2744      2741\n   macro avg     0.5109    0.5233    0.2619      2741\nweighted avg     0.8562    0.2744    0.3410      2741\n\nTest Macro F1: 0.26190165772110563\n\nEpoch 24 | Loss: 1.3149\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9325    0.4086    0.5683      2501\n         1.0     0.1009    0.6917    0.1761       240\n\n    accuracy                         0.4334      2741\n   macro avg     0.5167    0.5502    0.3722      2741\nweighted avg     0.8597    0.4334    0.5339      2741\n\nTest Macro F1: 0.3721893207499028\n\nEpoch 25 | Loss: 1.3126\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9234    0.5834    0.7150      2501\n         1.0     0.1025    0.4958    0.1699       240\n\n    accuracy                         0.5757      2741\n   macro avg     0.5130    0.5396    0.4424      2741\nweighted avg     0.8515    0.5757    0.6673      2741\n\nTest Macro F1: 0.44244974316486574\n\nEpoch 26 | Loss: 1.3114\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9194    0.7021    0.7962      2501\n         1.0     0.1035    0.3583    0.1606       240\n\n    accuracy                         0.6720      2741\n   macro avg     0.5114    0.5302    0.4784      2741\nweighted avg     0.8479    0.6720    0.7405      2741\n\nTest Macro F1: 0.4783944560972579\n\nEpoch 27 | Loss: 1.3130\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9170    0.7469    0.8233      2501\n         1.0     0.1009    0.2958    0.1504       240\n\n    accuracy                         0.7074      2741\n   macro avg     0.5089    0.5214    0.4868      2741\nweighted avg     0.8456    0.7074    0.7644      2741\n\nTest Macro F1: 0.4868469459404949\n\nEpoch 28 | Loss: 1.3129\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9182    0.7229    0.8089      2501\n         1.0     0.1023    0.3292    0.1561       240\n\n    accuracy                         0.6884      2741\n   macro avg     0.5103    0.5260    0.4825      2741\nweighted avg     0.8468    0.6884    0.7518      2741\n\nTest Macro F1: 0.4825375140373681\n\nEpoch 29 | Loss: 1.3156\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9209    0.6469    0.7600      2501\n         1.0     0.1026    0.4208    0.1650       240\n\n    accuracy                         0.6271      2741\n   macro avg     0.5118    0.5339    0.4625      2741\nweighted avg     0.8492    0.6271    0.7079      2741\n\nTest Macro F1: 0.4625069457875526\n\nEpoch 30 | Loss: 1.3092\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9256    0.5522    0.6917      2501\n         1.0     0.1033    0.5375    0.1733       240\n\n    accuracy                         0.5509      2741\n   macro avg     0.5144    0.5448    0.4325      2741\nweighted avg     0.8536    0.5509    0.6463      2741\n\nTest Macro F1: 0.43249057240365396\n\nEpoch 31 | Loss: 1.3115\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9260    0.4702    0.6237      2501\n         1.0     0.0993    0.6083    0.1707       240\n\n    accuracy                         0.4823      2741\n   macro avg     0.5126    0.5393    0.3972      2741\nweighted avg     0.8536    0.4823    0.5840      2741\n\nTest Macro F1: 0.39718383597732304\n\nEpoch 32 | Loss: 1.3073\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9342    0.4314    0.5903      2501\n         1.0     0.1034    0.6833    0.1796       240\n\n    accuracy                         0.4535      2741\n   macro avg     0.5188    0.5574    0.3849      2741\nweighted avg     0.8615    0.4535    0.5543      2741\n\nTest Macro F1: 0.3849450916856206\n\nEpoch 33 | Loss: 1.3105\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9343    0.4266    0.5858      2501\n         1.0     0.1032    0.6875    0.1794       240\n\n    accuracy                         0.4495      2741\n   macro avg     0.5188    0.5571    0.3826      2741\nweighted avg     0.8616    0.4495    0.5502      2741\n\nTest Macro F1: 0.3826131502503852\n\nEpoch 34 | Loss: 1.3078\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9310    0.4642    0.6195      2501\n         1.0     0.1031    0.6417    0.1776       240\n\n    accuracy                         0.4798      2741\n   macro avg     0.5171    0.5529    0.3986      2741\nweighted avg     0.8585    0.4798    0.5808      2741\n\nTest Macro F1: 0.3985772034973824\n\nEpoch 35 | Loss: 1.3054\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9252    0.5242    0.6692      2501\n         1.0     0.1012    0.5583    0.1714       240\n\n    accuracy                         0.5272      2741\n   macro avg     0.5132    0.5413    0.4203      2741\nweighted avg     0.8530    0.5272    0.6256      2741\n\nTest Macro F1: 0.42028724400073636\n\nEpoch 36 | Loss: 1.3060\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9248    0.5806    0.7133      2501\n         1.0     0.1042    0.5083    0.1729       240\n\n    accuracy                         0.5742      2741\n   macro avg     0.5145    0.5445    0.4431      2741\nweighted avg     0.8530    0.5742    0.6660      2741\n\nTest Macro F1: 0.44313262412866167\n\nEpoch 37 | Loss: 1.3044\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9226    0.6098    0.7342      2501\n         1.0     0.1029    0.4667    0.1687       240\n\n    accuracy                         0.5972      2741\n   macro avg     0.5128    0.5382    0.4515      2741\nweighted avg     0.8508    0.5972    0.6847      2741\n\nTest Macro F1: 0.4514533821371185\n\nEpoch 38 | Loss: 1.3083\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9224    0.6082    0.7330      2501\n         1.0     0.1026    0.4667    0.1682       240\n\n    accuracy                         0.5958      2741\n   macro avg     0.5125    0.5374    0.4506      2741\nweighted avg     0.8506    0.5958    0.6836      2741\n\nTest Macro F1: 0.45059010818046963\n\nEpoch 39 | Loss: 1.3040\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9253    0.5746    0.7089      2501\n         1.0     0.1044    0.5167    0.1737       240\n\n    accuracy                         0.5695      2741\n   macro avg     0.5148    0.5456    0.4413      2741\nweighted avg     0.8534    0.5695    0.6621      2741\n\nTest Macro F1: 0.4412994600899067\n\nEpoch 40 | Loss: 1.3049\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9230    0.5370    0.6790      2501\n         1.0     0.0995    0.5333    0.1678       240\n\n    accuracy                         0.5367      2741\n   macro avg     0.5113    0.5352    0.4234      2741\nweighted avg     0.8509    0.5367    0.6342      2741\n\nTest Macro F1: 0.4233637509326047\n\nEpoch 41 | Loss: 1.3008\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9283    0.5022    0.6518      2501\n         1.0     0.1030    0.5958    0.1757       240\n\n    accuracy                         0.5104      2741\n   macro avg     0.5157    0.5490    0.4137      2741\nweighted avg     0.8560    0.5104    0.6101      2741\n\nTest Macro F1: 0.4137330116831933\n\nEpoch 42 | Loss: 1.2995\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9329    0.4782    0.6323      2501\n         1.0     0.1056    0.6417    0.1813       240\n\n    accuracy                         0.4925      2741\n   macro avg     0.5192    0.5599    0.4068      2741\nweighted avg     0.8605    0.4925    0.5928      2741\n\nTest Macro F1: 0.4067927566043498\n\nEpoch 43 | Loss: 1.3042\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9331    0.4794    0.6334      2501\n         1.0     0.1058    0.6417    0.1816       240\n\n    accuracy                         0.4936      2741\n   macro avg     0.5194    0.5605    0.4075      2741\nweighted avg     0.8606    0.4936    0.5938      2741\n\nTest Macro F1: 0.40749496656001755\n\nEpoch 44 | Loss: 1.3023\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9282    0.5166    0.6638      2501\n         1.0     0.1038    0.5833    0.1762       240\n\n    accuracy                         0.5224      2741\n   macro avg     0.5160    0.5500    0.4200      2741\nweighted avg     0.8560    0.5224    0.6211      2741\n\nTest Macro F1: 0.41998345612988863\n\nEpoch 45 | Loss: 1.3021\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9249    0.5566    0.6950      2501\n         1.0     0.1028    0.5292    0.1721       240\n\n    accuracy                         0.5542      2741\n   macro avg     0.5138    0.5429    0.4335      2741\nweighted avg     0.8529    0.5542    0.6492      2741\n\nTest Macro F1: 0.4335221422608634\n\nEpoch 46 | Loss: 1.2981\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9242    0.5802    0.7128      2501\n         1.0     0.1033    0.5042    0.1715       240\n\n    accuracy                         0.5735      2741\n   macro avg     0.5138    0.5422    0.4422      2741\nweighted avg     0.8523    0.5735    0.6654      2741\n\nTest Macro F1: 0.4421782670149148\n\nEpoch 47 | Loss: 1.3020\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9239    0.5726    0.7070      2501\n         1.0     0.1024    0.5083    0.1705       240\n\n    accuracy                         0.5669      2741\n   macro avg     0.5132    0.5405    0.4387      2741\nweighted avg     0.8519    0.5669    0.6600      2741\n\nTest Macro F1: 0.4387480310872159\n\nEpoch 48 | Loss: 1.3013\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9252    0.5490    0.6891      2501\n         1.0     0.1026    0.5375    0.1723       240\n\n    accuracy                         0.5480      2741\n   macro avg     0.5139    0.5432    0.4307      2741\nweighted avg     0.8532    0.5480    0.6438      2741\n\nTest Macro F1: 0.43071437731171247\n\nEpoch 49 | Loss: 1.2971\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9284    0.5186    0.6655      2501\n         1.0     0.1042    0.5833    0.1768       240\n\n    accuracy                         0.5243      2741\n   macro avg     0.5163    0.5510    0.4211      2741\nweighted avg     0.8562    0.5243    0.6227      2741\n\nTest Macro F1: 0.4211185741457676\n\nEpoch 50 | Loss: 1.2971\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9291    0.4926    0.6438      2501\n         1.0     0.1032    0.6083    0.1764       240\n\n    accuracy                         0.5027      2741\n   macro avg     0.5161    0.5505    0.4101      2741\nweighted avg     0.8568    0.5027    0.6029      2741\n\nTest Macro F1: 0.4101407000821797\n\nEpoch 51 | Loss: 1.3028\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9341    0.4702    0.6255      2501\n         1.0     0.1059    0.6542    0.1823       240\n\n    accuracy                         0.4863      2741\n   macro avg     0.5200    0.5622    0.4039      2741\nweighted avg     0.8616    0.4863    0.5867      2741\n\nTest Macro F1: 0.4039390120344973\n\nEpoch 52 | Loss: 1.2971\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9333    0.4702    0.6254      2501\n         1.0     0.1053    0.6500    0.1813       240\n\n    accuracy                         0.4860      2741\n   macro avg     0.5193    0.5601    0.4033      2741\nweighted avg     0.8608    0.4860    0.5865      2741\n\nTest Macro F1: 0.40332777098083467\n\nEpoch 53 | Loss: 1.2975\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9284    0.4922    0.6433      2501\n         1.0     0.1025    0.6042    0.1752       240\n\n    accuracy                         0.5020      2741\n   macro avg     0.5154    0.5482    0.4093      2741\nweighted avg     0.8560    0.5020    0.6023      2741\n\nTest Macro F1: 0.40927516919455265\n\nEpoch 54 | Loss: 1.2954\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9258    0.5238    0.6691      2501\n         1.0     0.1018    0.5625    0.1724       240\n\n    accuracy                         0.5272      2741\n   macro avg     0.5138    0.5431    0.4207      2741\nweighted avg     0.8536    0.5272    0.6256      2741\n\nTest Macro F1: 0.42073192208798565\n\nEpoch 55 | Loss: 1.2960\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9265    0.5498    0.6901      2501\n         1.0     0.1042    0.5458    0.1750       240\n\n    accuracy                         0.5494      2741\n   macro avg     0.5154    0.5478    0.4326      2741\nweighted avg     0.8545    0.5494    0.6450      2741\n\nTest Macro F1: 0.4325522647134503\n\nEpoch 56 | Loss: 1.2968\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9263    0.5426    0.6843      2501\n         1.0     0.1034    0.5500    0.1741       240\n\n    accuracy                         0.5432      2741\n   macro avg     0.5149    0.5463    0.4292      2741\nweighted avg     0.8542    0.5432    0.6396      2741\n\nTest Macro F1: 0.4292295860460351\n\nEpoch 57 | Loss: 1.2964\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9268    0.5366    0.6797      2501\n         1.0     0.1036    0.5583    0.1748       240\n\n    accuracy                         0.5385      2741\n   macro avg     0.5152    0.5475    0.4272      2741\nweighted avg     0.8547    0.5385    0.6355      2741\n\nTest Macro F1: 0.4272431756691687\n\nEpoch 58 | Loss: 1.2943\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9264    0.5182    0.6646      2501\n         1.0     0.1021    0.5708    0.1732       240\n\n    accuracy                         0.5228      2741\n   macro avg     0.5142    0.5445    0.4189      2741\nweighted avg     0.8542    0.5228    0.6216      2741\n\nTest Macro F1: 0.4189069337741904\n\nEpoch 59 | Loss: 1.2994\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9283    0.5074    0.6562      2501\n         1.0     0.1033    0.5917    0.1760       240\n\n    accuracy                         0.5148      2741\n   macro avg     0.5158    0.5495    0.4161      2741\nweighted avg     0.8561    0.5148    0.6141      2741\n\nTest Macro F1: 0.4160566988181231\n\nEpoch 60 | Loss: 1.2929\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9285    0.4982    0.6485      2501\n         1.0     0.1029    0.6000    0.1757       240\n\n    accuracy                         0.5071      2741\n   macro avg     0.5157    0.5491    0.4121      2741\nweighted avg     0.8562    0.5071    0.6071      2741\n\nTest Macro F1: 0.41208431548402946\n\nEpoch 61 | Loss: 1.2930\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9278    0.4982    0.6483      2501\n         1.0     0.1023    0.5958    0.1746       240\n\n    accuracy                         0.5067      2741\n   macro avg     0.5150    0.5470    0.4114      2741\nweighted avg     0.8555    0.5067    0.6068      2741\n\nTest Macro F1: 0.4114431065523677\n\nEpoch 62 | Loss: 1.2899\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9268    0.5110    0.6588      2501\n         1.0     0.1021    0.5792    0.1735       240\n\n    accuracy                         0.5170      2741\n   macro avg     0.5144    0.5451    0.4161      2741\nweighted avg     0.8545    0.5170    0.6163      2741\n\nTest Macro F1: 0.41614798512169066\n\nEpoch 63 | Loss: 1.2940\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9250    0.5178    0.6639      2501\n         1.0     0.1007    0.5625    0.1708       240\n\n    accuracy                         0.5217      2741\n   macro avg     0.5128    0.5401    0.4174      2741\nweighted avg     0.8528    0.5217    0.6208      2741\n\nTest Macro F1: 0.41735515682983054\n\nEpoch 64 | Loss: 1.2924\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9250    0.5230    0.6682      2501\n         1.0     0.1010    0.5583    0.1710       240\n\n    accuracy                         0.5261      2741\n   macro avg     0.5130    0.5407    0.4196      2741\nweighted avg     0.8529    0.5261    0.6247      2741\n\nTest Macro F1: 0.4196133373432407\n\nEpoch 65 | Loss: 1.2877\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9244    0.5282    0.6723      2501\n         1.0     0.1006    0.5500    0.1701       240\n\n    accuracy                         0.5301      2741\n   macro avg     0.5125    0.5391    0.4212      2741\nweighted avg     0.8523    0.5301    0.6283      2741\n\nTest Macro F1: 0.4211838619133811\n\nEpoch 66 | Loss: 1.2900\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9267    0.5210    0.6670      2501\n         1.0     0.1026    0.5708    0.1740       240\n\n    accuracy                         0.5254      2741\n   macro avg     0.5147    0.5459    0.4205      2741\nweighted avg     0.8546    0.5254    0.6238      2741\n\nTest Macro F1: 0.42048809422241723\n\nEpoch 67 | Loss: 1.2899\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9278    0.5034    0.6527      2501\n         1.0     0.1026    0.5917    0.1749       240\n\n    accuracy                         0.5111      2741\n   macro avg     0.5152    0.5475    0.4138      2741\nweighted avg     0.8555    0.5111    0.6108      2741\n\nTest Macro F1: 0.4137733121886068\n\nEpoch 68 | Loss: 1.2906\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9263    0.4922    0.6428      2501\n         1.0     0.1006    0.5917    0.1719       240\n\n    accuracy                         0.5009      2741\n   macro avg     0.5134    0.5419    0.4074      2741\nweighted avg     0.8540    0.5009    0.6016      2741\n\nTest Macro F1: 0.4073663381359093\n\nEpoch 69 | Loss: 1.2868\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9268    0.4858    0.6375      2501\n         1.0     0.1007    0.6000    0.1725       240\n\n    accuracy                         0.4958      2741\n   macro avg     0.5137    0.5429    0.4050      2741\nweighted avg     0.8544    0.4958    0.5967      2741\n\nTest Macro F1: 0.4049578701987421\n\nEpoch 70 | Loss: 1.2850\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9261    0.4910    0.6418      2501\n         1.0     0.1004    0.5917    0.1716       240\n\n    accuracy                         0.4998      2741\n   macro avg     0.5132    0.5413    0.4067      2741\nweighted avg     0.8538    0.4998    0.6006      2741\n\nTest Macro F1: 0.4066785765316715\n\nEpoch 71 | Loss: 1.2874\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9260    0.4950    0.6451      2501\n         1.0     0.1004    0.5875    0.1715       240\n\n    accuracy                         0.5031      2741\n   macro avg     0.5132    0.5413    0.4083      2741\nweighted avg     0.8537    0.5031    0.6037      2741\n\nTest Macro F1: 0.40833025868856576\n\nEpoch 72 | Loss: 1.2867\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9262    0.5018    0.6509      2501\n         1.0     0.1010    0.5833    0.1722       240\n\n    accuracy                         0.5089      2741\n   macro avg     0.5136    0.5426    0.4116      2741\nweighted avg     0.8539    0.5089    0.6090      2741\n\nTest Macro F1: 0.41156766598786326\n\nEpoch 73 | Loss: 1.2817\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9271    0.5186    0.6651      2501\n         1.0     0.1028    0.5750    0.1745       240\n\n    accuracy                         0.5235      2741\n   macro avg     0.5150    0.5468    0.4198      2741\nweighted avg     0.8549    0.5235    0.6222      2741\n\nTest Macro F1: 0.41979545528218093\n\nEpoch 74 | Loss: 1.2840\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9285    0.5086    0.6572      2501\n         1.0     0.1036    0.5917    0.1763       240\n\n    accuracy                         0.5159      2741\n   macro avg     0.5160    0.5501    0.4167      2741\nweighted avg     0.8562    0.5159    0.6151      2741\n\nTest Macro F1: 0.4167412716212054\n\nEpoch 75 | Loss: 1.2856\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9272    0.4786    0.6313      2501\n         1.0     0.1007    0.6083    0.1728       240\n\n    accuracy                         0.4900      2741\n   macro avg     0.5139    0.5435    0.4021      2741\nweighted avg     0.8548    0.4900    0.5912      2741\n\nTest Macro F1: 0.402055089506404\n\nEpoch 76 | Loss: 1.2914\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9275    0.4346    0.5919      2501\n         1.0     0.0988    0.6458    0.1714       240\n\n    accuracy                         0.4531      2741\n   macro avg     0.5131    0.5402    0.3816      2741\nweighted avg     0.8549    0.4531    0.5551      2741\n\nTest Macro F1: 0.38162606816478756\n\nEpoch 77 | Loss: 1.2866\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9259    0.4246    0.5822      2501\n         1.0     0.0972    0.6458    0.1690       240\n\n    accuracy                         0.4440      2741\n   macro avg     0.5116    0.5352    0.3756      2741\nweighted avg     0.8533    0.4440    0.5461      2741\n\nTest Macro F1: 0.3756331429719337\n\nEpoch 78 | Loss: 1.2817\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9279    0.4578    0.6131      2501\n         1.0     0.1002    0.6292    0.1729       240\n\n    accuracy                         0.4728      2741\n   macro avg     0.5140    0.5435    0.3930      2741\nweighted avg     0.8554    0.4728    0.5746      2741\n\nTest Macro F1: 0.3929934582826632\n\nEpoch 79 | Loss: 1.2897\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9292    0.5094    0.6581      2501\n         1.0     0.1044    0.5958    0.1776       240\n\n    accuracy                         0.5170      2741\n   macro avg     0.5168    0.5526    0.4178      2741\nweighted avg     0.8570    0.5170    0.6160      2741\n\nTest Macro F1: 0.4178488013962322\n\nEpoch 80 | Loss: 1.2803\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9266    0.5450    0.6863      2501\n         1.0     0.1039    0.5500    0.1748       240\n\n    accuracy                         0.5454      2741\n   macro avg     0.5153    0.5475    0.4306      2741\nweighted avg     0.8546    0.5454    0.6415      2741\n\nTest Macro F1: 0.43056928299420444\n\nEpoch 81 | Loss: 1.2874\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9283    0.5226    0.6687      2501\n         1.0     0.1043    0.5792    0.1767       240\n\n    accuracy                         0.5275      2741\n   macro avg     0.5163    0.5509    0.4227      2741\nweighted avg     0.8561    0.5275    0.6256      2741\n\nTest Macro F1: 0.4227227922197573\n\nEpoch 82 | Loss: 1.2816\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9289    0.4806    0.6335      2501\n         1.0     0.1023    0.6167    0.1755       240\n\n    accuracy                         0.4925      2741\n   macro avg     0.5156    0.5486    0.4045      2741\nweighted avg     0.8565    0.4925    0.5934      2741\n\nTest Macro F1: 0.4044622405077033\n\nEpoch 83 | Loss: 1.2862\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9273    0.4438    0.6003      2501\n         1.0     0.0991    0.6375    0.1715       240\n\n    accuracy                         0.4608      2741\n   macro avg     0.5132    0.5407    0.3859      2741\nweighted avg     0.8548    0.4608    0.5628      2741\n\nTest Macro F1: 0.3859245817033568\n\nEpoch 84 | Loss: 1.2852\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9283    0.4298    0.5876      2501\n         1.0     0.0992    0.6542    0.1722       240\n\n    accuracy                         0.4495      2741\n   macro avg     0.5138    0.5420    0.3799      2741\nweighted avg     0.8557    0.4495    0.5512      2741\n\nTest Macro F1: 0.379917896448421\n\nEpoch 85 | Loss: 1.2819\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9283    0.4558    0.6114      2501\n         1.0     0.1005    0.6333    0.1734       240\n\n    accuracy                         0.4714      2741\n   macro avg     0.5144    0.5446    0.3924      2741\nweighted avg     0.8559    0.4714    0.5731      2741\n\nTest Macro F1: 0.392420486842691\n\nEpoch 86 | Loss: 1.2761\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9281    0.5106    0.6588      2501\n         1.0     0.1033    0.5875    0.1757       240\n\n    accuracy                         0.5173      2741\n   macro avg     0.5157    0.5490    0.4172      2741\nweighted avg     0.8558    0.5173    0.6165      2741\n\nTest Macro F1: 0.41722885263921666\n\nEpoch 87 | Loss: 1.2714\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9255    0.5466    0.6873      2501\n         1.0     0.1028    0.5417    0.1729       240\n\n    accuracy                         0.5462      2741\n   macro avg     0.5142    0.5441    0.4301      2741\nweighted avg     0.8535    0.5462    0.6422      2741\n\nTest Macro F1: 0.4300761903233743\n\nEpoch 88 | Loss: 1.2828\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9253    0.5446    0.6856      2501\n         1.0     0.1024    0.5417    0.1723       240\n\n    accuracy                         0.5443      2741\n   macro avg     0.5139    0.5431    0.4290      2741\nweighted avg     0.8532    0.5443    0.6407      2741\n\nTest Macro F1: 0.4289637625209395\n\nEpoch 89 | Loss: 1.2851\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9277    0.5130    0.6607      2501\n         1.0     0.1031    0.5833    0.1752       240\n\n    accuracy                         0.5192      2741\n   macro avg     0.5154    0.5482    0.4179      2741\nweighted avg     0.8555    0.5192    0.6182      2741\n\nTest Macro F1: 0.41793906904743183\n\nEpoch 90 | Loss: 1.2716\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9258    0.4838    0.6355      2501\n         1.0     0.0997    0.5958    0.1708       240\n\n    accuracy                         0.4936      2741\n   macro avg     0.5128    0.5398    0.4032      2741\nweighted avg     0.8535    0.4936    0.5948      2741\n\nTest Macro F1: 0.40317623465156677\n\nEpoch 91 | Loss: 1.2828\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9277    0.4722    0.6259      2501\n         1.0     0.1008    0.6167    0.1733       240\n\n    accuracy                         0.4849      2741\n   macro avg     0.5143    0.5444    0.3996      2741\nweighted avg     0.8553    0.4849    0.5862      2741\n\nTest Macro F1: 0.39958163150062853\n\nEpoch 92 | Loss: 1.2861\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9260    0.4754    0.6283      2501\n         1.0     0.0995    0.6042    0.1709       240\n\n    accuracy                         0.4867      2741\n   macro avg     0.5128    0.5398    0.3996      2741\nweighted avg     0.8536    0.4867    0.5882      2741\n\nTest Macro F1: 0.3995796451738206\n\nEpoch 93 | Loss: 1.2783\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9277    0.4974    0.6476      2501\n         1.0     0.1021    0.5958    0.1744       240\n\n    accuracy                         0.5060      2741\n   macro avg     0.5149    0.5466    0.4110      2741\nweighted avg     0.8554    0.5060    0.6061      2741\n\nTest Macro F1: 0.4109848148195173\n\nEpoch 94 | Loss: 1.2880\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9272    0.5094    0.6575      2501\n         1.0     0.1024    0.5833    0.1742       240\n\n    accuracy                         0.5159      2741\n   macro avg     0.5148    0.5464    0.4159      2741\nweighted avg     0.8550    0.5159    0.6152      2741\n\nTest Macro F1: 0.41589304855772136\n\nEpoch 95 | Loss: 1.2770\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9256    0.5122    0.6595      2501\n         1.0     0.1010    0.5708    0.1716       240\n\n    accuracy                         0.5173      2741\n   macro avg     0.5133    0.5415    0.4155      2741\nweighted avg     0.8534    0.5173    0.6167      2741\n\nTest Macro F1: 0.4155155781956032\n\nEpoch 96 | Loss: 1.2692\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9281    0.4954    0.6460      2501\n         1.0     0.1024    0.6000    0.1750       240\n\n    accuracy                         0.5046      2741\n   macro avg     0.5153    0.5477    0.4105      2741\nweighted avg     0.8558    0.5046    0.6047      2741\n\nTest Macro F1: 0.41047751239456853\n\nEpoch 97 | Loss: 1.2763\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9273    0.4794    0.6321      2501\n         1.0     0.1008    0.6083    0.1730       240\n\n    accuracy                         0.4907      2741\n   macro avg     0.5141    0.5439    0.4025      2741\nweighted avg     0.8549    0.4907    0.5919      2741\n\nTest Macro F1: 0.40251819410543455\n\nEpoch 98 | Loss: 1.2761\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9281    0.4850    0.6371      2501\n         1.0     0.1018    0.6083    0.1744       240\n\n    accuracy                         0.4958      2741\n   macro avg     0.5149    0.5467    0.4058      2741\nweighted avg     0.8557    0.4958    0.5966      2741\n\nTest Macro F1: 0.4057561644729576\n\nEpoch 99 | Loss: 1.2785\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9274    0.4902    0.6414      2501\n         1.0     0.1015    0.6000    0.1736       240\n\n    accuracy                         0.4998      2741\n   macro avg     0.5144    0.5451    0.4075      2741\nweighted avg     0.8551    0.4998    0.6004      2741\n\nTest Macro F1: 0.40748983382676185\n\nEpoch 100 | Loss: 1.2779\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9279    0.5094    0.6577      2501\n         1.0     0.1031    0.5875    0.1754       240\n\n    accuracy                         0.5162      2741\n   macro avg     0.5155    0.5484    0.4165      2741\nweighted avg     0.8557    0.5162    0.6155      2741\n\nTest Macro F1: 0.4165456275668637\n\nEpoch 101 | Loss: 1.2729\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9274    0.4906    0.6417      2501\n         1.0     0.1016    0.6000    0.1737       240\n\n    accuracy                         0.5002      2741\n   macro avg     0.5145    0.5453    0.4077      2741\nweighted avg     0.8551    0.5002    0.6008      2741\n\nTest Macro F1: 0.4077198293048539\n\nEpoch 102 | Loss: 1.2782\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9260    0.4806    0.6328      2501\n         1.0     0.0998    0.6000    0.1711       240\n\n    accuracy                         0.4911      2741\n   macro avg     0.5129    0.5403    0.4020      2741\nweighted avg     0.8537    0.4911    0.5924      2741\n\nTest Macro F1: 0.40196054970840905\n\nEpoch 103 | Loss: 1.2804\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9277    0.4826    0.6349      2501\n         1.0     0.1014    0.6083    0.1738       240\n\n    accuracy                         0.4936      2741\n   macro avg     0.5146    0.5455    0.4044      2741\nweighted avg     0.8554    0.4936    0.5946      2741\n\nTest Macro F1: 0.4043692542771974\n\nEpoch 104 | Loss: 1.2705\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9277    0.5026    0.6520      2501\n         1.0     0.1025    0.5917    0.1747       240\n\n    accuracy                         0.5104      2741\n   macro avg     0.5151    0.5471    0.4133      2741\nweighted avg     0.8554    0.5104    0.6102      2741\n\nTest Macro F1: 0.4133163504871563\n\nEpoch 105 | Loss: 1.2753\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9235    0.5258    0.6701      2501\n         1.0     0.0995    0.5458    0.1683       240\n\n    accuracy                         0.5275      2741\n   macro avg     0.5115    0.5358    0.4192      2741\nweighted avg     0.8513    0.5275    0.6261      2741\n\nTest Macro F1: 0.419168006414426\n\nEpoch 106 | Loss: 1.2745\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9235    0.5258    0.6701      2501\n         1.0     0.0995    0.5458    0.1683       240\n\n    accuracy                         0.5275      2741\n   macro avg     0.5115    0.5358    0.4192      2741\nweighted avg     0.8513    0.5275    0.6261      2741\n\nTest Macro F1: 0.419168006414426\n\nEpoch 107 | Loss: 1.2759\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9250    0.5030    0.6516      2501\n         1.0     0.0999    0.5750    0.1703       240\n\n    accuracy                         0.5093      2741\n   macro avg     0.5125    0.5390    0.4110      2741\nweighted avg     0.8528    0.5093    0.6095      2741\n\nTest Macro F1: 0.4109549599987601\n\nEpoch 108 | Loss: 1.2729\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9255    0.4870    0.6382      2501\n         1.0     0.0996    0.5917    0.1706       240\n\n    accuracy                         0.4962      2741\n   macro avg     0.5126    0.5393    0.4044      2741\nweighted avg     0.8532    0.4962    0.5973      2741\n\nTest Macro F1: 0.4043840539517773\n\nEpoch 109 | Loss: 1.2708\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9255    0.4966    0.6464      2501\n         1.0     0.1001    0.5833    0.1708       240\n\n    accuracy                         0.5042      2741\n   macro avg     0.5128    0.5400    0.4086      2741\nweighted avg     0.8532    0.5042    0.6047      2741\n\nTest Macro F1: 0.4086029494765329\n\nEpoch 110 | Loss: 1.2687\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9254    0.5454    0.6863      2501\n         1.0     0.1026    0.5417    0.1725       240\n\n    accuracy                         0.5451      2741\n   macro avg     0.5140    0.5435    0.4294      2741\nweighted avg     0.8533    0.5451    0.6413      2741\n\nTest Macro F1: 0.4294087549506913\n\nEpoch 111 | Loss: 1.2763\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9249    0.5466    0.6871      2501\n         1.0     0.1021    0.5375    0.1717       240\n\n    accuracy                         0.5458      2741\n   macro avg     0.5135    0.5420    0.4294      2741\nweighted avg     0.8529    0.5458    0.6420      2741\n\nTest Macro F1: 0.429382000011036\n\nEpoch 112 | Loss: 1.2660\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9268    0.5266    0.6716      2501\n         1.0     0.1030    0.5667    0.1744       240\n\n    accuracy                         0.5301      2741\n   macro avg     0.5149    0.5466    0.4230      2741\nweighted avg     0.8547    0.5301    0.6281      2741\n\nTest Macro F1: 0.42297754939264376\n\nEpoch 113 | Loss: 1.2744\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9269    0.4918    0.6426      2501\n         1.0     0.1011    0.5958    0.1729       240\n\n    accuracy                         0.5009      2741\n   macro avg     0.5140    0.5438    0.4078      2741\nweighted avg     0.8546    0.5009    0.6015      2741\n\nTest Macro F1: 0.40777368818064313\n\nEpoch 114 | Loss: 1.2663\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9258    0.4686    0.6222      2501\n         1.0     0.0990    0.6083    0.1703       240\n\n    accuracy                         0.4808      2741\n   macro avg     0.5124    0.5385    0.3963      2741\nweighted avg     0.8534    0.4808    0.5827      2741\n\nTest Macro F1: 0.3962541048123144\n\nEpoch 115 | Loss: 1.2709\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9264    0.5030    0.6520      2501\n         1.0     0.1012    0.5833    0.1725       240\n\n    accuracy                         0.5100      2741\n   macro avg     0.5138    0.5432    0.4123      2741\nweighted avg     0.8541    0.5100    0.6100      2741\n\nTest Macro F1: 0.41225120175017166\n\nEpoch 116 | Loss: 1.2671\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9265    0.5742    0.7090      2501\n         1.0     0.1058    0.5250    0.1761       240\n\n    accuracy                         0.5699      2741\n   macro avg     0.5161    0.5496    0.4425      2741\nweighted avg     0.8546    0.5699    0.6623      2741\n\nTest Macro F1: 0.4425306896814048\n\nEpoch 117 | Loss: 1.2788\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9251    0.5530    0.6922      2501\n         1.0     0.1027    0.5333    0.1723       240\n\n    accuracy                         0.5513      2741\n   macro avg     0.5139    0.5432    0.4322      2741\nweighted avg     0.8531    0.5513    0.6467      2741\n\nTest Macro F1: 0.4322333773881553\n\nEpoch 118 | Loss: 1.2730\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9241    0.4870    0.6379      2501\n         1.0     0.0984    0.5833    0.1684       240\n\n    accuracy                         0.4954      2741\n   macro avg     0.5113    0.5352    0.4031      2741\nweighted avg     0.8518    0.4954    0.5968      2741\n\nTest Macro F1: 0.40311686495836796\n\nEpoch 119 | Loss: 1.2714\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9238    0.4510    0.6061      2501\n         1.0     0.0967    0.6125    0.1670       240\n\n    accuracy                         0.4652      2741\n   macro avg     0.5103    0.5318    0.3866      2741\nweighted avg     0.8514    0.4652    0.5677      2741\n\nTest Macro F1: 0.3865855966977676\n\nEpoch 120 | Loss: 1.2620\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9213    0.4590    0.6128      2501\n         1.0     0.0950    0.5917    0.1637       240\n\n    accuracy                         0.4706      2741\n   macro avg     0.5082    0.5253    0.3882      2741\nweighted avg     0.8490    0.4706    0.5734      2741\n\nTest Macro F1: 0.3882228164856573\n\nEpoch 121 | Loss: 1.2700\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9222    0.5258    0.6697      2501\n         1.0     0.0981    0.5375    0.1659       240\n\n    accuracy                         0.5268      2741\n   macro avg     0.5101    0.5316    0.4178      2741\nweighted avg     0.8500    0.5268    0.6256      2741\n\nTest Macro F1: 0.4178194165710715\n\nEpoch 122 | Loss: 1.2671\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9233    0.5822    0.7141      2501\n         1.0     0.1022    0.4958    0.1695       240\n\n    accuracy                         0.5746      2741\n   macro avg     0.5128    0.5390    0.4418      2741\nweighted avg     0.8514    0.5746    0.6664      2741\n\nTest Macro F1: 0.4417955983674473\n\nEpoch 123 | Loss: 1.2711\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9222    0.5122    0.6586      2501\n         1.0     0.0976    0.5500    0.1658       240\n\n    accuracy                         0.5155      2741\n   macro avg     0.5099    0.5311    0.4122      2741\nweighted avg     0.8500    0.5155    0.6155      2741\n\nTest Macro F1: 0.41222048546072265\n\nEpoch 124 | Loss: 1.2662\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9206    0.4494    0.6040      2501\n         1.0     0.0941    0.5958    0.1625       240\n\n    accuracy                         0.4622      2741\n   macro avg     0.5073    0.5226    0.3832      2741\nweighted avg     0.8482    0.4622    0.5653      2741\n\nTest Macro F1: 0.3832381783987103\n\nEpoch 125 | Loss: 1.2628\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9191    0.4494    0.6037      2501\n         1.0     0.0929    0.5875    0.1604       240\n\n    accuracy                         0.4615      2741\n   macro avg     0.5060    0.5185    0.3820      2741\nweighted avg     0.8467    0.4615    0.5648      2741\n\nTest Macro F1: 0.3820307717123135\n\nEpoch 126 | Loss: 1.2693\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9219    0.5146    0.6605      2501\n         1.0     0.0974    0.5458    0.1653       240\n\n    accuracy                         0.5173      2741\n   macro avg     0.5097    0.5302    0.4129      2741\nweighted avg     0.8497    0.5173    0.6171      2741\n\nTest Macro F1: 0.41290388384173216\n\nEpoch 127 | Loss: 1.2598\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9243    0.5714    0.7062      2501\n         1.0     0.1029    0.5125    0.1714       240\n\n    accuracy                         0.5662      2741\n   macro avg     0.5136    0.5419    0.4388      2741\nweighted avg     0.8524    0.5662    0.6594      2741\n\nTest Macro F1: 0.43881534822972923\n\nEpoch 128 | Loss: 1.2688\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9239    0.5582    0.6959      2501\n         1.0     0.1016    0.5208    0.1701       240\n\n    accuracy                         0.5549      2741\n   macro avg     0.5128    0.5395    0.4330      2741\nweighted avg     0.8519    0.5549    0.6499      2741\n\nTest Macro F1: 0.43299014521062656\n\nEpoch 129 | Loss: 1.2684\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9238    0.4946    0.6443      2501\n         1.0     0.0984    0.5750    0.1681       240\n\n    accuracy                         0.5016      2741\n   macro avg     0.5111    0.5348    0.4062      2741\nweighted avg     0.8516    0.5016    0.6026      2741\n\nTest Macro F1: 0.4061792656313438\n\nEpoch 130 | Loss: 1.2584\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9232    0.4566    0.6110      2501\n         1.0     0.0964    0.6042    0.1663       240\n\n    accuracy                         0.4695      2741\n   macro avg     0.5098    0.5304    0.3887      2741\nweighted avg     0.8508    0.4695    0.5721      2741\n\nTest Macro F1: 0.3886531702671791\n\nEpoch 131 | Loss: 1.2663\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9254    0.4610    0.6154      2501\n         1.0     0.0983    0.6125    0.1695       240\n\n    accuracy                         0.4743      2741\n   macro avg     0.5118    0.5368    0.3924      2741\nweighted avg     0.8529    0.4743    0.5764      2741\n\nTest Macro F1: 0.39243906172007736\n\nEpoch 132 | Loss: 1.2588\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9238    0.5334    0.6763      2501\n         1.0     0.1002    0.5417    0.1692       240\n\n    accuracy                         0.5341      2741\n   macro avg     0.5120    0.5375    0.4227      2741\nweighted avg     0.8517    0.5341    0.6319      2741\n\nTest Macro F1: 0.422729907734274\n\nEpoch 133 | Loss: 1.2620\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9246    0.5782    0.7114      2501\n         1.0     0.1037    0.5083    0.1722       240\n\n    accuracy                         0.5721      2741\n   macro avg     0.5141    0.5433    0.4418      2741\nweighted avg     0.8527    0.5721    0.6642      2741\n\nTest Macro F1: 0.4418169460452544\n\nEpoch 134 | Loss: 1.2573\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9255    0.5914    0.7216      2501\n         1.0     0.1059    0.5042    0.1750       240\n\n    accuracy                         0.5837      2741\n   macro avg     0.5157    0.5478    0.4483      2741\nweighted avg     0.8538    0.5837    0.6738      2741\n\nTest Macro F1: 0.4483106738024212\n\nEpoch 135 | Loss: 1.2671\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9255    0.5218    0.6673      2501\n         1.0     0.1014    0.5625    0.1719       240\n\n    accuracy                         0.5254      2741\n   macro avg     0.5135    0.5421    0.4196      2741\nweighted avg     0.8534    0.5254    0.6240      2741\n\nTest Macro F1: 0.4196067791622675\n\nEpoch 136 | Loss: 1.2663\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9251    0.4838    0.6353      2501\n         1.0     0.0991    0.5917    0.1698       240\n\n    accuracy                         0.4933      2741\n   macro avg     0.5121    0.5377    0.4025      2741\nweighted avg     0.8528    0.4933    0.5946      2741\n\nTest Macro F1: 0.4025461450740272\n\nEpoch 137 | Loss: 1.2591\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9245    0.5238    0.6687      2501\n         1.0     0.1005    0.5542    0.1701       240\n\n    accuracy                         0.5265      2741\n   macro avg     0.5125    0.5390    0.4194      2741\nweighted avg     0.8523    0.5265    0.6250      2741\n\nTest Macro F1: 0.4193926255501202\n\nEpoch 138 | Loss: 1.2619\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9243    0.5518    0.6910      2501\n         1.0     0.1018    0.5292    0.1707       240\n\n    accuracy                         0.5498      2741\n   macro avg     0.5130    0.5405    0.4309      2741\nweighted avg     0.8523    0.5498    0.6455      2741\n\nTest Macro F1: 0.43086773978171555\n\nEpoch 139 | Loss: 1.2610\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9244    0.5474    0.6876      2501\n         1.0     0.1016    0.5333    0.1707       240\n\n    accuracy                         0.5462      2741\n   macro avg     0.5130    0.5404    0.4291      2741\nweighted avg     0.8523    0.5462    0.6423      2741\n\nTest Macro F1: 0.4291304202243429\n\nEpoch 140 | Loss: 1.2542\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9249    0.5174    0.6636      2501\n         1.0     0.1006    0.5625    0.1707       240\n\n    accuracy                         0.5213      2741\n   macro avg     0.5128    0.5399    0.4171      2741\nweighted avg     0.8528    0.5213    0.6204      2741\n\nTest Macro F1: 0.4171298907582094\n\nEpoch 141 | Loss: 1.2623\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9227    0.4866    0.6372      2501\n         1.0     0.0970    0.5750    0.1661       240\n\n    accuracy                         0.4943      2741\n   macro avg     0.5099    0.5308    0.4016      2741\nweighted avg     0.8504    0.4943    0.5959      2741\n\nTest Macro F1: 0.40161887840928423\n\nEpoch 142 | Loss: 1.2568\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9235    0.4970    0.6462      2501\n         1.0     0.0982    0.5708    0.1676       240\n\n    accuracy                         0.5035      2741\n   macro avg     0.5108    0.5339    0.4069      2741\nweighted avg     0.8512    0.5035    0.6043      2741\n\nTest Macro F1: 0.4069009649681352\n\nEpoch 143 | Loss: 1.2570\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9250    0.5474    0.6878      2501\n         1.0     0.1023    0.5375    0.1719       240\n\n    accuracy                         0.5465      2741\n   macro avg     0.5136    0.5424    0.4298      2741\nweighted avg     0.8530    0.5465    0.6426      2741\n\nTest Macro F1: 0.4298261512336832\n\nEpoch 144 | Loss: 1.2547\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9233    0.5678    0.7031      2501\n         1.0     0.1014    0.5083    0.1691       240\n\n    accuracy                         0.5626      2741\n   macro avg     0.5123    0.5381    0.4361      2741\nweighted avg     0.8513    0.5626    0.6564      2741\n\nTest Macro F1: 0.43611825587562153\n\nEpoch 145 | Loss: 1.2555\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9232    0.5574    0.6951      2501\n         1.0     0.1007    0.5167    0.1686       240\n\n    accuracy                         0.5538      2741\n   macro avg     0.5120    0.5370    0.4318      2741\nweighted avg     0.8512    0.5538    0.6490      2741\n\nTest Macro F1: 0.43184065031225316\n\nEpoch 146 | Loss: 1.2552\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9241    0.5358    0.6783      2501\n         1.0     0.1007    0.5417    0.1698       240\n\n    accuracy                         0.5363      2741\n   macro avg     0.5124    0.5387    0.4241      2741\nweighted avg     0.8520    0.5363    0.6338      2741\n\nTest Macro F1: 0.42406646673216525\n\nEpoch 147 | Loss: 1.2591\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9215    0.5070    0.6541      2501\n         1.0     0.0967    0.5500    0.1645       240\n\n    accuracy                         0.5108      2741\n   macro avg     0.5091    0.5285    0.4093      2741\nweighted avg     0.8493    0.5108    0.6112      2741\n\nTest Macro F1: 0.40929999349145085\n\nEpoch 148 | Loss: 1.2494\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9261    0.5610    0.6987      2501\n         1.0     0.1044    0.5333    0.1746       240\n\n    accuracy                         0.5586      2741\n   macro avg     0.5152    0.5472    0.4367      2741\nweighted avg     0.8541    0.5586    0.6528      2741\n\nTest Macro F1: 0.4366650043754043\n\nEpoch 149 | Loss: 1.2494\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9222    0.6497    0.7624      2501\n         1.0     0.1052    0.4292    0.1690       240\n\n    accuracy                         0.6304      2741\n   macro avg     0.5137    0.5395    0.4657      2741\nweighted avg     0.8507    0.6304    0.7104      2741\n\nTest Macro F1: 0.4656824456466414\n\nEpoch 150 | Loss: 1.2547\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9254    0.6102    0.7354      2501\n         1.0     0.1071    0.4875    0.1757       240\n\n    accuracy                         0.5994      2741\n   macro avg     0.5163    0.5488    0.4555      2741\nweighted avg     0.8538    0.5994    0.6864      2741\n\nTest Macro F1: 0.4555486812113318\n\nEpoch 151 | Loss: 1.2570\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9225    0.4810    0.6323      2501\n         1.0     0.0967    0.5792    0.1658       240\n\n    accuracy                         0.4896      2741\n   macro avg     0.5096    0.5301    0.3990      2741\nweighted avg     0.8502    0.4896    0.5915      2741\n\nTest Macro F1: 0.3990490496373209\n\nEpoch 152 | Loss: 1.2552\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9229    0.4738    0.6262      2501\n         1.0     0.0968    0.5875    0.1662       240\n\n    accuracy                         0.4838      2741\n   macro avg     0.5098    0.5307    0.3962      2741\nweighted avg     0.8506    0.4838    0.5859      2741\n\nTest Macro F1: 0.3961657412373534\n\nEpoch 153 | Loss: 1.2613\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9231    0.5566    0.6944      2501\n         1.0     0.1006    0.5167    0.1684       240\n\n    accuracy                         0.5531      2741\n   macro avg     0.5118    0.5366    0.4314      2741\nweighted avg     0.8511    0.5531    0.6484      2741\n\nTest Macro F1: 0.4314006994107115\n\nEpoch 154 | Loss: 1.2608\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9223    0.5650    0.7007      2501\n         1.0     0.1001    0.5042    0.1670       240\n\n    accuracy                         0.5596      2741\n   macro avg     0.5112    0.5346    0.4339      2741\nweighted avg     0.8503    0.5596    0.6540      2741\n\nTest Macro F1: 0.43386539996033413\n\nEpoch 155 | Loss: 1.2516\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9238    0.5138    0.6603      2501\n         1.0     0.0993    0.5583    0.1686       240\n\n    accuracy                         0.5177      2741\n   macro avg     0.5115    0.5361    0.4144      2741\nweighted avg     0.8516    0.5177    0.6173      2741\n\nTest Macro F1: 0.4144411694364185\n\nEpoch 156 | Loss: 1.2596\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9227    0.4918    0.6416      2501\n         1.0     0.0973    0.5708    0.1663       240\n\n    accuracy                         0.4987      2741\n   macro avg     0.5100    0.5313    0.4039      2741\nweighted avg     0.8505    0.4987    0.6000      2741\n\nTest Macro F1: 0.40394483947916193\n\nEpoch 157 | Loss: 1.2647\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9238    0.5282    0.6721      2501\n         1.0     0.0999    0.5458    0.1689       240\n\n    accuracy                         0.5297      2741\n   macro avg     0.5118    0.5370    0.4205      2741\nweighted avg     0.8516    0.5297    0.6280      2741\n\nTest Macro F1: 0.42050844508126234\n\nEpoch 158 | Loss: 1.2545\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9249    0.5610    0.6984      2501\n         1.0     0.1029    0.5250    0.1721       240\n\n    accuracy                         0.5578      2741\n   macro avg     0.5139    0.5430    0.4352      2741\nweighted avg     0.8529    0.5578    0.6523      2741\n\nTest Macro F1: 0.43524426963908314\n\nEpoch 159 | Loss: 1.2504\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9260    0.5758    0.7101      2501\n         1.0     0.1054    0.5208    0.1753       240\n\n    accuracy                         0.5710      2741\n   macro avg     0.5157    0.5483    0.4427      2741\nweighted avg     0.8542    0.5710    0.6632      2741\n\nTest Macro F1: 0.44268736981003676\n\nEpoch 160 | Loss: 1.2541\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9252    0.5790    0.7122      2501\n         1.0     0.1046    0.5125    0.1737       240\n\n    accuracy                         0.5731      2741\n   macro avg     0.5149    0.5457    0.4430      2741\nweighted avg     0.8534    0.5731    0.6651      2741\n\nTest Macro F1: 0.4429883615263408\n\nEpoch 161 | Loss: 1.2526\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9262    0.5522    0.6919      2501\n         1.0     0.1040    0.5417    0.1745       240\n\n    accuracy                         0.5513      2741\n   macro avg     0.5151    0.5469    0.4332      2741\nweighted avg     0.8542    0.5513    0.6466      2741\n\nTest Macro F1: 0.43319020591518603\n\nEpoch 162 | Loss: 1.2490\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9265    0.5342    0.6777      2501\n         1.0     0.1032    0.5583    0.1741       240\n\n    accuracy                         0.5363      2741\n   macro avg     0.5148    0.5463    0.4259      2741\nweighted avg     0.8544    0.5363    0.6336      2741\n\nTest Macro F1: 0.42589782898836026\n\nEpoch 163 | Loss: 1.2550\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9258    0.5486    0.6889      2501\n         1.0     0.1033    0.5417    0.1734       240\n\n    accuracy                         0.5480      2741\n   macro avg     0.5145    0.5451    0.4312      2741\nweighted avg     0.8538    0.5480    0.6438      2741\n\nTest Macro F1: 0.43118845486915125\n\nEpoch 164 | Loss: 1.2478\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9249    0.5218    0.6672      2501\n         1.0     0.1008    0.5583    0.1707       240\n\n    accuracy                         0.5250      2741\n   macro avg     0.5128    0.5401    0.4189      2741\nweighted avg     0.8527    0.5250    0.6237      2741\n\nTest Macro F1: 0.41893927552655225\n\nEpoch 165 | Loss: 1.2502\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9239    0.5194    0.6650      2501\n         1.0     0.0996    0.5542    0.1689       240\n\n    accuracy                         0.5224      2741\n   macro avg     0.5118    0.5368    0.4169      2741\nweighted avg     0.8517    0.5224    0.6215      2741\n\nTest Macro F1: 0.41692460825299316\n\nEpoch 166 | Loss: 1.2501\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9244    0.5770    0.7105      2501\n         1.0     0.1034    0.5083    0.1718       240\n\n    accuracy                         0.5710      2741\n   macro avg     0.5139    0.5427    0.4412      2741\nweighted avg     0.8525    0.5710    0.6633      2741\n\nTest Macro F1: 0.44115921526203006\n\nEpoch 167 | Loss: 1.2471\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9234    0.5978    0.7257      2501\n         1.0     0.1034    0.4833    0.1703       240\n\n    accuracy                         0.5877      2741\n   macro avg     0.5134    0.5405    0.4480      2741\nweighted avg     0.8516    0.5877    0.6771      2741\n\nTest Macro F1: 0.4480329469797414\n\nEpoch 168 | Loss: 1.2581\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9224    0.4990    0.6476      2501\n         1.0     0.0973    0.5625    0.1658       240\n\n    accuracy                         0.5046      2741\n   macro avg     0.5098    0.5308    0.4067      2741\nweighted avg     0.8501    0.5046    0.6055      2741\n\nTest Macro F1: 0.40674324133068296\n\nEpoch 169 | Loss: 1.2530\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9230    0.5174    0.6631      2501\n         1.0     0.0986    0.5500    0.1672       240\n\n    accuracy                         0.5202      2741\n   macro avg     0.5108    0.5337    0.4151      2741\nweighted avg     0.8508    0.5202    0.6197      2741\n\nTest Macro F1: 0.41513705457405414\n\nEpoch 170 | Loss: 1.2457\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9261    0.5662    0.7027      2501\n         1.0     0.1048    0.5292    0.1749       240\n\n    accuracy                         0.5629      2741\n   macro avg     0.5154    0.5477    0.4388      2741\nweighted avg     0.8542    0.5629    0.6565      2741\n\nTest Macro F1: 0.43883032900628216\n\nEpoch 171 | Loss: 1.2498\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9222    0.6449    0.7591      2501\n         1.0     0.1048    0.4333    0.1688       240\n\n    accuracy                         0.6264      2741\n   macro avg     0.5135    0.5391    0.4639      2741\nweighted avg     0.8507    0.6264    0.7074      2741\n\nTest Macro F1: 0.4639449961802903\n\nEpoch 172 | Loss: 1.2436\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9233    0.6206    0.7422      2501\n         1.0     0.1047    0.4625    0.1708       240\n\n    accuracy                         0.6067      2741\n   macro avg     0.5140    0.5415    0.4565      2741\nweighted avg     0.8516    0.6067    0.6922      2741\n\nTest Macro F1: 0.4564989147629033\n\nEpoch 173 | Loss: 1.2471\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9228    0.4542    0.6088      2501\n         1.0     0.0960    0.6042    0.1657       240\n\n    accuracy                         0.4673      2741\n   macro avg     0.5094    0.5292    0.3873      2741\nweighted avg     0.8504    0.4673    0.5700      2741\n\nTest Macro F1: 0.3872515694380646\n\nEpoch 174 | Loss: 1.2425\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9228    0.4542    0.6088      2501\n         1.0     0.0960    0.6042    0.1657       240\n\n    accuracy                         0.4673      2741\n   macro avg     0.5094    0.5292    0.3873      2741\nweighted avg     0.8504    0.4673    0.5700      2741\n\nTest Macro F1: 0.3872515694380646\n\nEpoch 175 | Loss: 1.2475\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9211    0.6397    0.7551      2501\n         1.0     0.1026    0.4292    0.1656       240\n\n    accuracy                         0.6213      2741\n   macro avg     0.5119    0.5345    0.4603      2741\nweighted avg     0.8495    0.6213    0.7035      2741\n\nTest Macro F1: 0.46033400150832543\n\nEpoch 176 | Loss: 1.2425\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9200    0.6945    0.7915      2501\n         1.0     0.1043    0.3708    0.1629       240\n\n    accuracy                         0.6662      2741\n   macro avg     0.5122    0.5327    0.4772      2741\nweighted avg     0.8486    0.6662    0.7365      2741\n\nTest Macro F1: 0.47718939701411894\n\nEpoch 177 | Loss: 1.2567\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9221    0.5014    0.6496      2501\n         1.0     0.0970    0.5583    0.1653       240\n\n    accuracy                         0.5064      2741\n   macro avg     0.5095    0.5299    0.4075      2741\nweighted avg     0.8498    0.5064    0.6072      2741\n\nTest Macro F1: 0.4074513463779349\n\nEpoch 178 | Loss: 1.2425\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9242    0.4094    0.5675      2501\n         1.0     0.0955    0.6500    0.1666       240\n\n    accuracy                         0.4305      2741\n   macro avg     0.5099    0.5297    0.3670      2741\nweighted avg     0.8516    0.4305    0.5324      2741\n\nTest Macro F1: 0.36702394810860967\n\nEpoch 179 | Loss: 1.2430\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9219    0.5378    0.6793      2501\n         1.0     0.0983    0.5250    0.1656       240\n\n    accuracy                         0.5367      2741\n   macro avg     0.5101    0.5314    0.4224      2741\nweighted avg     0.8498    0.5367    0.6343      2741\n\nTest Macro F1: 0.4224322727936394\n\nEpoch 180 | Loss: 1.2491\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9189    0.6977    0.7932      2501\n         1.0     0.1021    0.3583    0.1590       240\n\n    accuracy                         0.6680      2741\n   macro avg     0.5105    0.5280    0.4761      2741\nweighted avg     0.8474    0.6680    0.7377      2741\n\nTest Macro F1: 0.47607334901697196\n\nEpoch 181 | Loss: 1.2369\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9185    0.7033    0.7966      2501\n         1.0     0.1017    0.3500    0.1576       240\n\n    accuracy                         0.6724      2741\n   macro avg     0.5101    0.5267    0.4771      2741\nweighted avg     0.8470    0.6724    0.7407      2741\n\nTest Macro F1: 0.47712352489327564\n\nEpoch 182 | Loss: 1.2488\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9230    0.5274    0.6712      2501\n         1.0     0.0991    0.5417    0.1675       240\n\n    accuracy                         0.5286      2741\n   macro avg     0.5111    0.5345    0.4194      2741\nweighted avg     0.8509    0.5286    0.6271      2741\n\nTest Macro F1: 0.4193862962671494\n\nEpoch 183 | Loss: 1.2461\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9195    0.4290    0.5851      2501\n         1.0     0.0928    0.6083    0.1610       240\n\n    accuracy                         0.4447      2741\n   macro avg     0.5061    0.5187    0.3730      2741\nweighted avg     0.8471    0.4447    0.5479      2741\n\nTest Macro F1: 0.373015104861137\n\nEpoch 184 | Loss: 1.2497\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9222    0.4978    0.6466      2501\n         1.0     0.0971    0.5625    0.1655       240\n\n    accuracy                         0.5035      2741\n   macro avg     0.5096    0.5302    0.4061      2741\nweighted avg     0.8500    0.5035    0.6045      2741\n\nTest Macro F1: 0.40606395720668476\n\nEpoch 185 | Loss: 1.2375\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9198    0.6421    0.7563      2501\n         1.0     0.1005    0.4167    0.1619       240\n\n    accuracy                         0.6224      2741\n   macro avg     0.5102    0.5294    0.4591      2741\nweighted avg     0.8481    0.6224    0.7043      2741\n\nTest Macro F1: 0.45912094176503726\n\nEpoch 186 | Loss: 1.2379\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9197    0.6773    0.7801      2501\n         1.0     0.1023    0.3833    0.1615       240\n\n    accuracy                         0.6516      2741\n   macro avg     0.5110    0.5303    0.4708      2741\nweighted avg     0.8481    0.6516    0.7259      2741\n\nTest Macro F1: 0.4708255663347334\n\nEpoch 187 | Loss: 1.2362\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9212    0.5702    0.7044      2501\n         1.0     0.0989    0.4917    0.1647       240\n\n    accuracy                         0.5633      2741\n   macro avg     0.5100    0.5309    0.4345      2741\nweighted avg     0.8492    0.5633    0.6571      2741\n\nTest Macro F1: 0.4345304562032065\n\nEpoch 188 | Loss: 1.2426\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9219    0.4722    0.6245      2501\n         1.0     0.0959    0.5833    0.1647       240\n\n    accuracy                         0.4819      2741\n   macro avg     0.5089    0.5278    0.3946      2741\nweighted avg     0.8496    0.4819    0.5843      2741\n\nTest Macro F1: 0.39462158210719506\n\nEpoch 189 | Loss: 1.2319\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9225    0.4806    0.6320      2501\n         1.0     0.0967    0.5792    0.1657       240\n\n    accuracy                         0.4892      2741\n   macro avg     0.5096    0.5299    0.3988      2741\nweighted avg     0.8502    0.4892    0.5911      2741\n\nTest Macro F1: 0.3988198859741142\n\nEpoch 190 | Loss: 1.2477\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9230    0.5562    0.6941      2501\n         1.0     0.1005    0.5167    0.1682       240\n\n    accuracy                         0.5527      2741\n   macro avg     0.5118    0.5364    0.4312      2741\nweighted avg     0.8510    0.5527    0.6481      2741\n\nTest Macro F1: 0.43118071861704\n\nEpoch 191 | Loss: 1.2365\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9192    0.6273    0.7457      2501\n         1.0     0.0986    0.4250    0.1601       240\n\n    accuracy                         0.6096      2741\n   macro avg     0.5089    0.5262    0.4529      2741\nweighted avg     0.8473    0.6096    0.6944      2741\n\nTest Macro F1: 0.45292401107854663\n\nEpoch 192 | Loss: 1.2426\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9200    0.5978    0.7247      2501\n         1.0     0.0986    0.4583    0.1622       240\n\n    accuracy                         0.5856      2741\n   macro avg     0.5093    0.5280    0.4435      2741\nweighted avg     0.8481    0.5856    0.6754      2741\n\nTest Macro F1: 0.44345734724897296\n\nEpoch 193 | Loss: 1.2474\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9254    0.5358    0.6787      2501\n         1.0     0.1021    0.5500    0.1722       240\n\n    accuracy                         0.5370      2741\n   macro avg     0.5138    0.5429    0.4254      2741\nweighted avg     0.8533    0.5370    0.6343      2741\n\nTest Macro F1: 0.4254320868965811\n\nEpoch 194 | Loss: 1.2429\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9249    0.5270    0.6714      2501\n         1.0     0.1011    0.5542    0.1710       240\n\n    accuracy                         0.5294      2741\n   macro avg     0.5130    0.5406    0.4212      2741\nweighted avg     0.8528    0.5294    0.6276      2741\n\nTest Macro F1: 0.4211862253750947\n\nEpoch 195 | Loss: 1.2473\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9236    0.5754    0.7090      2501\n         1.0     0.1023    0.5042    0.1701       240\n\n    accuracy                         0.5691      2741\n   macro avg     0.5130    0.5398    0.4396      2741\nweighted avg     0.8517    0.5691    0.6618      2741\n\nTest Macro F1: 0.439552441266443\n\nEpoch 196 | Loss: 1.2446\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9190    0.6218    0.7417      2501\n         1.0     0.0982    0.4292    0.1598       240\n\n    accuracy                         0.6049      2741\n   macro avg     0.5086    0.5255    0.4508      2741\nweighted avg     0.8472    0.6049    0.6908      2741\n\nTest Macro F1: 0.4507630934634306\n\nEpoch 197 | Loss: 1.2477\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9204    0.5594    0.6958      2501\n         1.0     0.0975    0.4958    0.1629       240\n\n    accuracy                         0.5538      2741\n   macro avg     0.5089    0.5276    0.4294      2741\nweighted avg     0.8483    0.5538    0.6492      2741\n\nTest Macro F1: 0.42937446305595145\n\nEpoch 198 | Loss: 1.2414\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9215    0.5114    0.6578      2501\n         1.0     0.0968    0.5458    0.1645       240\n\n    accuracy                         0.5144      2741\n   macro avg     0.5091    0.5286    0.4111      2741\nweighted avg     0.8493    0.5144    0.6146      2741\n\nTest Macro F1: 0.41111109496952225\n\nEpoch 199 | Loss: 1.2373\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9175    0.5558    0.6922      2501\n         1.0     0.0938    0.4792    0.1569       240\n\n    accuracy                         0.5491      2741\n   macro avg     0.5056    0.5175    0.4246      2741\nweighted avg     0.8454    0.5491    0.6454      2741\n\nTest Macro F1: 0.42456028546115676\n\nEpoch 200 | Loss: 1.2388\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9160    0.6321    0.7480      2501\n         1.0     0.0936    0.3958    0.1514       240\n\n    accuracy                         0.6115      2741\n   macro avg     0.5048    0.5140    0.4497      2741\nweighted avg     0.8440    0.6115    0.6958      2741\n\nTest Macro F1: 0.4497213417444487\n\nEpoch 201 | Loss: 1.2364\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9161    0.5546    0.6909      2501\n         1.0     0.0921    0.4708    0.1541       240\n\n    accuracy                         0.5472      2741\n   macro avg     0.5041    0.5127    0.4225      2741\nweighted avg     0.8440    0.5472    0.6439      2741\n\nTest Macro F1: 0.42248249364813784\n\nEpoch 202 | Loss: 1.2510\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9201    0.4606    0.6139      2501\n         1.0     0.0940    0.5833    0.1619       240\n\n    accuracy                         0.4714      2741\n   macro avg     0.5071    0.5220    0.3879      2741\nweighted avg     0.8478    0.4714    0.5743      2741\n\nTest Macro F1: 0.38792609636986763\n\nEpoch 203 | Loss: 1.2324\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9166    0.5446    0.6832      2501\n         1.0     0.0924    0.4833    0.1552       240\n\n    accuracy                         0.5392      2741\n   macro avg     0.5045    0.5140    0.4192      2741\nweighted avg     0.8444    0.5392    0.6370      2741\n\nTest Macro F1: 0.41920220650223594\n\nEpoch 204 | Loss: 1.2354\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9188    0.6745    0.7780      2501\n         1.0     0.1006    0.3792    0.1590       240\n\n    accuracy                         0.6487      2741\n   macro avg     0.5097    0.5268    0.4685      2741\nweighted avg     0.8472    0.6487    0.7238      2741\n\nTest Macro F1: 0.46845453913869994\n\nEpoch 205 | Loss: 1.2407\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9189    0.6521    0.7629      2501\n         1.0     0.0994    0.4000    0.1592       240\n\n    accuracy                         0.6301      2741\n   macro avg     0.5091    0.5261    0.4610      2741\nweighted avg     0.8471    0.6301    0.7100      2741\n\nTest Macro F1: 0.46103323420316555\n\nEpoch 206 | Loss: 1.2358\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9222    0.5306    0.6736      2501\n         1.0     0.0983    0.5333    0.1660       240\n\n    accuracy                         0.5308      2741\n   macro avg     0.5102    0.5320    0.4198      2741\nweighted avg     0.8500    0.5308    0.6292      2741\n\nTest Macro F1: 0.4198111095748813\n\nEpoch 207 | Loss: 1.2454\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9209    0.4750    0.6267      2501\n         1.0     0.0951    0.5750    0.1632       240\n\n    accuracy                         0.4838      2741\n   macro avg     0.5080    0.5250    0.3950      2741\nweighted avg     0.8486    0.4838    0.5862      2741\n\nTest Macro F1: 0.39498229567647614\n\nEpoch 208 | Loss: 1.2379\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9238    0.5670    0.7027      2501\n         1.0     0.1020    0.5125    0.1701       240\n\n    accuracy                         0.5622      2741\n   macro avg     0.5129    0.5397    0.4364      2741\nweighted avg     0.8518    0.5622    0.6560      2741\n\nTest Macro F1: 0.4364001990385288\n\nEpoch 209 | Loss: 1.2323\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9208    0.6925    0.7905      2501\n         1.0     0.1058    0.3792    0.1655       240\n\n    accuracy                         0.6651      2741\n   macro avg     0.5133    0.5358    0.4780      2741\nweighted avg     0.8494    0.6651    0.7358      2741\n\nTest Macro F1: 0.4779805817186008\n\nEpoch 210 | Loss: 1.2442\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9206    0.6441    0.7579      2501\n         1.0     0.1019    0.4208    0.1641       240\n\n    accuracy                         0.6246      2741\n   macro avg     0.5112    0.5325    0.4610      2741\nweighted avg     0.8489    0.6246    0.7059      2741\n\nTest Macro F1: 0.4610167703647309\n\nEpoch 211 | Loss: 1.2339\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9257    0.5730    0.7078      2501\n         1.0     0.1048    0.5208    0.1745       240\n\n    accuracy                         0.5684      2741\n   macro avg     0.5152    0.5469    0.4411      2741\nweighted avg     0.8538    0.5684    0.6611      2741\n\nTest Macro F1: 0.44114413507802275\n\nEpoch 212 | Loss: 1.2359\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9239    0.6070    0.7326      2501\n         1.0     0.1047    0.4792    0.1719       240\n\n    accuracy                         0.5958      2741\n   macro avg     0.5143    0.5431    0.4523      2741\nweighted avg     0.8522    0.5958    0.6835      2741\n\nTest Macro F1: 0.4522619191901703\n\nEpoch 213 | Loss: 1.2363\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9176    0.6769    0.7791      2501\n         1.0     0.0982    0.3667    0.1549       240\n\n    accuracy                         0.6498      2741\n   macro avg     0.5079    0.5218    0.4670      2741\nweighted avg     0.8459    0.6498    0.7245      2741\n\nTest Macro F1: 0.4670184012496516\n\nEpoch 214 | Loss: 1.2352\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9172    0.6689    0.7736      2501\n         1.0     0.0971    0.3708    0.1538       240\n\n    accuracy                         0.6428      2741\n   macro avg     0.5071    0.5199    0.4637      2741\nweighted avg     0.8454    0.6428    0.7194      2741\n\nTest Macro F1: 0.46374388617163187\n\nEpoch 215 | Loss: 1.2364\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9228    0.5782    0.7109      2501\n         1.0     0.1014    0.4958    0.1683       240\n\n    accuracy                         0.5710      2741\n   macro avg     0.5121    0.5370    0.4396      2741\nweighted avg     0.8509    0.5710    0.6634      2741\n\nTest Macro F1: 0.43961564298022715\n\nEpoch 216 | Loss: 1.2222\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9221    0.5298    0.6729      2501\n         1.0     0.0982    0.5333    0.1658       240\n\n    accuracy                         0.5301      2741\n   macro avg     0.5101    0.5316    0.4194      2741\nweighted avg     0.8499    0.5301    0.6285      2741\n\nTest Macro F1: 0.41936676517103183\n\nEpoch 217 | Loss: 1.2386\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9219    0.5762    0.7092      2501\n         1.0     0.1002    0.4917    0.1664       240\n\n    accuracy                         0.5688      2741\n   macro avg     0.5111    0.5339    0.4378      2741\nweighted avg     0.8500    0.5688    0.6616      2741\n\nTest Macro F1: 0.4377925685505814\n\nEpoch 218 | Loss: 1.2303\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9229    0.6653    0.7732      2501\n         1.0     0.1077    0.4208    0.1715       240\n\n    accuracy                         0.6439      2741\n   macro avg     0.5153    0.5431    0.4724      2741\nweighted avg     0.8515    0.6439    0.7205      2741\n\nTest Macro F1: 0.47235564026987964\n\nEpoch 219 | Loss: 1.2360\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9205    0.7177    0.8066      2501\n         1.0     0.1075    0.3542    0.1649       240\n\n    accuracy                         0.6859      2741\n   macro avg     0.5140    0.5359    0.4857      2741\nweighted avg     0.8493    0.6859    0.7504      2741\n\nTest Macro F1: 0.48572439066537865\n\nEpoch 220 | Loss: 1.2325\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9225    0.6665    0.7739      2501\n         1.0     0.1071    0.4167    0.1704       240\n\n    accuracy                         0.6447      2741\n   macro avg     0.5148    0.5416    0.4721      2741\nweighted avg     0.8511    0.6447    0.7211      2741\n\nTest Macro F1: 0.47213337888860946\n\nEpoch 221 | Loss: 1.2353\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9237    0.5958    0.7244      2501\n         1.0     0.1037    0.4875    0.1711       240\n\n    accuracy                         0.5863      2741\n   macro avg     0.5137    0.5416    0.4477      2741\nweighted avg     0.8519    0.5863    0.6759      2741\n\nTest Macro F1: 0.44770424481232246\n\nEpoch 222 | Loss: 1.2283\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9220    0.6142    0.7372      2501\n         1.0     0.1023    0.4583    0.1673       240\n\n    accuracy                         0.6005      2741\n   macro avg     0.5121    0.5362    0.4523      2741\nweighted avg     0.8502    0.6005    0.6873      2741\n\nTest Macro F1: 0.45226070127317575\n\nEpoch 223 | Loss: 1.2338\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9245    0.6953    0.7937      2501\n         1.0     0.1140    0.4083    0.1782       240\n\n    accuracy                         0.6702      2741\n   macro avg     0.5192    0.5518    0.4859      2741\nweighted avg     0.8535    0.6702    0.7398      2741\n\nTest Macro F1: 0.4859416621716941\n\nEpoch 224 | Loss: 1.2276\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9208    0.7249    0.8112      2501\n         1.0     0.1088    0.3500    0.1660       240\n\n    accuracy                         0.6921      2741\n   macro avg     0.5148    0.5375    0.4886      2741\nweighted avg     0.8497    0.6921    0.7547      2741\n\nTest Macro F1: 0.488596793732481\n\nEpoch 225 | Loss: 1.2276\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9216    0.6769    0.7805      2501\n         1.0     0.1062    0.4000    0.1678       240\n\n    accuracy                         0.6527      2741\n   macro avg     0.5139    0.5385    0.4742      2741\nweighted avg     0.8502    0.6527    0.7269      2741\n\nTest Macro F1: 0.47418809866942646\n\nEpoch 226 | Loss: 1.2285\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9203    0.6417    0.7562      2501\n         1.0     0.1013    0.4208    0.1633       240\n\n    accuracy                         0.6224      2741\n   macro avg     0.5108    0.5313    0.4597      2741\nweighted avg     0.8486    0.6224    0.7043      2741\n\nTest Macro F1: 0.45974102396371025\n\nEpoch 227 | Loss: 1.2304\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9213    0.7489    0.8262      2501\n         1.0     0.1130    0.3333    0.1688       240\n\n    accuracy                         0.7125      2741\n   macro avg     0.5171    0.5411    0.4975      2741\nweighted avg     0.8505    0.7125    0.7686      2741\n\nTest Macro F1: 0.4974892002106913\n\nEpoch 228 | Loss: 1.2425\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9205    0.7357    0.8178      2501\n         1.0     0.1092    0.3375    0.1650       240\n\n    accuracy                         0.7008      2741\n   macro avg     0.5148    0.5366    0.4914      2741\nweighted avg     0.8494    0.7008    0.7606      2741\n\nTest Macro F1: 0.4913736139398054\n\nEpoch 229 | Loss: 1.2345\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9206    0.6305    0.7485      2501\n         1.0     0.1012    0.4333    0.1640       240\n\n    accuracy                         0.6133      2741\n   macro avg     0.5109    0.5319    0.4562      2741\nweighted avg     0.8489    0.6133    0.6973      2741\n\nTest Macro F1: 0.45624768871674565\n\nEpoch 230 | Loss: 1.2297\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9199    0.5698    0.7037      2501\n         1.0     0.0973    0.4833    0.1620       240\n\n    accuracy                         0.5622      2741\n   macro avg     0.5086    0.5266    0.4329      2741\nweighted avg     0.8479    0.5622    0.6563      2741\n\nTest Macro F1: 0.4328574384440306\n\nEpoch 231 | Loss: 1.2232\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9226    0.7101    0.8025      2501\n         1.0     0.1115    0.3792    0.1723       240\n\n    accuracy                         0.6811      2741\n   macro avg     0.5171    0.5446    0.4874      2741\nweighted avg     0.8516    0.6811    0.7474      2741\n\nTest Macro F1: 0.4874394932150242\n\nEpoch 232 | Loss: 1.2272\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9223    0.7213    0.8095      2501\n         1.0     0.1121    0.3667    0.1717       240\n\n    accuracy                         0.6903      2741\n   macro avg     0.5172    0.5440    0.4906      2741\nweighted avg     0.8514    0.6903    0.7537      2741\n\nTest Macro F1: 0.49061022124692866\n\nEpoch 233 | Loss: 1.2320\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9195    0.5798    0.7111      2501\n         1.0     0.0971    0.4708    0.1610       240\n\n    accuracy                         0.5702      2741\n   macro avg     0.5083    0.5253    0.4361      2741\nweighted avg     0.8475    0.5702    0.6630      2741\n\nTest Macro F1: 0.43605078462851876\n\nEpoch 234 | Loss: 1.2218\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9174    0.5150    0.6597      2501\n         1.0     0.0927    0.5167    0.1573       240\n\n    accuracy                         0.5151      2741\n   macro avg     0.5051    0.5158    0.4085      2741\nweighted avg     0.8452    0.5151    0.6157      2741\n\nTest Macro F1: 0.4084638574515056\n\nEpoch 235 | Loss: 1.2224\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9193    0.6509    0.7622      2501\n         1.0     0.1000    0.4042    0.1603       240\n\n    accuracy                         0.6293      2741\n   macro avg     0.5096    0.5276    0.4613      2741\nweighted avg     0.8475    0.6293    0.7095      2741\n\nTest Macro F1: 0.46125143157829573\n\nEpoch 236 | Loss: 1.2179\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9164    0.7933    0.8504      2501\n         1.0     0.1024    0.2458    0.1446       240\n\n    accuracy                         0.7453      2741\n   macro avg     0.5094    0.5196    0.4975      2741\nweighted avg     0.8451    0.7453    0.7886      2741\n\nTest Macro F1: 0.49750752208298665\n\nEpoch 237 | Loss: 1.2304\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9186    0.6493    0.7608      2501\n         1.0     0.0987    0.4000    0.1583       240\n\n    accuracy                         0.6275      2741\n   macro avg     0.5086    0.5247    0.4596      2741\nweighted avg     0.8468    0.6275    0.7081      2741\n\nTest Macro F1: 0.4595595810746274\n\nEpoch 238 | Loss: 1.2256\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9179    0.6034    0.7281      2501\n         1.0     0.0957    0.4375    0.1571       240\n\n    accuracy                         0.5888      2741\n   macro avg     0.5068    0.5204    0.4426      2741\nweighted avg     0.8459    0.5888    0.6781      2741\n\nTest Macro F1: 0.44258710740878743\n\nEpoch 239 | Loss: 1.2190\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9190    0.6261    0.7448      2501\n         1.0     0.0984    0.4250    0.1597       240\n\n    accuracy                         0.6085      2741\n   macro avg     0.5087    0.5256    0.4523      2741\nweighted avg     0.8472    0.6085    0.6936      2741\n\nTest Macro F1: 0.4522884994464397\n\nEpoch 240 | Loss: 1.2157\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9180    0.7385    0.8185      2501\n         1.0     0.1029    0.3125    0.1548       240\n\n    accuracy                         0.7012      2741\n   macro avg     0.5104    0.5255    0.4867      2741\nweighted avg     0.8466    0.7012    0.7604      2741\n\nTest Macro F1: 0.48666151242471867\n\nEpoch 241 | Loss: 1.2209\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9195    0.6489    0.7609      2501\n         1.0     0.1004    0.4083    0.1612       240\n\n    accuracy                         0.6279      2741\n   macro avg     0.5100    0.5286    0.4610      2741\nweighted avg     0.8478    0.6279    0.7084      2741\n\nTest Macro F1: 0.4610421755866459\n\nEpoch 242 | Loss: 1.2222\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9203    0.5174    0.6624      2501\n         1.0     0.0959    0.5333    0.1625       240\n\n    accuracy                         0.5188      2741\n   macro avg     0.5081    0.5254    0.4125      2741\nweighted avg     0.8482    0.5188    0.6186      2741\n\nTest Macro F1: 0.4124702507912132\n\nEpoch 243 | Loss: 1.2285\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9200    0.5290    0.6717      2501\n         1.0     0.0959    0.5208    0.1620       240\n\n    accuracy                         0.5283      2741\n   macro avg     0.5080    0.5249    0.4169      2741\nweighted avg     0.8479    0.5283    0.6271      2741\n\nTest Macro F1: 0.4168830662417157\n\nEpoch 244 | Loss: 1.2331\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9215    0.6293    0.7479      2501\n         1.0     0.1026    0.4417    0.1665       240\n\n    accuracy                         0.6129      2741\n   macro avg     0.5121    0.5355    0.4572      2741\nweighted avg     0.8498    0.6129    0.6970      2741\n\nTest Macro F1: 0.4572284318737184\n\nEpoch 245 | Loss: 1.2222\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9188    0.7013    0.7955      2501\n         1.0     0.1022    0.3542    0.1586       240\n\n    accuracy                         0.6709      2741\n   macro avg     0.5105    0.5277    0.4770      2741\nweighted avg     0.8473    0.6709    0.7397      2741\n\nTest Macro F1: 0.47702347107997434\n\nEpoch 246 | Loss: 1.2238\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9211    0.6625    0.7707      2501\n         1.0     0.1040    0.4083    0.1658       240\n\n    accuracy                         0.6403      2741\n   macro avg     0.5126    0.5354    0.4683      2741\nweighted avg     0.8495    0.6403    0.7177      2741\n\nTest Macro F1: 0.468259158698304\n\nEpoch 247 | Loss: 1.2286\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9255    0.4966    0.6464      2501\n         1.0     0.1001    0.5833    0.1708       240\n\n    accuracy                         0.5042      2741\n   macro avg     0.5128    0.5400    0.4086      2741\nweighted avg     0.8532    0.5042    0.6047      2741\n\nTest Macro F1: 0.4086029494765329\n\nEpoch 248 | Loss: 1.2273\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9263    0.5178    0.6643      2501\n         1.0     0.1020    0.5708    0.1731       240\n\n    accuracy                         0.5224      2741\n   macro avg     0.5142    0.5443    0.4187      2741\nweighted avg     0.8541    0.5224    0.6213      2741\n\nTest Macro F1: 0.41868098093409434\n\nEpoch 249 | Loss: 1.2241\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9178    0.7237    0.8093      2501\n         1.0     0.1014    0.3250    0.1546       240\n\n    accuracy                         0.6888      2741\n   macro avg     0.5096    0.5244    0.4820      2741\nweighted avg     0.8464    0.6888    0.7520      2741\n\nTest Macro F1: 0.4819543846051753\n\nEpoch 250 | Loss: 1.2212\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9178    0.7589    0.8308      2501\n         1.0     0.1040    0.2917    0.1533       240\n\n    accuracy                         0.7180      2741\n   macro avg     0.5109    0.5253    0.4921      2741\nweighted avg     0.8465    0.7180    0.7715      2741\n\nTest Macro F1: 0.49207850323277225\n\nEpoch 251 | Loss: 1.2274\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9199    0.6425    0.7566      2501\n         1.0     0.1006    0.4167    0.1621       240\n\n    accuracy                         0.6228      2741\n   macro avg     0.5102    0.5296    0.4593      2741\nweighted avg     0.8481    0.6228    0.7045      2741\n\nTest Macro F1: 0.4593329456973937\n\nEpoch 252 | Loss: 1.2234\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9234    0.6070    0.7324      2501\n         1.0     0.1039    0.4750    0.1705       240\n\n    accuracy                         0.5954      2741\n   macro avg     0.5136    0.5410    0.4515      2741\nweighted avg     0.8516    0.5954    0.6832      2741\n\nTest Macro F1: 0.45148988652736943\n\nEpoch 253 | Loss: 1.2201\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9195    0.7309    0.8144      2501\n         1.0     0.1062    0.3333    0.1611       240\n\n    accuracy                         0.6961      2741\n   macro avg     0.5129    0.5321    0.4878      2741\nweighted avg     0.8483    0.6961    0.7572      2741\n\nTest Macro F1: 0.48778159076107935\n\nEpoch 254 | Loss: 1.2166\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9174    0.7857    0.8464      2501\n         1.0     0.1052    0.2625    0.1502       240\n\n    accuracy                         0.7399      2741\n   macro avg     0.5113    0.5241    0.4983      2741\nweighted avg     0.8463    0.7399    0.7855      2741\n\nTest Macro F1: 0.49830713927973386\n\nEpoch 255 | Loss: 1.2271\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9223    0.6405    0.7560      2501\n         1.0     0.1046    0.4375    0.1688       240\n\n    accuracy                         0.6228      2741\n   macro avg     0.5134    0.5390    0.4624      2741\nweighted avg     0.8507    0.6228    0.7046      2741\n\nTest Macro F1: 0.46241363926744544\n\nEpoch 256 | Loss: 1.2064\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9192    0.5278    0.6706      2501\n         1.0     0.0950    0.5167    0.1605       240\n\n    accuracy                         0.5268      2741\n   macro avg     0.5071    0.5222    0.4155      2741\nweighted avg     0.8471    0.5268    0.6259      2741\n\nTest Macro F1: 0.41553957023771654\n\nEpoch 257 | Loss: 1.2127\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9199    0.6014    0.7273      2501\n         1.0     0.0986    0.4542    0.1620       240\n\n    accuracy                         0.5885      2741\n   macro avg     0.5092    0.5278    0.4446      2741\nweighted avg     0.8480    0.5885    0.6778      2741\n\nTest Macro F1: 0.44461704714305017\n\nEpoch 258 | Loss: 1.2201\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9232    0.6633    0.7720      2501\n         1.0     0.1081    0.4250    0.1723       240\n\n    accuracy                         0.6425      2741\n   macro avg     0.5156    0.5442    0.4721      2741\nweighted avg     0.8518    0.6425    0.7195      2741\n\nTest Macro F1: 0.4721421339906682\n\nEpoch 259 | Loss: 1.2168\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9207    0.6265    0.7457      2501\n         1.0     0.1011    0.4375    0.1642       240\n\n    accuracy                         0.6100      2741\n   macro avg     0.5109    0.5320    0.4549      2741\nweighted avg     0.8489    0.6100    0.6947      2741\n\nTest Macro F1: 0.45492431873655165\n\nEpoch 260 | Loss: 1.2171\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9189    0.5798    0.7110      2501\n         1.0     0.0963    0.4667    0.1597       240\n\n    accuracy                         0.5699      2741\n   macro avg     0.5076    0.5232    0.4353      2741\nweighted avg     0.8469    0.5699    0.6627      2741\n\nTest Macro F1: 0.4353082221282906\n\nEpoch 261 | Loss: 1.2194\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9203    0.6921    0.7901      2501\n         1.0     0.1047    0.3750    0.1636       240\n\n    accuracy                         0.6644      2741\n   macro avg     0.5125    0.5336    0.4768      2741\nweighted avg     0.8488    0.6644    0.7352      2741\n\nTest Macro F1: 0.4768432845110161\n\nEpoch 262 | Loss: 1.2261\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9204    0.6793    0.7817      2501\n         1.0     0.1039    0.3875    0.1639       240\n\n    accuracy                         0.6538      2741\n   macro avg     0.5121    0.5334    0.4728      2741\nweighted avg     0.8489    0.6538    0.7276      2741\n\nTest Macro F1: 0.4727825864006672\n\nEpoch 263 | Loss: 1.2205\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9200    0.6665    0.7730      2501\n         1.0     0.1023    0.3958    0.1625       240\n\n    accuracy                         0.6428      2741\n   macro avg     0.5111    0.5312    0.4678      2741\nweighted avg     0.8484    0.6428    0.7196      2741\n\nTest Macro F1: 0.4677719517078592\n\nEpoch 264 | Loss: 1.2249\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9183    0.7553    0.8289      2501\n         1.0     0.1053    0.3000    0.1558       240\n\n    accuracy                         0.7154      2741\n   macro avg     0.5118    0.5276    0.4924      2741\nweighted avg     0.8471    0.7154    0.7699      2741\n\nTest Macro F1: 0.49235823413094143\n\nEpoch 265 | Loss: 1.2198\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9208    0.6649    0.7722      2501\n         1.0     0.1037    0.4042    0.1651       240\n\n    accuracy                         0.6421      2741\n   macro avg     0.5123    0.5346    0.4687      2741\nweighted avg     0.8493    0.6421    0.7191      2741\n\nTest Macro F1: 0.4686688172149247\n\nEpoch 266 | Loss: 1.2134\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9208    0.5250    0.6687      2501\n         1.0     0.0966    0.5292    0.1633       240\n\n    accuracy                         0.5254      2741\n   macro avg     0.5087    0.5271    0.4160      2741\nweighted avg     0.8486    0.5254    0.6245      2741\n\nTest Macro F1: 0.4160239483106894\n\nEpoch 267 | Loss: 1.2194\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9187    0.5554    0.6923      2501\n         1.0     0.0952    0.4875    0.1593       240\n\n    accuracy                         0.5494      2741\n   macro avg     0.5069    0.5214    0.4258      2741\nweighted avg     0.8465    0.5494    0.6456      2741\n\nTest Macro F1: 0.42577111114541455\n\nEpoch 268 | Loss: 1.2093\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9212    0.6773    0.7806      2501\n         1.0     0.1053    0.3958    0.1664       240\n\n    accuracy                         0.6527      2741\n   macro avg     0.5132    0.5366    0.4735      2741\nweighted avg     0.8497    0.6527    0.7269      2741\n\nTest Macro F1: 0.47350997118806853\n\nEpoch 269 | Loss: 1.2110\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9209    0.7077    0.8004      2501\n         1.0     0.1074    0.3667    0.1662       240\n\n    accuracy                         0.6779      2741\n   macro avg     0.5142    0.5372    0.4833      2741\nweighted avg     0.8497    0.6779    0.7448      2741\n\nTest Macro F1: 0.48327813427834626\n\nEpoch 270 | Loss: 1.2124\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9205    0.6849    0.7854      2501\n         1.0     0.1045    0.3833    0.1643       240\n\n    accuracy                         0.6585      2741\n   macro avg     0.5125    0.5341    0.4749      2741\nweighted avg     0.8490    0.6585    0.7310      2741\n\nTest Macro F1: 0.47485262330516803\n\nEpoch 271 | Loss: 1.2219\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9191    0.7309    0.8143      2501\n         1.0     0.1051    0.3292    0.1593       240\n\n    accuracy                         0.6957      2741\n   macro avg     0.5121    0.5300    0.4868      2741\nweighted avg     0.8478    0.6957    0.7569      2741\n\nTest Macro F1: 0.4867640455492492\n\nEpoch 272 | Loss: 1.2197\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9189    0.7385    0.8189      2501\n         1.0     0.1053    0.3208    0.1586       240\n\n    accuracy                         0.7019      2741\n   macro avg     0.5121    0.5297    0.4887      2741\nweighted avg     0.8477    0.7019    0.7611      2741\n\nTest Macro F1: 0.4887432733944099\n\nEpoch 273 | Loss: 1.2165\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9199    0.6058    0.7305      2501\n         1.0     0.0987    0.4500    0.1619       240\n\n    accuracy                         0.5921      2741\n   macro avg     0.5093    0.5279    0.4462      2741\nweighted avg     0.8480    0.5921    0.6807      2741\n\nTest Macro F1: 0.44619577867768134\n\nEpoch 274 | Loss: 1.2083\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9214    0.5298    0.6728      2501\n         1.0     0.0975    0.5292    0.1646       240\n\n    accuracy                         0.5297      2741\n   macro avg     0.5094    0.5295    0.4187      2741\nweighted avg     0.8493    0.5297    0.6283      2741\n\nTest Macro F1: 0.4186869856036902\n\nEpoch 275 | Loss: 1.2126\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9214    0.5674    0.7023      2501\n         1.0     0.0991    0.4958    0.1652       240\n\n    accuracy                         0.5611      2741\n   macro avg     0.5103    0.5316    0.4337      2741\nweighted avg     0.8494    0.5611    0.6553      2741\n\nTest Macro F1: 0.4337322458677803\n\nEpoch 276 | Loss: 1.2177\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9201    0.6857    0.7858      2501\n         1.0     0.1038    0.3792    0.1629       240\n\n    accuracy                         0.6589      2741\n   macro avg     0.5119    0.5324    0.4744      2741\nweighted avg     0.8486    0.6589    0.7313      2741\n\nTest Macro F1: 0.47436627113412316\n\nEpoch 277 | Loss: 1.2089\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9188    0.7237    0.8097      2501\n         1.0     0.1038    0.3333    0.1583       240\n\n    accuracy                         0.6895      2741\n   macro avg     0.5113    0.5285    0.4840      2741\nweighted avg     0.8474    0.6895    0.7526      2741\n\nTest Macro F1: 0.4839607086530384\n\nEpoch 278 | Loss: 1.2129\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9197    0.6321    0.7493      2501\n         1.0     0.0998    0.4250    0.1616       240\n\n    accuracy                         0.6140      2741\n   macro avg     0.5098    0.5286    0.4555      2741\nweighted avg     0.8479    0.6140    0.6978      2741\n\nTest Macro F1: 0.4554686385110522\n\nEpoch 279 | Loss: 1.2052\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9222    0.5878    0.7179      2501\n         1.0     0.1011    0.4833    0.1673       240\n\n    accuracy                         0.5786      2741\n   macro avg     0.5117    0.5355    0.4426      2741\nweighted avg     0.8503    0.5786    0.6697      2741\n\nTest Macro F1: 0.44260810086332797\n\nEpoch 280 | Loss: 1.2102\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9171    0.7921    0.8500      2501\n         1.0     0.1050    0.2542    0.1486       240\n\n    accuracy                         0.7450      2741\n   macro avg     0.5111    0.5231    0.4993      2741\nweighted avg     0.8460    0.7450    0.7886      2741\n\nTest Macro F1: 0.4993157255595645\n\nEpoch 281 | Loss: 1.2163\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9152    0.7469    0.8225      2501\n         1.0     0.0957    0.2792    0.1426       240\n\n    accuracy                         0.7059      2741\n   macro avg     0.5055    0.5130    0.4825      2741\nweighted avg     0.8435    0.7059    0.7630      2741\n\nTest Macro F1: 0.48254916289571564\n\nEpoch 282 | Loss: 1.2080\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9187    0.5422    0.6819      2501\n         1.0     0.0949    0.5000    0.1595       240\n\n    accuracy                         0.5385      2741\n   macro avg     0.5068    0.5211    0.4207      2741\nweighted avg     0.8466    0.5385    0.6362      2741\n\nTest Macro F1: 0.4206947422763949\n\nEpoch 283 | Loss: 1.2133\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9191    0.4998    0.6475      2501\n         1.0     0.0941    0.5417    0.1604       240\n\n    accuracy                         0.5035      2741\n   macro avg     0.5066    0.5207    0.4039      2741\nweighted avg     0.8469    0.5035    0.6049      2741\n\nTest Macro F1: 0.4039477327571097\n\nEpoch 284 | Loss: 1.2077\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9192    0.7369    0.8180      2501\n         1.0     0.1060    0.3250    0.1598       240\n\n    accuracy                         0.7008      2741\n   macro avg     0.5126    0.5310    0.4889      2741\nweighted avg     0.8480    0.7008    0.7604      2741\n\nTest Macro F1: 0.48892824139762653\n\nEpoch 285 | Loss: 1.2185\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9142    0.7629    0.8317      2501\n         1.0     0.0933    0.2542    0.1365       240\n\n    accuracy                         0.7184      2741\n   macro avg     0.5038    0.5085    0.4841      2741\nweighted avg     0.8423    0.7184    0.7709      2741\n\nTest Macro F1: 0.4841001425760031\n\nEpoch 286 | Loss: 1.2145\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9173    0.5674    0.7011      2501\n         1.0     0.0938    0.4667    0.1562       240\n\n    accuracy                         0.5586      2741\n   macro avg     0.5055    0.5170    0.4286      2741\nweighted avg     0.8452    0.5586    0.6534      2741\n\nTest Macro F1: 0.4286466860711903\n\nEpoch 287 | Loss: 1.2060\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9164    0.5214    0.6646      2501\n         1.0     0.0918    0.5042    0.1553       240\n\n    accuracy                         0.5199      2741\n   macro avg     0.5041    0.5128    0.4100      2741\nweighted avg     0.8442    0.5199    0.6200      2741\n\nTest Macro F1: 0.40997763671504417\n\nEpoch 288 | Loss: 1.2096\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9198    0.6785    0.7809      2501\n         1.0     0.1027    0.3833    0.1620       240\n\n    accuracy                         0.6527      2741\n   macro avg     0.5112    0.5309    0.4715      2741\nweighted avg     0.8482    0.6527    0.7268      2741\n\nTest Macro F1: 0.4714599145725712\n\nEpoch 289 | Loss: 1.2116\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9151    0.7973    0.8521      2501\n         1.0     0.0979    0.2292    0.1372       240\n\n    accuracy                         0.7475      2741\n   macro avg     0.5065    0.5132    0.4946      2741\nweighted avg     0.8435    0.7475    0.7895      2741\n\nTest Macro F1: 0.4946469296843361\n\nEpoch 290 | Loss: 1.2026\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9150    0.7705    0.8366      2501\n         1.0     0.0961    0.2542    0.1394       240\n\n    accuracy                         0.7253      2741\n   macro avg     0.5055    0.5123    0.4880      2741\nweighted avg     0.8433    0.7253    0.7755      2741\n\nTest Macro F1: 0.4879908214208193\n\nEpoch 291 | Loss: 1.1972\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9183    0.6429    0.7563      2501\n         1.0     0.0980    0.4042    0.1577       240\n\n    accuracy                         0.6220      2741\n   macro avg     0.5082    0.5236    0.4570      2741\nweighted avg     0.8465    0.6220    0.7039      2741\n\nTest Macro F1: 0.4570367650995419\n\nEpoch 292 | Loss: 1.2141\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9181    0.7125    0.8023      2501\n         1.0     0.1013    0.3375    0.1558       240\n\n    accuracy                         0.6797      2741\n   macro avg     0.5097    0.5250    0.4791      2741\nweighted avg     0.8466    0.6797    0.7457      2741\n\nTest Macro F1: 0.47905525923873515\n\nEpoch 293 | Loss: 1.2080\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9198    0.6006    0.7267      2501\n         1.0     0.0984    0.4542    0.1617       240\n\n    accuracy                         0.5877      2741\n   macro avg     0.5091    0.5274    0.4442      2741\nweighted avg     0.8479    0.5877    0.6772      2741\n\nTest Macro F1: 0.4441890295285962\n\nEpoch 294 | Loss: 1.1964\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9218    0.5138    0.6598      2501\n         1.0     0.0973    0.5458    0.1651       240\n\n    accuracy                         0.5166      2741\n   macro avg     0.5095    0.5298    0.4125      2741\nweighted avg     0.8496    0.5166    0.6165      2741\n\nTest Macro F1: 0.4124558248865744\n\nEpoch 295 | Loss: 1.2126\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9210    0.5314    0.6739      2501\n         1.0     0.0971    0.5250    0.1638       240\n\n    accuracy                         0.5308      2741\n   macro avg     0.5090    0.5282    0.4189      2741\nweighted avg     0.8489    0.5308    0.6293      2741\n\nTest Macro F1: 0.41889212301215717\n\nEpoch 296 | Loss: 1.2118\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9207    0.6689    0.7749      2501\n         1.0     0.1039    0.4000    0.1649       240\n\n    accuracy                         0.6454      2741\n   macro avg     0.5123    0.5345    0.4699      2741\nweighted avg     0.8492    0.6454    0.7215      2741\n\nTest Macro F1: 0.46992211934696765\n\nEpoch 297 | Loss: 1.2098\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9171    0.7521    0.8264      2501\n         1.0     0.1014    0.2917    0.1505       240\n\n    accuracy                         0.7118      2741\n   macro avg     0.5093    0.5219    0.4885      2741\nweighted avg     0.8457    0.7118    0.7673      2741\n\nTest Macro F1: 0.48849377326756993\n\nEpoch 298 | Loss: 1.2081\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9202    0.6090    0.7329      2501\n         1.0     0.0994    0.4500    0.1629       240\n\n    accuracy                         0.5950      2741\n   macro avg     0.5098    0.5295    0.4479      2741\nweighted avg     0.8484    0.5950    0.6830      2741\n\nTest Macro F1: 0.4479060966209242\n\nEpoch 299 | Loss: 1.1977\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9217    0.6166    0.7389      2501\n         1.0     0.1021    0.4542    0.1667       240\n\n    accuracy                         0.6023      2741\n   macro avg     0.5119    0.5354    0.4528      2741\nweighted avg     0.8499    0.6023    0.6888      2741\n\nTest Macro F1: 0.4527631368790928\n\nEpoch 300 | Loss: 1.2012\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9177    0.7577    0.8300      2501\n         1.0     0.1036    0.2917    0.1528       240\n\n    accuracy                         0.7169      2741\n   macro avg     0.5106    0.5247    0.4914      2741\nweighted avg     0.8464    0.7169    0.7708      2741\n\nTest Macro F1: 0.49144330508199013\n\nEpoch 301 | Loss: 1.2064\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9170    0.7953    0.8518      2501\n         1.0     0.1049    0.2500    0.1478       240\n\n    accuracy                         0.7475      2741\n   macro avg     0.5110    0.5226    0.4998      2741\nweighted avg     0.8459    0.7475    0.7902      2741\n\nTest Macro F1: 0.49980168985559226\n\nEpoch 302 | Loss: 1.2008\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9180    0.7113    0.8015      2501\n         1.0     0.1009    0.3375    0.1553       240\n\n    accuracy                         0.6786      2741\n   macro avg     0.5094    0.5244    0.4784      2741\nweighted avg     0.8464    0.6786    0.7450      2741\n\nTest Macro F1: 0.4784265327135041\n\nEpoch 303 | Loss: 1.2196\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9193    0.6745    0.7781      2501\n         1.0     0.1015    0.3833    0.1606       240\n\n    accuracy                         0.6490      2741\n   macro avg     0.5104    0.5289    0.4693      2741\nweighted avg     0.8477    0.6490    0.7241      2741\n\nTest Macro F1: 0.4693474977943497\n\nEpoch 304 | Loss: 1.2159\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9199    0.5830    0.7137      2501\n         1.0     0.0978    0.4708    0.1619       240\n\n    accuracy                         0.5731      2741\n   macro avg     0.5088    0.5269    0.4378      2741\nweighted avg     0.8479    0.5731    0.6653      2741\n\nTest Macro F1: 0.43777375257185414\n\nEpoch 305 | Loss: 1.2067\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9200    0.5886    0.7179      2501\n         1.0     0.0982    0.4667    0.1622       240\n\n    accuracy                         0.5779      2741\n   macro avg     0.5091    0.5276    0.4400      2741\nweighted avg     0.8480    0.5779    0.6692      2741\n\nTest Macro F1: 0.4400374963736967\n\nEpoch 306 | Loss: 1.2038\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9195    0.6393    0.7542      2501\n         1.0     0.0998    0.4167    0.1610       240\n\n    accuracy                         0.6198      2741\n   macro avg     0.5096    0.5280    0.4576      2741\nweighted avg     0.8477    0.6198    0.7023      2741\n\nTest Macro F1: 0.45763793941603625\n\nEpoch 307 | Loss: 1.1979\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9189    0.6026    0.7278      2501\n         1.0     0.0972    0.4458    0.1596       240\n\n    accuracy                         0.5888      2741\n   macro avg     0.5080    0.5242    0.4437      2741\nweighted avg     0.8470    0.5888    0.6781      2741\n\nTest Macro F1: 0.4437129586260312\n\nEpoch 308 | Loss: 1.1923\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9210    0.5830    0.7140      2501\n         1.0     0.0993    0.4792    0.1645       240\n\n    accuracy                         0.5739      2741\n   macro avg     0.5102    0.5311    0.4393      2741\nweighted avg     0.8491    0.5739    0.6659      2741\n\nTest Macro F1: 0.4392633102557313\n\nEpoch 309 | Loss: 1.2017\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9233    0.5822    0.7141      2501\n         1.0     0.1022    0.4958    0.1695       240\n\n    accuracy                         0.5746      2741\n   macro avg     0.5128    0.5390    0.4418      2741\nweighted avg     0.8514    0.5746    0.6664      2741\n\nTest Macro F1: 0.4417955983674473\n\nEpoch 310 | Loss: 1.1965\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9187    0.6957    0.7918      2501\n         1.0     0.1015    0.3583    0.1582       240\n\n    accuracy                         0.6662      2741\n   macro avg     0.5101    0.5270    0.4750      2741\nweighted avg     0.8471    0.6662    0.7363      2741\n\nTest Macro F1: 0.47502127218665513\n\nEpoch 311 | Loss: 1.1994\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9226    0.6673    0.7745      2501\n         1.0     0.1073    0.4167    0.1706       240\n\n    accuracy                         0.6454      2741\n   macro avg     0.5150    0.5420    0.4726      2741\nweighted avg     0.8512    0.6454    0.7216      2741\n\nTest Macro F1: 0.4725632112002407\n\nEpoch 312 | Loss: 1.1924\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9182    0.7049    0.7976      2501\n         1.0     0.1011    0.3458    0.1565       240\n\n    accuracy                         0.6735      2741\n   macro avg     0.5097    0.5254    0.4770      2741\nweighted avg     0.8467    0.6735    0.7414      2741\n\nTest Macro F1: 0.47700664359823236\n\nEpoch 313 | Loss: 1.1906\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9189    0.6929    0.7901      2501\n         1.0     0.1018    0.3625    0.1589       240\n\n    accuracy                         0.6640      2741\n   macro avg     0.5103    0.5277    0.4745      2741\nweighted avg     0.8473    0.6640    0.7348      2741\n\nTest Macro F1: 0.47448282753215454\n\nEpoch 314 | Loss: 1.2096\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9165    0.7461    0.8226      2501\n         1.0     0.0993    0.2917    0.1481       240\n\n    accuracy                         0.7063      2741\n   macro avg     0.5079    0.5189    0.4854      2741\nweighted avg     0.8449    0.7063    0.7635      2741\n\nTest Macro F1: 0.48535906415562574\n\nEpoch 315 | Loss: 1.1968\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9155    0.7405    0.8187      2501\n         1.0     0.0961    0.2875    0.1441       240\n\n    accuracy                         0.7008      2741\n   macro avg     0.5058    0.5140    0.4814      2741\nweighted avg     0.8437    0.7008    0.7597      2741\n\nTest Macro F1: 0.4813972891505106\n\nEpoch 316 | Loss: 1.1999\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9183    0.6653    0.7716      2501\n         1.0     0.0990    0.3833    0.1574       240\n\n    accuracy                         0.6406      2741\n   macro avg     0.5087    0.5243    0.4645      2741\nweighted avg     0.8466    0.6406    0.7178      2741\n\nTest Macro F1: 0.4645100842004508\n\nEpoch 317 | Loss: 1.1875\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9181    0.6413    0.7552      2501\n         1.0     0.0976    0.4042    0.1572       240\n\n    accuracy                         0.6206      2741\n   macro avg     0.5079    0.5228    0.4562      2741\nweighted avg     0.8463    0.6206    0.7028      2741\n\nTest Macro F1: 0.45619561269370346\n\nEpoch 318 | Loss: 1.2084\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9173    0.6833    0.7832      2501\n         1.0     0.0979    0.3583    0.1538       240\n\n    accuracy                         0.6549      2741\n   macro avg     0.5076    0.5208    0.4685      2741\nweighted avg     0.8456    0.6549    0.7281      2741\n\nTest Macro F1: 0.46853627582316854\n\nEpoch 319 | Loss: 1.1933\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9167    0.8225    0.8670      2501\n         1.0     0.1066    0.2208    0.1438       240\n\n    accuracy                         0.7698      2741\n   macro avg     0.5117    0.5217    0.5054      2741\nweighted avg     0.8457    0.7698    0.8037      2741\n\nTest Macro F1: 0.5054221182620282\n\nEpoch 320 | Loss: 1.1912\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9170    0.7373    0.8174      2501\n         1.0     0.1000    0.3042    0.1505       240\n\n    accuracy                         0.6994      2741\n   macro avg     0.5085    0.5207    0.4839      2741\nweighted avg     0.8454    0.6994    0.7590      2741\n\nTest Macro F1: 0.4839456752211742\n\nEpoch 321 | Loss: 1.1854\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9226    0.5578    0.6952      2501\n         1.0     0.1001    0.5125    0.1675       240\n\n    accuracy                         0.5538      2741\n   macro avg     0.5114    0.5351    0.4314      2741\nweighted avg     0.8506    0.5538    0.6490      2741\n\nTest Macro F1: 0.43135066310189635\n\nEpoch 322 | Loss: 1.1954\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9189    0.6841    0.7843      2501\n         1.0     0.1013    0.3708    0.1591       240\n\n    accuracy                         0.6567      2741\n   macro avg     0.5101    0.5275    0.4717      2741\nweighted avg     0.8473    0.6567    0.7296      2741\n\nTest Macro F1: 0.47169665623898416\n\nEpoch 323 | Loss: 1.2082\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9162    0.8437    0.8784      2501\n         1.0     0.1073    0.1958    0.1386       240\n\n    accuracy                         0.7869      2741\n   macro avg     0.5118    0.5197    0.5085      2741\nweighted avg     0.8454    0.7869    0.8137      2741\n\nTest Macro F1: 0.5085388528242197\n\nEpoch 324 | Loss: 1.2059\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9183    0.7237    0.8095      2501\n         1.0     0.1026    0.3292    0.1564       240\n\n    accuracy                         0.6892      2741\n   macro avg     0.5105    0.5264    0.4830      2741\nweighted avg     0.8469    0.6892    0.7523      2741\n\nTest Macro F1: 0.48295843001115857\n\nEpoch 325 | Loss: 1.2078\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9192    0.4638    0.6165      2501\n         1.0     0.0933    0.5750    0.1606       240\n\n    accuracy                         0.4735      2741\n   macro avg     0.5062    0.5194    0.3885      2741\nweighted avg     0.8469    0.4735    0.5766      2741\n\nTest Macro F1: 0.38854391454592085\n\nEpoch 326 | Loss: 1.2174\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9246    0.5734    0.7078      2501\n         1.0     0.1034    0.5125    0.1720       240\n\n    accuracy                         0.5680      2741\n   macro avg     0.5140    0.5429    0.4399      2741\nweighted avg     0.8527    0.5680    0.6609      2741\n\nTest Macro F1: 0.43991329499720416\n\nEpoch 327 | Loss: 1.1882\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9175    0.8093    0.8600      2501\n         1.0     0.1084    0.2417    0.1497       240\n\n    accuracy                         0.7596      2741\n   macro avg     0.5130    0.5255    0.5048      2741\nweighted avg     0.8467    0.7596    0.7978      2741\n\nTest Macro F1: 0.504836585181987\n\nEpoch 328 | Loss: 1.1922\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9170    0.7597    0.8310      2501\n         1.0     0.1016    0.2833    0.1496       240\n\n    accuracy                         0.7180      2741\n   macro avg     0.5093    0.5215    0.4903      2741\nweighted avg     0.8456    0.7180    0.7713      2741\n\nTest Macro F1: 0.49028965874938685\n\nEpoch 329 | Loss: 1.1935\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9256    0.5574    0.6958      2501\n         1.0     0.1036    0.5333    0.1736       240\n\n    accuracy                         0.5553      2741\n   macro avg     0.5146    0.5454    0.4347      2741\nweighted avg     0.8537    0.5553    0.6501      2741\n\nTest Macro F1: 0.43467085143371975\n\nEpoch 330 | Loss: 1.1912\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9253    0.4802    0.6323      2501\n         1.0     0.0991    0.5958    0.1699       240\n\n    accuracy                         0.4903      2741\n   macro avg     0.5122    0.5380    0.4011      2741\nweighted avg     0.8529    0.4903    0.5918      2741\n\nTest Macro F1: 0.40110314547860026\n\nEpoch 331 | Loss: 1.2164\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9178    0.7633    0.8334      2501\n         1.0     0.1044    0.2875    0.1532       240\n\n    accuracy                         0.7216      2741\n   macro avg     0.5111    0.5254    0.4933      2741\nweighted avg     0.8466    0.7216    0.7739      2741\n\nTest Macro F1: 0.49330281593058817\n\nEpoch 332 | Loss: 1.1892\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9150    0.8784    0.8964      2501\n         1.0     0.1059    0.1500    0.1241       240\n\n    accuracy                         0.8147      2741\n   macro avg     0.5105    0.5142    0.5103      2741\nweighted avg     0.8442    0.8147    0.8288      2741\n\nTest Macro F1: 0.5102533800419252\n\nEpoch 333 | Loss: 1.2024\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9173    0.6833    0.7832      2501\n         1.0     0.0979    0.3583    0.1538       240\n\n    accuracy                         0.6549      2741\n   macro avg     0.5076    0.5208    0.4685      2741\nweighted avg     0.8456    0.6549    0.7281      2741\n\nTest Macro F1: 0.46853627582316854\n\nEpoch 334 | Loss: 1.1952\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9238    0.4654    0.6190      2501\n         1.0     0.0972    0.6000    0.1673       240\n\n    accuracy                         0.4772      2741\n   macro avg     0.5105    0.5327    0.3932      2741\nweighted avg     0.8514    0.4772    0.5794      2741\n\nTest Macro F1: 0.39316443989747063\n\nEpoch 335 | Loss: 1.1969\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9255    0.6014    0.7290      2501\n         1.0     0.1066    0.4958    0.1755       240\n\n    accuracy                         0.5921      2741\n   macro avg     0.5161    0.5486    0.4523      2741\nweighted avg     0.8538    0.5921    0.6806      2741\n\nTest Macro F1: 0.45227580477495755\n\nEpoch 336 | Loss: 1.2031\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9179    0.7869    0.8474      2501\n         1.0     0.1072    0.2667    0.1529       240\n\n    accuracy                         0.7413      2741\n   macro avg     0.5126    0.5268    0.5001      2741\nweighted avg     0.8469    0.7413    0.7866      2741\n\nTest Macro F1: 0.500144938160147\n\nEpoch 337 | Loss: 1.1978\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9153    0.7349    0.8153      2501\n         1.0     0.0955    0.2917    0.1439       240\n\n    accuracy                         0.6961      2741\n   macro avg     0.5054    0.5133    0.4796      2741\nweighted avg     0.8436    0.6961    0.7565      2741\n\nTest Macro F1: 0.47957163211546533\n\nEpoch 338 | Loss: 1.1984\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9248    0.5850    0.7166      2501\n         1.0     0.1044    0.5042    0.1730       240\n\n    accuracy                         0.5779      2741\n   macro avg     0.5146    0.5446    0.4448      2741\nweighted avg     0.8529    0.5779    0.6690      2741\n\nTest Macro F1: 0.4448053147370755\n\nEpoch 339 | Loss: 1.1888\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9259    0.5298    0.6740      2501\n         1.0     0.1023    0.5583    0.1729       240\n\n    accuracy                         0.5323      2741\n   macro avg     0.5141    0.5441    0.4234      2741\nweighted avg     0.8538    0.5323    0.6301      2741\n\nTest Macro F1: 0.42343024972926857\n\nEpoch 340 | Loss: 1.1990\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9254    0.6050    0.7316      2501\n         1.0     0.1067    0.4917    0.1753       240\n\n    accuracy                         0.5950      2741\n   macro avg     0.5160    0.5483    0.4535      2741\nweighted avg     0.8537    0.5950    0.6829      2741\n\nTest Macro F1: 0.4534795410716185\n\nEpoch 341 | Loss: 1.2089\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9191    0.7045    0.7976      2501\n         1.0     0.1032    0.3542    0.1598       240\n\n    accuracy                         0.6738      2741\n   macro avg     0.5111    0.5293    0.4787      2741\nweighted avg     0.8477    0.6738    0.7418      2741\n\nTest Macro F1: 0.4787102148762581\n\nEpoch 342 | Loss: 1.1991\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9203    0.7569    0.8306      2501\n         1.0     0.1111    0.3167    0.1645       240\n\n    accuracy                         0.7184      2741\n   macro avg     0.5157    0.5368    0.4976      2741\nweighted avg     0.8494    0.7184    0.7723      2741\n\nTest Macro F1: 0.4975648163449831\n\nEpoch 343 | Loss: 1.1879\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9204    0.6933    0.7909      2501\n         1.0     0.1050    0.3750    0.1641       240\n\n    accuracy                         0.6655      2741\n   macro avg     0.5127    0.5342    0.4775      2741\nweighted avg     0.8490    0.6655    0.7360      2741\n\nTest Macro F1: 0.47748092912254736\n\nEpoch 344 | Loss: 1.1916\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9228    0.6022    0.7288      2501\n         1.0     0.1028    0.4750    0.1690       240\n\n    accuracy                         0.5910      2741\n   macro avg     0.5128    0.5386    0.4489      2741\nweighted avg     0.8510    0.5910    0.6798      2741\n\nTest Macro F1: 0.44889126678775776\n\nEpoch 345 | Loss: 1.1923\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9226    0.6337    0.7514      2501\n         1.0     0.1046    0.4458    0.1694       240\n\n    accuracy                         0.6173      2741\n   macro avg     0.5136    0.5398    0.4604      2741\nweighted avg     0.8510    0.6173    0.7004      2741\n\nTest Macro F1: 0.4604003642985199\n\nEpoch 346 | Loss: 1.1955\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9205    0.7313    0.8151      2501\n         1.0     0.1088    0.3417    0.1650       240\n\n    accuracy                         0.6972      2741\n   macro avg     0.5146    0.5365    0.4900      2741\nweighted avg     0.8494    0.6972    0.7581      2741\n\nTest Macro F1: 0.4900261641148137\n\nEpoch 347 | Loss: 1.1847\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9190    0.6713    0.7759      2501\n         1.0     0.1007    0.3833    0.1594       240\n\n    accuracy                         0.6461      2741\n   macro avg     0.5098    0.5273    0.4677      2741\nweighted avg     0.8473    0.6461    0.7219      2741\n\nTest Macro F1: 0.46766170548794356\n\nEpoch 348 | Loss: 1.1932\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9228    0.5542    0.6925      2501\n         1.0     0.1001    0.5167    0.1677       240\n\n    accuracy                         0.5509      2741\n   macro avg     0.5114    0.5354    0.4301      2741\nweighted avg     0.8507    0.5509    0.6465      2741\n\nTest Macro F1: 0.4300807524849939\n\nEpoch 349 | Loss: 1.1929\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9220    0.5486    0.6879      2501\n         1.0     0.0990    0.5167    0.1661       240\n\n    accuracy                         0.5458      2741\n   macro avg     0.5105    0.5326    0.4270      2741\nweighted avg     0.8500    0.5458    0.6422      2741\n\nTest Macro F1: 0.4270001042720126\n\nEpoch 350 | Loss: 1.2045\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9202    0.6226    0.7427      2501\n         1.0     0.1001    0.4375    0.1629       240\n\n    accuracy                         0.6063      2741\n   macro avg     0.5102    0.5300    0.4528      2741\nweighted avg     0.8484    0.6063    0.6919      2741\n\nTest Macro F1: 0.4527916692955139\n\nEpoch 351 | Loss: 1.1846\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9217    0.6965    0.7934      2501\n         1.0     0.1081    0.3833    0.1687       240\n\n    accuracy                         0.6691      2741\n   macro avg     0.5149    0.5399    0.4810      2741\nweighted avg     0.8505    0.6691    0.7387      2741\n\nTest Macro F1: 0.4810468709327741\n\nEpoch 352 | Loss: 1.1986\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9198    0.6102    0.7337      2501\n         1.0     0.0989    0.4458    0.1619       240\n\n    accuracy                         0.5958      2741\n   macro avg     0.5094    0.5280    0.4478      2741\nweighted avg     0.8480    0.5958    0.6836      2741\n\nTest Macro F1: 0.4477648958454556\n\nEpoch 353 | Loss: 1.1921\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9225    0.5810    0.7130      2501\n         1.0     0.1012    0.4917    0.1679       240\n\n    accuracy                         0.5731      2741\n   macro avg     0.5119    0.5363    0.4404      2741\nweighted avg     0.8506    0.5731    0.6652      2741\n\nTest Macro F1: 0.4404029694691334\n\nEpoch 354 | Loss: 1.1967\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9207    0.6689    0.7749      2501\n         1.0     0.1039    0.4000    0.1649       240\n\n    accuracy                         0.6454      2741\n   macro avg     0.5123    0.5345    0.4699      2741\nweighted avg     0.8492    0.6454    0.7215      2741\n\nTest Macro F1: 0.46992211934696765\n\nEpoch 355 | Loss: 1.1795\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9188    0.7777    0.8424      2501\n         1.0     0.1090    0.2833    0.1574       240\n\n    accuracy                         0.7344      2741\n   macro avg     0.5139    0.5305    0.4999      2741\nweighted avg     0.8478    0.7344    0.7824      2741\n\nTest Macro F1: 0.49988170283752786\n\nEpoch 356 | Loss: 1.1922\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9206    0.6581    0.7675      2501\n         1.0     0.1028    0.4083    0.1643       240\n\n    accuracy                         0.6363      2741\n   macro avg     0.5117    0.5332    0.4659      2741\nweighted avg     0.8490    0.6363    0.7147      2741\n\nTest Macro F1: 0.46591829192478\n\nEpoch 357 | Loss: 1.1912\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9200    0.7077    0.8000      2501\n         1.0     0.1053    0.3583    0.1627       240\n\n    accuracy                         0.6771      2741\n   macro avg     0.5126    0.5330    0.4814      2741\nweighted avg     0.8486    0.6771    0.7442      2741\n\nTest Macro F1: 0.48136234626300856\n\nEpoch 358 | Loss: 1.1904\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9211    0.6537    0.7647      2501\n         1.0     0.1035    0.4167    0.1658       240\n\n    accuracy                         0.6330      2741\n   macro avg     0.5123    0.5352    0.4653      2741\nweighted avg     0.8495    0.6330    0.7123      2741\n\nTest Macro F1: 0.46528543748361406\n\nEpoch 359 | Loss: 1.1945\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9246    0.5930    0.7225      2501\n         1.0     0.1047    0.4958    0.1728       240\n\n    accuracy                         0.5845      2741\n   macro avg     0.5146    0.5444    0.4477      2741\nweighted avg     0.8528    0.5845    0.6744      2741\n\nTest Macro F1: 0.44768650095487283\n\nEpoch 360 | Loss: 1.1879\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9236    0.5754    0.7090      2501\n         1.0     0.1023    0.5042    0.1701       240\n\n    accuracy                         0.5691      2741\n   macro avg     0.5130    0.5398    0.4396      2741\nweighted avg     0.8517    0.5691    0.6618      2741\n\nTest Macro F1: 0.439552441266443\n\nEpoch 361 | Loss: 1.1890\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9183    0.7105    0.8012      2501\n         1.0     0.1017    0.3417    0.1568       240\n\n    accuracy                         0.6782      2741\n   macro avg     0.5100    0.5261    0.4790      2741\nweighted avg     0.8468    0.6782    0.7448      2741\n\nTest Macro F1: 0.478979995069025\n\nEpoch 362 | Loss: 1.1798\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9159    0.8185    0.8644      2501\n         1.0     0.1028    0.2167    0.1394       240\n\n    accuracy                         0.7658      2741\n   macro avg     0.5093    0.5176    0.5019      2741\nweighted avg     0.8447    0.7658    0.8010      2741\n\nTest Macro F1: 0.5019263776175639\n\nEpoch 363 | Loss: 1.1853\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9209    0.6421    0.7567      2501\n         1.0     0.1023    0.4250    0.1649       240\n\n    accuracy                         0.6231      2741\n   macro avg     0.5116    0.5336    0.4608      2741\nweighted avg     0.8492    0.6231    0.7048      2741\n\nTest Macro F1: 0.4607850026613649\n\nEpoch 364 | Loss: 1.1807\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9241    0.5650    0.7012      2501\n         1.0     0.1023    0.5167    0.1708       240\n\n    accuracy                         0.5607      2741\n   macro avg     0.5132    0.5408    0.4360      2741\nweighted avg     0.8522    0.5607    0.6548      2741\n\nTest Macro F1: 0.4360197964303536\n\nEpoch 365 | Loss: 1.1891\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9221    0.6198    0.7413      2501\n         1.0     0.1028    0.4542    0.1677       240\n\n    accuracy                         0.6053      2741\n   macro avg     0.5125    0.5370    0.4545      2741\nweighted avg     0.8503    0.6053    0.6910      2741\n\nTest Macro F1: 0.4544822131479234\n\nEpoch 366 | Loss: 1.1841\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9174    0.7857    0.8464      2501\n         1.0     0.1052    0.2625    0.1502       240\n\n    accuracy                         0.7399      2741\n   macro avg     0.5113    0.5241    0.4983      2741\nweighted avg     0.8463    0.7399    0.7855      2741\n\nTest Macro F1: 0.49830713927973386\n\nEpoch 367 | Loss: 1.1865\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9191    0.7545    0.8287      2501\n         1.0     0.1076    0.3083    0.1595       240\n\n    accuracy                         0.7154      2741\n   macro avg     0.5134    0.5314    0.4941      2741\nweighted avg     0.8481    0.7154    0.7701      2741\n\nTest Macro F1: 0.49410238062786793\n\nEpoch 368 | Loss: 1.1811\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9246    0.6178    0.7407      2501\n         1.0     0.1065    0.4750    0.1740       240\n\n    accuracy                         0.6053      2741\n   macro avg     0.5156    0.5464    0.4573      2741\nweighted avg     0.8530    0.6053    0.6910      2741\n\nTest Macro F1: 0.45734888350544883\n\nEpoch 369 | Loss: 1.1919\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9235    0.5842    0.7157      2501\n         1.0     0.1027    0.4958    0.1701       240\n\n    accuracy                         0.5764      2741\n   macro avg     0.5131    0.5400    0.4429      2741\nweighted avg     0.8516    0.5764    0.6679      2741\n\nTest Macro F1: 0.44288588626598513\n\nEpoch 370 | Loss: 1.1783\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9175    0.7605    0.8317      2501\n         1.0     0.1033    0.2875    0.1520       240\n\n    accuracy                         0.7191      2741\n   macro avg     0.5104    0.5240    0.4918      2741\nweighted avg     0.8462    0.7191    0.7721      2741\n\nTest Macro F1: 0.4918197858418296\n\nEpoch 371 | Loss: 1.1798\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9174    0.8037    0.8568      2501\n         1.0     0.1073    0.2458    0.1494       240\n\n    accuracy                         0.7548      2741\n   macro avg     0.5123    0.5248    0.5031      2741\nweighted avg     0.8465    0.7548    0.7948      2741\n\nTest Macro F1: 0.5030722911068666\n\nEpoch 372 | Loss: 1.1789\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9224    0.6321    0.7502      2501\n         1.0     0.1042    0.4458    0.1689       240\n\n    accuracy                         0.6158      2741\n   macro avg     0.5133    0.5390    0.4595      2741\nweighted avg     0.8508    0.6158    0.6993      2741\n\nTest Macro F1: 0.4595404281135981\n\nEpoch 373 | Loss: 1.1878\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9275    0.5114    0.6593      2501\n         1.0     0.1028    0.5833    0.1748       240\n\n    accuracy                         0.5177      2741\n   macro avg     0.5151    0.5474    0.4170      2741\nweighted avg     0.8553    0.5177    0.6169      2741\n\nTest Macro F1: 0.4170299368057968\n\nEpoch 374 | Loss: 1.1956\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9186    0.7353    0.8168      2501\n         1.0     0.1042    0.3208    0.1573       240\n\n    accuracy                         0.6990      2741\n   macro avg     0.5114    0.5281    0.4870      2741\nweighted avg     0.8473    0.6990    0.7590      2741\n\nTest Macro F1: 0.4870460891241045\n\nEpoch 375 | Loss: 1.1771\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9163    0.8313    0.8717      2501\n         1.0     0.1059    0.2083    0.1404       240\n\n    accuracy                         0.7767      2741\n   macro avg     0.5111    0.5198    0.5061      2741\nweighted avg     0.8453    0.7767    0.8077      2741\n\nTest Macro F1: 0.5060737757048972\n\nEpoch 376 | Loss: 1.2047\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9211    0.5978    0.7250      2501\n         1.0     0.1002    0.4667    0.1649       240\n\n    accuracy                         0.5863      2741\n   macro avg     0.5107    0.5322    0.4450      2741\nweighted avg     0.8493    0.5863    0.6760      2741\n\nTest Macro F1: 0.44498635095543315\n\nEpoch 377 | Loss: 1.1808\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9230    0.5226    0.6673      2501\n         1.0     0.0989    0.5458    0.1674       240\n\n    accuracy                         0.5246      2741\n   macro avg     0.5109    0.5342    0.4174      2741\nweighted avg     0.8509    0.5246    0.6236      2741\n\nTest Macro F1: 0.4173798001828679\n\nEpoch 378 | Loss: 1.1752\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9220    0.5906    0.7200      2501\n         1.0     0.1010    0.4792    0.1668       240\n\n    accuracy                         0.5808      2741\n   macro avg     0.5115    0.5349    0.4434      2741\nweighted avg     0.8501    0.5808    0.6715      2741\n\nTest Macro F1: 0.44337426566846416\n\nEpoch 379 | Loss: 1.1775\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9190    0.7353    0.8170      2501\n         1.0     0.1054    0.3250    0.1592       240\n\n    accuracy                         0.6994      2741\n   macro avg     0.5122    0.5302    0.4881      2741\nweighted avg     0.8478    0.6994    0.7594      2741\n\nTest Macro F1: 0.48807695446014926\n\nEpoch 380 | Loss: 1.1768\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9188    0.6873    0.7864      2501\n         1.0     0.1011    0.3667    0.1586       240\n\n    accuracy                         0.6592      2741\n   macro avg     0.5100    0.5270    0.4725      2741\nweighted avg     0.8472    0.6592    0.7314      2741\n\nTest Macro F1: 0.47246317680901395\n\nEpoch 381 | Loss: 1.1859\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9228    0.6122    0.7361      2501\n         1.0     0.1035    0.4667    0.1694       240\n\n    accuracy                         0.5994      2741\n   macro avg     0.5132    0.5394    0.4527      2741\nweighted avg     0.8511    0.5994    0.6864      2741\n\nTest Macro F1: 0.4527489671825905\n\nEpoch 382 | Loss: 1.1850\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9252    0.5786    0.7119      2501\n         1.0     0.1045    0.5125    0.1736       240\n\n    accuracy                         0.5728      2741\n   macro avg     0.5148    0.5455    0.4428      2741\nweighted avg     0.8533    0.5728    0.6648      2741\n\nTest Macro F1: 0.4427686648073255\n\nEpoch 383 | Loss: 1.1882\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9193    0.7289    0.8131      2501\n         1.0     0.1055    0.3333    0.1603       240\n\n    accuracy                         0.6943      2741\n   macro avg     0.5124    0.5311    0.4867      2741\nweighted avg     0.8481    0.6943    0.7560      2741\n\nTest Macro F1: 0.4867169664932005\n\nEpoch 384 | Loss: 1.1827\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9197    0.7377    0.8187      2501\n         1.0     0.1075    0.3292    0.1621       240\n\n    accuracy                         0.7019      2741\n   macro avg     0.5136    0.5334    0.4904      2741\nweighted avg     0.8486    0.7019    0.7612      2741\n\nTest Macro F1: 0.4903888538057609\n\nEpoch 385 | Loss: 1.1952\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9261    0.5810    0.7140      2501\n         1.0     0.1058    0.5167    0.1756       240\n\n    accuracy                         0.5753      2741\n   macro avg     0.5159    0.5488    0.4448      2741\nweighted avg     0.8542    0.5753    0.6669      2741\n\nTest Macro F1: 0.44482115388630966\n\nEpoch 386 | Loss: 1.1767\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9239    0.5390    0.6808      2501\n         1.0     0.1006    0.5375    0.1695       240\n\n    accuracy                         0.5389      2741\n   macro avg     0.5123    0.5382    0.4252      2741\nweighted avg     0.8518    0.5389    0.6360      2741\n\nTest Macro F1: 0.42516093922138604\n\nEpoch 387 | Loss: 1.1861\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9218    0.5986    0.7258      2501\n         1.0     0.1012    0.4708    0.1665       240\n\n    accuracy                         0.5874      2741\n   macro avg     0.5115    0.5347    0.4462      2741\nweighted avg     0.8499    0.5874    0.6768      2741\n\nTest Macro F1: 0.4461810142694447\n\nEpoch 388 | Loss: 1.1819\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9191    0.7133    0.8032      2501\n         1.0     0.1037    0.3458    0.1596       240\n\n    accuracy                         0.6811      2741\n   macro avg     0.5114    0.5296    0.4814      2741\nweighted avg     0.8477    0.6811    0.7469      2741\n\nTest Macro F1: 0.481428583798012\n\nEpoch 389 | Loss: 1.1707\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9215    0.6669    0.7738      2501\n         1.0     0.1053    0.4083    0.1674       240\n\n    accuracy                         0.6443      2741\n   macro avg     0.5134    0.5376    0.4706      2741\nweighted avg     0.8501    0.6443    0.7207      2741\n\nTest Macro F1: 0.4706063431560794\n\nEpoch 390 | Loss: 1.1714\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9203    0.6098    0.7335      2501\n         1.0     0.0996    0.4500    0.1631       240\n\n    accuracy                         0.5958      2741\n   macro avg     0.5100    0.5299    0.4483      2741\nweighted avg     0.8485    0.5958    0.6836      2741\n\nTest Macro F1: 0.44833386374171874\n\nEpoch 391 | Loss: 1.1754\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9252    0.5738    0.7083      2501\n         1.0     0.1042    0.5167    0.1734       240\n\n    accuracy                         0.5688      2741\n   macro avg     0.5147    0.5452    0.4409      2741\nweighted avg     0.8533    0.5688    0.6615      2741\n\nTest Macro F1: 0.44085938740430347\n\nEpoch 392 | Loss: 1.1913\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9218    0.5846    0.7154      2501\n         1.0     0.1004    0.4833    0.1663       240\n\n    accuracy                         0.5757      2741\n   macro avg     0.5111    0.5339    0.4409      2741\nweighted avg     0.8499    0.5757    0.6674      2741\n\nTest Macro F1: 0.4408737205914724\n\nEpoch 393 | Loss: 1.1816\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9218    0.6645    0.7723      2501\n         1.0     0.1055    0.4125    0.1681       240\n\n    accuracy                         0.6425      2741\n   macro avg     0.5137    0.5385    0.4702      2741\nweighted avg     0.8503    0.6425    0.7194      2741\n\nTest Macro F1: 0.4701931633857398\n\nEpoch 394 | Loss: 1.1837\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9208    0.8045    0.8587      2501\n         1.0     0.1205    0.2792    0.1683       240\n\n    accuracy                         0.7585      2741\n   macro avg     0.5207    0.5418    0.5135      2741\nweighted avg     0.8507    0.7585    0.7983      2741\n\nTest Macro F1: 0.5135349174382369\n\nEpoch 395 | Loss: 1.1860\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9190    0.7989    0.8548      2501\n         1.0     0.1129    0.2667    0.1586       240\n\n    accuracy                         0.7523      2741\n   macro avg     0.5160    0.5328    0.5067      2741\nweighted avg     0.8485    0.7523    0.7938      2741\n\nTest Macro F1: 0.5066857510155126\n\nEpoch 396 | Loss: 1.1801\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9168    0.7097    0.8001      2501\n         1.0     0.0981    0.3292    0.1512       240\n\n    accuracy                         0.6764      2741\n   macro avg     0.5075    0.5194    0.4756      2741\nweighted avg     0.8452    0.6764    0.7433      2741\n\nTest Macro F1: 0.47564316162586684\n\nEpoch 397 | Loss: 1.1806\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9228    0.5402    0.6815      2501\n         1.0     0.0995    0.5292    0.1674       240\n\n    accuracy                         0.5392      2741\n   macro avg     0.5111    0.5347    0.4244      2741\nweighted avg     0.8507    0.5392    0.6365      2741\n\nTest Macro F1: 0.4244492639534623\n\nEpoch 398 | Loss: 1.1901\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9182    0.6285    0.7463      2501\n         1.0     0.0972    0.4167    0.1576       240\n\n    accuracy                         0.6100      2741\n   macro avg     0.5077    0.5226    0.4519      2741\nweighted avg     0.8463    0.6100    0.6947      2741\n\nTest Macro F1: 0.45193299212520366\n\nEpoch 399 | Loss: 1.1862\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9199    0.7713    0.8391      2501\n         1.0     0.1118    0.3000    0.1629       240\n\n    accuracy                         0.7300      2741\n   macro avg     0.5158    0.5356    0.5010      2741\nweighted avg     0.8491    0.7300    0.7799      2741\n\nTest Macro F1: 0.5009781943359202\n\nEpoch 400 | Loss: 1.1877\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9179    0.6925    0.7894      2501\n         1.0     0.0995    0.3542    0.1554       240\n\n    accuracy                         0.6629      2741\n   macro avg     0.5087    0.5233    0.4724      2741\nweighted avg     0.8462    0.6629    0.7339      2741\n\nTest Macro F1: 0.4724093797443252\n\nEpoch 401 | Loss: 1.1891\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9227    0.5250    0.6692      2501\n         1.0     0.0986    0.5417    0.1669       240\n\n    accuracy                         0.5265      2741\n   macro avg     0.5107    0.5333    0.4180      2741\nweighted avg     0.8505    0.5265    0.6252      2741\n\nTest Macro F1: 0.41804785141043105\n\nEpoch 402 | Loss: 1.1874\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9186    0.6273    0.7455      2501\n         1.0     0.0978    0.4208    0.1587       240\n\n    accuracy                         0.6093      2741\n   macro avg     0.5082    0.5241    0.4521      2741\nweighted avg     0.8467    0.6093    0.6942      2741\n\nTest Macro F1: 0.4521127714766753\n\nEpoch 403 | Loss: 1.1806\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9183    0.7637    0.8339      2501\n         1.0     0.1059    0.2917    0.1554       240\n\n    accuracy                         0.7224      2741\n   macro avg     0.5121    0.5277    0.4946      2741\nweighted avg     0.8471    0.7224    0.7745      2741\n\nTest Macro F1: 0.4946309867931554\n\nEpoch 404 | Loss: 1.1786\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9181    0.8429    0.8789      2501\n         1.0     0.1169    0.2167    0.1518       240\n\n    accuracy                         0.7880      2741\n   macro avg     0.5175    0.5298    0.5154      2741\nweighted avg     0.8480    0.7880    0.8152      2741\n\nTest Macro F1: 0.515353726249222\n\nEpoch 405 | Loss: 1.1903\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9214    0.6941    0.7918      2501\n         1.0     0.1074    0.3833    0.1677       240\n\n    accuracy                         0.6669      2741\n   macro avg     0.5144    0.5387    0.4798      2741\nweighted avg     0.8502    0.6669    0.7371      2741\n\nTest Macro F1: 0.47976018352114036\n\nEpoch 406 | Loss: 1.1798\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9255    0.5214    0.6670      2501\n         1.0     0.1014    0.5625    0.1718       240\n\n    accuracy                         0.5250      2741\n   macro avg     0.5134    0.5419    0.4194      2741\nweighted avg     0.8533    0.5250    0.6236      2741\n\nTest Macro F1: 0.41938169891255545\n\nEpoch 407 | Loss: 1.1944\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9245    0.6022    0.7293      2501\n         1.0     0.1052    0.4875    0.1731       240\n\n    accuracy                         0.5921      2741\n   macro avg     0.5149    0.5448    0.4512      2741\nweighted avg     0.8528    0.5921    0.6806      2741\n\nTest Macro F1: 0.45118737195008385\n\nEpoch 408 | Loss: 1.1854\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9177    0.7801    0.8433      2501\n         1.0     0.1057    0.2708    0.1520       240\n\n    accuracy                         0.7355      2741\n   macro avg     0.5117    0.5255    0.4977      2741\nweighted avg     0.8466    0.7355    0.7828      2741\n\nTest Macro F1: 0.49767889213704963\n\nEpoch 409 | Loss: 1.1847\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9179    0.7465    0.8234      2501\n         1.0     0.1033    0.3042    0.1542       240\n\n    accuracy                         0.7078      2741\n   macro avg     0.5106    0.5253    0.4888      2741\nweighted avg     0.8466    0.7078    0.7648      2741\n\nTest Macro F1: 0.48877241308652986\n\nEpoch 410 | Loss: 1.1849\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9200    0.5934    0.7214      2501\n         1.0     0.0984    0.4625    0.1623       240\n\n    accuracy                         0.5819      2741\n   macro avg     0.5092    0.5279    0.4419      2741\nweighted avg     0.8481    0.5819    0.6725      2741\n\nTest Macro F1: 0.4418598452865269\n\nEpoch 411 | Loss: 1.1794\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9263    0.5430    0.6846      2501\n         1.0     0.1035    0.5500    0.1743       240\n\n    accuracy                         0.5436      2741\n   macro avg     0.5149    0.5465    0.4295      2741\nweighted avg     0.8543    0.5436    0.6400      2741\n\nTest Macro F1: 0.42945288731040987\n\nEpoch 412 | Loss: 1.1659\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9208    0.6138    0.7366      2501\n         1.0     0.1006    0.4500    0.1644       240\n\n    accuracy                         0.5994      2741\n   macro avg     0.5107    0.5319    0.4505      2741\nweighted avg     0.8490    0.5994    0.6865      2741\n\nTest Macro F1: 0.4504739305340099\n\nEpoch 413 | Loss: 1.1861\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9175    0.7157    0.8041      2501\n         1.0     0.1000    0.3292    0.1534       240\n\n    accuracy                         0.6819      2741\n   macro avg     0.5087    0.5224    0.4788      2741\nweighted avg     0.8459    0.6819    0.7472      2741\n\nTest Macro F1: 0.47876551609836093\n\nEpoch 414 | Loss: 1.1757\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9179    0.7333    0.8153      2501\n         1.0     0.1023    0.3167    0.1546       240\n\n    accuracy                         0.6968      2741\n   macro avg     0.5101    0.5250    0.4850      2741\nweighted avg     0.8465    0.6968    0.7574      2741\n\nTest Macro F1: 0.48496048743283515\n\nEpoch 415 | Loss: 1.1776\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9201    0.6677    0.7739      2501\n         1.0     0.1026    0.3958    0.1630       240\n\n    accuracy                         0.6439      2741\n   macro avg     0.5114    0.5318    0.4684      2741\nweighted avg     0.8485    0.6439    0.7204      2741\n\nTest Macro F1: 0.46840747340861\n\nEpoch 416 | Loss: 1.1876\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9165    0.7813    0.8435      2501\n         1.0     0.1018    0.2583    0.1461       240\n\n    accuracy                         0.7355      2741\n   macro avg     0.5092    0.5198    0.4948      2741\nweighted avg     0.8452    0.7355    0.7824      2741\n\nTest Macro F1: 0.49478405162737643\n\nEpoch 417 | Loss: 1.1858\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9171    0.7609    0.8317      2501\n         1.0     0.1021    0.2833    0.1501       240\n\n    accuracy                         0.7191      2741\n   macro avg     0.5096    0.5221    0.4909      2741\nweighted avg     0.8457    0.7191    0.7720      2741\n\nTest Macro F1: 0.4909205722533537\n\nEpoch 418 | Loss: 1.1731\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9172    0.6381    0.7527      2501\n         1.0     0.0959    0.4000    0.1547       240\n\n    accuracy                         0.6173      2741\n   macro avg     0.5066    0.5191    0.4537      2741\nweighted avg     0.8453    0.6173    0.7003      2741\n\nTest Macro F1: 0.4536833083131344\n\nEpoch 419 | Loss: 1.1795\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9229    0.5506    0.6897      2501\n         1.0     0.1001    0.5208    0.1679       240\n\n    accuracy                         0.5480      2741\n   macro avg     0.5115    0.5357    0.4288      2741\nweighted avg     0.8509    0.5480    0.6440      2741\n\nTest Macro F1: 0.42880245264673217\n\nEpoch 420 | Loss: 1.1750\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9224    0.5938    0.7225      2501\n         1.0     0.1017    0.4792    0.1678       240\n\n    accuracy                         0.5837      2741\n   macro avg     0.5120    0.5365    0.4451      2741\nweighted avg     0.8505    0.5837    0.6739      2741\n\nTest Macro F1: 0.445106358365709\n\nEpoch 421 | Loss: 1.1742\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9187    0.6505    0.7617      2501\n         1.0     0.0990    0.4000    0.1587       240\n\n    accuracy                         0.6286      2741\n   macro avg     0.5088    0.5253    0.4602      2741\nweighted avg     0.8469    0.6286    0.7089      2741\n\nTest Macro F1: 0.46019090290030024\n\nEpoch 422 | Loss: 1.1751\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9186    0.7629    0.8336      2501\n         1.0     0.1069    0.2958    0.1571       240\n\n    accuracy                         0.7220      2741\n   macro avg     0.5128    0.5294    0.4953      2741\nweighted avg     0.8476    0.7220    0.7743      2741\n\nTest Macro F1: 0.4953157076746425\n\nEpoch 423 | Loss: 1.1832\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9193    0.6925    0.7900      2501\n         1.0     0.1027    0.3667    0.1604       240\n\n    accuracy                         0.6640      2741\n   macro avg     0.5110    0.5296    0.4752      2741\nweighted avg     0.8478    0.6640    0.7348      2741\n\nTest Macro F1: 0.4752016747239543\n\nEpoch 424 | Loss: 1.1781\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9238    0.5234    0.6682      2501\n         1.0     0.0997    0.5500    0.1688       240\n\n    accuracy                         0.5257      2741\n   macro avg     0.5117    0.5367    0.4185      2741\nweighted avg     0.8516    0.5257    0.6245      2741\n\nTest Macro F1: 0.418498007099504\n\nEpoch 425 | Loss: 1.1819\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9232    0.5578    0.6954      2501\n         1.0     0.1008    0.5167    0.1687       240\n\n    accuracy                         0.5542      2741\n   macro avg     0.5120    0.5372    0.4321      2741\nweighted avg     0.8512    0.5542    0.6493      2741\n\nTest Macro F1: 0.4320606208585129\n\nEpoch 426 | Loss: 1.1870\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9180    0.8017    0.8559      2501\n         1.0     0.1095    0.2542    0.1531       240\n\n    accuracy                         0.7537      2741\n   macro avg     0.5138    0.5279    0.5045      2741\nweighted avg     0.8472    0.7537    0.7944      2741\n\nTest Macro F1: 0.504498593310828\n\nEpoch 427 | Loss: 1.1841\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9177    0.8477    0.8813      2501\n         1.0     0.1160    0.2083    0.1490       240\n\n    accuracy                         0.7917      2741\n   macro avg     0.5169    0.5280    0.5152      2741\nweighted avg     0.8475    0.7917    0.8172      2741\n\nTest Macro F1: 0.5151724763884058\n\nEpoch 428 | Loss: 1.1986\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9233    0.5822    0.7141      2501\n         1.0     0.1022    0.4958    0.1695       240\n\n    accuracy                         0.5746      2741\n   macro avg     0.5128    0.5390    0.4418      2741\nweighted avg     0.8514    0.5746    0.6664      2741\n\nTest Macro F1: 0.4417955983674473\n\nEpoch 429 | Loss: 1.1766\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9266    0.4342    0.5913      2501\n         1.0     0.0982    0.6417    0.1703       240\n\n    accuracy                         0.4524      2741\n   macro avg     0.5124    0.5379    0.3808      2741\nweighted avg     0.8541    0.4524    0.5545      2741\n\nTest Macro F1: 0.38080101955660184\n\nEpoch 430 | Loss: 1.1939\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9208    0.6369    0.7530      2501\n         1.0     0.1019    0.4292    0.1647       240\n\n    accuracy                         0.6188      2741\n   macro avg     0.5113    0.5331    0.4588      2741\nweighted avg     0.8491    0.6188    0.7015      2741\n\nTest Macro F1: 0.4588408686900633\n\nEpoch 431 | Loss: 1.1589\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9182    0.8792    0.8983      2501\n         1.0     0.1272    0.1833    0.1502       240\n\n    accuracy                         0.8183      2741\n   macro avg     0.5227    0.5313    0.5242      2741\nweighted avg     0.8489    0.8183    0.8328      2741\n\nTest Macro F1: 0.5242274810948271\nNew Best: 0.5242274810948271 epoch: 431\n\nEpoch 432 | Loss: 1.1844\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9176    0.7921    0.8502      2501\n         1.0     0.1065    0.2583    0.1509       240\n\n    accuracy                         0.7453      2741\n   macro avg     0.5120    0.5252    0.5005      2741\nweighted avg     0.8465    0.7453    0.7890      2741\n\nTest Macro F1: 0.5005330868915969\n\nEpoch 433 | Loss: 1.1840\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9237    0.5226    0.6675      2501\n         1.0     0.0995    0.5500    0.1686       240\n\n    accuracy                         0.5250      2741\n   macro avg     0.5116    0.5363    0.4181      2741\nweighted avg     0.8515    0.5250    0.6238      2741\n\nTest Macro F1: 0.4180501254309855\n\nEpoch 434 | Loss: 1.1729\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9237    0.5470    0.6871      2501\n         1.0     0.1008    0.5292    0.1693       240\n\n    accuracy                         0.5454      2741\n   macro avg     0.5122    0.5381    0.4282      2741\nweighted avg     0.8516    0.5454    0.6418      2741\n\nTest Macro F1: 0.42821262347229194\n\nEpoch 435 | Loss: 1.1761\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9169    0.7413    0.8198      2501\n         1.0     0.1001    0.3000    0.1502       240\n\n    accuracy                         0.7027      2741\n   macro avg     0.5085    0.5207    0.4850      2741\nweighted avg     0.8454    0.7027    0.7612      2741\n\nTest Macro F1: 0.48498313682102623\n\nEpoch 436 | Loss: 1.1773\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9168    0.8237    0.8677      2501\n         1.0     0.1073    0.2208    0.1444       240\n\n    accuracy                         0.7709      2741\n   macro avg     0.5120    0.5223    0.5061      2741\nweighted avg     0.8459    0.7709    0.8044      2741\n\nTest Macro F1: 0.5060739757913271\n\nEpoch 437 | Loss: 1.1745\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9224    0.6134    0.7368      2501\n         1.0     0.1030    0.4625    0.1684       240\n\n    accuracy                         0.6001      2741\n   macro avg     0.5127    0.5379    0.4526      2741\nweighted avg     0.8507    0.6001    0.6870      2741\n\nTest Macro F1: 0.4526142861932395\n\nEpoch 438 | Loss: 1.1705\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9227    0.5490    0.6884      2501\n         1.0     0.0998    0.5208    0.1674       240\n\n    accuracy                         0.5465      2741\n   macro avg     0.5112    0.5349    0.4279      2741\nweighted avg     0.8507    0.5465    0.6428      2741\n\nTest Macro F1: 0.4279205860322182\n\nEpoch 439 | Loss: 1.1613\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9186    0.6493    0.7608      2501\n         1.0     0.0987    0.4000    0.1583       240\n\n    accuracy                         0.6275      2741\n   macro avg     0.5086    0.5247    0.4596      2741\nweighted avg     0.8468    0.6275    0.7081      2741\n\nTest Macro F1: 0.4595595810746274\n\nEpoch 440 | Loss: 1.1715\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9181    0.8069    0.8589      2501\n         1.0     0.1105    0.2500    0.1533       240\n\n    accuracy                         0.7581      2741\n   macro avg     0.5143    0.5284    0.5061      2741\nweighted avg     0.8474    0.7581    0.7971      2741\n\nTest Macro F1: 0.506081427612788\n\nEpoch 441 | Loss: 1.1733\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9169    0.7813    0.8437      2501\n         1.0     0.1033    0.2625    0.1482       240\n\n    accuracy                         0.7359      2741\n   macro avg     0.5101    0.5219    0.4960      2741\nweighted avg     0.8457    0.7359    0.7828      2741\n\nTest Macro F1: 0.4959656608757492\n\nEpoch 442 | Loss: 1.1816\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9199    0.6202    0.7409      2501\n         1.0     0.0995    0.4375    0.1622       240\n\n    accuracy                         0.6042      2741\n   macro avg     0.5097    0.5288    0.4515      2741\nweighted avg     0.8481    0.6042    0.6902      2741\n\nTest Macro F1: 0.45151337150381815\n\nEpoch 443 | Loss: 1.1736\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9193    0.6106    0.7338      2501\n         1.0     0.0981    0.4417    0.1606       240\n\n    accuracy                         0.5958      2741\n   macro avg     0.5087    0.5261    0.4472      2741\nweighted avg     0.8474    0.5958    0.6836      2741\n\nTest Macro F1: 0.44719394813099766\n\nEpoch 444 | Loss: 1.1703\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9186    0.6809    0.7821      2501\n         1.0     0.1003    0.3708    0.1579       240\n\n    accuracy                         0.6538      2741\n   macro avg     0.5094    0.5259    0.4700      2741\nweighted avg     0.8469    0.6538    0.7274      2741\n\nTest Macro F1: 0.4700154948416745\n\nEpoch 445 | Loss: 1.1668\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9179    0.7509    0.8260      2501\n         1.0     0.1036    0.3000    0.1540       240\n\n    accuracy                         0.7114      2741\n   macro avg     0.5107    0.5254    0.4900      2741\nweighted avg     0.8466    0.7114    0.7672      2741\n\nTest Macro F1: 0.4900249209386456\n\nEpoch 446 | Loss: 1.1568\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9180    0.7609    0.8321      2501\n         1.0     0.1048    0.2917    0.1542       240\n\n    accuracy                         0.7198      2741\n   macro avg     0.5114    0.5263    0.4931      2741\nweighted avg     0.8468    0.7198    0.7727      2741\n\nTest Macro F1: 0.4931397344500326\n\nEpoch 447 | Loss: 1.1709\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9215    0.6150    0.7376      2501\n         1.0     0.1017    0.4542    0.1662       240\n\n    accuracy                         0.6009      2741\n   macro avg     0.5116    0.5346    0.4519      2741\nweighted avg     0.8497    0.6009    0.6876      2741\n\nTest Macro F1: 0.45190420834064454\n\nEpoch 448 | Loss: 1.1714\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9242    0.5266    0.6709      2501\n         1.0     0.1003    0.5500    0.1697       240\n\n    accuracy                         0.5286      2741\n   macro avg     0.5123    0.5383    0.4203      2741\nweighted avg     0.8521    0.5286    0.6270      2741\n\nTest Macro F1: 0.42028883967800185\n\nEpoch 449 | Loss: 1.1676\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9214    0.5814    0.7129      2501\n         1.0     0.0997    0.4833    0.1654       240\n\n    accuracy                         0.5728      2741\n   macro avg     0.5106    0.5324    0.4391      2741\nweighted avg     0.8495    0.5728    0.6650      2741\n\nTest Macro F1: 0.4391398881359018\n\nEpoch 450 | Loss: 1.1746\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9184    0.7425    0.8211      2501\n         1.0     0.1043    0.3125    0.1564       240\n\n    accuracy                         0.7049      2741\n   macro avg     0.5114    0.5275    0.4888      2741\nweighted avg     0.8471    0.7049    0.7629      2741\n\nTest Macro F1: 0.4887746720100739\n\nEpoch 451 | Loss: 1.1726\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9176    0.8417    0.8780      2501\n         1.0     0.1141    0.2125    0.1485       240\n\n    accuracy                         0.7866      2741\n   macro avg     0.5159    0.5271    0.5132      2741\nweighted avg     0.8473    0.7866    0.8141      2741\n\nTest Macro F1: 0.5132347651073945\n\nEpoch 452 | Loss: 1.1775\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9180    0.6397    0.7540      2501\n         1.0     0.0972    0.4042    0.1567       240\n\n    accuracy                         0.6191      2741\n   macro avg     0.5076    0.5220    0.4554      2741\nweighted avg     0.8461    0.6191    0.7017      2741\n\nTest Macro F1: 0.45535500845820154\n\nEpoch 453 | Loss: 1.1737\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9238    0.4942    0.6439      2501\n         1.0     0.0984    0.5750    0.1680       240\n\n    accuracy                         0.5013      2741\n   macro avg     0.5111    0.5346    0.4060      2741\nweighted avg     0.8515    0.5013    0.6022      2741\n\nTest Macro F1: 0.4059515397360942\n\nEpoch 454 | Loss: 1.1637\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9230    0.5414    0.6825      2501\n         1.0     0.0997    0.5292    0.1678       240\n\n    accuracy                         0.5403      2741\n   macro avg     0.5113    0.5353    0.4251      2741\nweighted avg     0.8509    0.5403    0.6374      2741\n\nTest Macro F1: 0.4251135903609324\n\nEpoch 455 | Loss: 1.1716\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9181    0.7481    0.8244      2501\n         1.0     0.1038    0.3042    0.1548       240\n\n    accuracy                         0.7092      2741\n   macro avg     0.5109    0.5261    0.4896      2741\nweighted avg     0.8468    0.7092    0.7658      2741\n\nTest Macro F1: 0.4896178448263979\n\nEpoch 456 | Loss: 1.1718\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9187    0.8229    0.8682      2501\n         1.0     0.1158    0.2417    0.1565       240\n\n    accuracy                         0.7720      2741\n   macro avg     0.5173    0.5323    0.5124      2741\nweighted avg     0.8484    0.7720    0.8059      2741\n\nTest Macro F1: 0.5123582405301785\n\nEpoch 457 | Loss: 1.1772\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9188    0.6649    0.7715      2501\n         1.0     0.0999    0.3875    0.1588       240\n\n    accuracy                         0.6406      2741\n   macro avg     0.5093    0.5262    0.4652      2741\nweighted avg     0.8471    0.6406    0.7179      2741\n\nTest Macro F1: 0.4651766646243468\n\nEpoch 458 | Loss: 1.1647\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9235    0.5162    0.6622      2501\n         1.0     0.0990    0.5542    0.1680       240\n\n    accuracy                         0.5195      2741\n   macro avg     0.5112    0.5352    0.4151      2741\nweighted avg     0.8513    0.5195    0.6190      2741\n\nTest Macro F1: 0.41512822909870306\n\nEpoch 459 | Loss: 1.1626\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9207    0.5522    0.6903      2501\n         1.0     0.0975    0.5042    0.1634       240\n\n    accuracy                         0.5480      2741\n   macro avg     0.5091    0.5282    0.4269      2741\nweighted avg     0.8486    0.5480    0.6442      2741\n\nTest Macro F1: 0.42686526207745834\n\nEpoch 460 | Loss: 1.1613\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9159    0.7705    0.8369      2501\n         1.0     0.0989    0.2625    0.1437       240\n\n    accuracy                         0.7260      2741\n   macro avg     0.5074    0.5165    0.4903      2741\nweighted avg     0.8443    0.7260    0.7762      2741\n\nTest Macro F1: 0.49029400148814495\n\nEpoch 461 | Loss: 1.1599\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9160    0.8237    0.8674      2501\n         1.0     0.1037    0.2125    0.1393       240\n\n    accuracy                         0.7702      2741\n   macro avg     0.5098    0.5181    0.5034      2741\nweighted avg     0.8448    0.7702    0.8036      2741\n\nTest Macro F1: 0.5033563416738568\n\nEpoch 462 | Loss: 1.1819\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9170    0.6094    0.7322      2501\n         1.0     0.0945    0.4250    0.1547       240\n\n    accuracy                         0.5932      2741\n   macro avg     0.5057    0.5172    0.4434      2741\nweighted avg     0.8450    0.5932    0.6816      2741\n\nTest Macro F1: 0.4434134638937155\n\nEpoch 463 | Loss: 1.1700\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9227    0.4726    0.6251      2501\n         1.0     0.0966    0.5875    0.1659       240\n\n    accuracy                         0.4827      2741\n   macro avg     0.5096    0.5301    0.3955      2741\nweighted avg     0.8504    0.4827    0.5849      2741\n\nTest Macro F1: 0.395474227766199\n\nEpoch 464 | Loss: 1.1755\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9176    0.6238    0.7427      2501\n         1.0     0.0961    0.4167    0.1561       240\n\n    accuracy                         0.6056      2741\n   macro avg     0.5069    0.5202    0.4494      2741\nweighted avg     0.8457    0.6056    0.6913      2741\n\nTest Macro F1: 0.44940416959569307\n\nEpoch 465 | Loss: 1.1736\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9164    0.8373    0.8751      2501\n         1.0     0.1075    0.2042    0.1408       240\n\n    accuracy                         0.7818      2741\n   macro avg     0.5119    0.5207    0.5079      2741\nweighted avg     0.8456    0.7818    0.8108      2741\n\nTest Macro F1: 0.5079284166942856\n\nEpoch 466 | Loss: 1.1679\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9157    0.7909    0.8487      2501\n         1.0     0.0998    0.2417    0.1413       240\n\n    accuracy                         0.7428      2741\n   macro avg     0.5078    0.5163    0.4950      2741\nweighted avg     0.8443    0.7428    0.7868      2741\n\nTest Macro F1: 0.4950180064656552\n\nEpoch 467 | Loss: 1.1821\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9212    0.5282    0.6714      2501\n         1.0     0.0972    0.5292    0.1642       240\n\n    accuracy                         0.5283      2741\n   macro avg     0.5092    0.5287    0.4178      2741\nweighted avg     0.8490    0.5283    0.6270      2741\n\nTest Macro F1: 0.4177995858689483\n\nEpoch 468 | Loss: 1.1764\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9215    0.4602    0.6139      2501\n         1.0     0.0952    0.5917    0.1640       240\n\n    accuracy                         0.4717      2741\n   macro avg     0.5084    0.5259    0.3889      2741\nweighted avg     0.8492    0.4717    0.5745      2741\n\nTest Macro F1: 0.3889194765204003\n\nEpoch 469 | Loss: 1.1853\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9179    0.5898    0.7181      2501\n         1.0     0.0952    0.4500    0.1572       240\n\n    accuracy                         0.5775      2741\n   macro avg     0.5065    0.5199    0.4377      2741\nweighted avg     0.8458    0.5775    0.6690      2741\n\nTest Macro F1: 0.43765812154790096\n\nEpoch 470 | Loss: 1.1541\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9163    0.8097    0.8597      2501\n         1.0     0.1036    0.2292    0.1427       240\n\n    accuracy                         0.7588      2741\n   macro avg     0.5099    0.5194    0.5012      2741\nweighted avg     0.8451    0.7588    0.7969      2741\n\nTest Macro F1: 0.501180970882233\n\nEpoch 471 | Loss: 1.1773\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9164    0.7841    0.8451      2501\n         1.0     0.1015    0.2542    0.1451       240\n\n    accuracy                         0.7377      2741\n   macro avg     0.5089    0.5191    0.4951      2741\nweighted avg     0.8450    0.7377    0.7838      2741\n\nTest Macro F1: 0.4950709452353154\n\nEpoch 472 | Loss: 1.1627\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9216    0.6014    0.7278      2501\n         1.0     0.1010    0.4667    0.1660       240\n\n    accuracy                         0.5896      2741\n   macro avg     0.5113    0.5340    0.4469      2741\nweighted avg     0.8497    0.5896    0.6786      2741\n\nTest Macro F1: 0.44692477710635814\n\nEpoch 473 | Loss: 1.1708\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9253    0.5002    0.6494      2501\n         1.0     0.1001    0.5792    0.1707       240\n\n    accuracy                         0.5071      2741\n   macro avg     0.5127    0.5397    0.4100      2741\nweighted avg     0.8530    0.5071    0.6074      2741\n\nTest Macro F1: 0.4100104882676546\n\nEpoch 474 | Loss: 1.1644\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9196    0.6309    0.7484      2501\n         1.0     0.0995    0.4250    0.1613       240\n\n    accuracy                         0.6129      2741\n   macro avg     0.5095    0.5280    0.4548      2741\nweighted avg     0.8478    0.6129    0.6970      2741\n\nTest Macro F1: 0.4548320790776277\n\nEpoch 475 | Loss: 1.1721\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9163    0.8225    0.8668      2501\n         1.0     0.1048    0.2167    0.1413       240\n\n    accuracy                         0.7694      2741\n   macro avg     0.5105    0.5196    0.5041      2741\nweighted avg     0.8452    0.7694    0.8033      2741\n\nTest Macro F1: 0.5040697887465875\n\nEpoch 476 | Loss: 1.1666\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9162    0.7957    0.8517      2501\n         1.0     0.1019    0.2417    0.1434       240\n\n    accuracy                         0.7472      2741\n   macro avg     0.5091    0.5187    0.4975      2741\nweighted avg     0.8449    0.7472    0.7897      2741\n\nTest Macro F1: 0.49754407998821304\n\nEpoch 477 | Loss: 1.1562\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9207    0.6126    0.7357      2501\n         1.0     0.1003    0.4500    0.1640       240\n\n    accuracy                         0.5983      2741\n   macro avg     0.5105    0.5313    0.4498      2741\nweighted avg     0.8488    0.5983    0.6856      2741\n\nTest Macro F1: 0.44983168666099693\n\nEpoch 478 | Loss: 1.1586\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9194    0.6613    0.7693      2501\n         1.0     0.1008    0.3958    0.1607       240\n\n    accuracy                         0.6381      2741\n   macro avg     0.5101    0.5286    0.4650      2741\nweighted avg     0.8477    0.6381    0.7160      2741\n\nTest Macro F1: 0.46502341321370955\n\nEpoch 479 | Loss: 1.1766\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9191    0.6589    0.7676      2501\n         1.0     0.1002    0.3958    0.1599       240\n\n    accuracy                         0.6359      2741\n   macro avg     0.5097    0.5274    0.4638      2741\nweighted avg     0.8474    0.6359    0.7144      2741\n\nTest Macro F1: 0.46375766671528207\n\nEpoch 480 | Loss: 1.1690\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9199    0.6106    0.7340      2501\n         1.0     0.0990    0.4458    0.1620       240\n\n    accuracy                         0.5961      2741\n   macro avg     0.5094    0.5282    0.4480      2741\nweighted avg     0.8480    0.5961    0.6839      2741\n\nTest Macro F1: 0.4479783345622568\n\nEpoch 481 | Loss: 1.1707\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9194    0.5610    0.6968      2501\n         1.0     0.0963    0.4875    0.1608       240\n\n    accuracy                         0.5545      2741\n   macro avg     0.5078    0.5242    0.4288      2741\nweighted avg     0.8473    0.5545    0.6499      2741\n\nTest Macro F1: 0.42881068253208365\n\nEpoch 482 | Loss: 1.1636\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9185    0.5770    0.7087      2501\n         1.0     0.0957    0.4667    0.1589       240\n\n    accuracy                         0.5673      2741\n   macro avg     0.5071    0.5218    0.4338      2741\nweighted avg     0.8465    0.5673    0.6606      2741\n\nTest Macro F1: 0.43380394041995846\n\nEpoch 483 | Loss: 1.1643\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9198    0.6373    0.7530      2501\n         1.0     0.1002    0.4208    0.1619       240\n\n    accuracy                         0.6184      2741\n   macro avg     0.5100    0.5291    0.4574      2741\nweighted avg     0.8480    0.6184    0.7012      2741\n\nTest Macro F1: 0.4574056326683865\n\nEpoch 484 | Loss: 1.1713\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9200    0.6993    0.7946      2501\n         1.0     0.1048    0.3667    0.1630       240\n\n    accuracy                         0.6702      2741\n   macro avg     0.5124    0.5330    0.4788      2741\nweighted avg     0.8487    0.6702    0.7393      2741\n\nTest Macro F1: 0.47880088175408486\n\nEpoch 485 | Loss: 1.1687\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9186    0.7269    0.8116      2501\n         1.0     0.1037    0.3292    0.1577       240\n\n    accuracy                         0.6921      2741\n   macro avg     0.5112    0.5280    0.4846      2741\nweighted avg     0.8473    0.6921    0.7544      2741\n\nTest Macro F1: 0.48464588679783294\n\nEpoch 486 | Loss: 1.1607\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9198    0.6509    0.7624      2501\n         1.0     0.1009    0.4083    0.1618       240\n\n    accuracy                         0.6297      2741\n   macro avg     0.5104    0.5296    0.4621      2741\nweighted avg     0.8481    0.6297    0.7098      2741\n\nTest Macro F1: 0.4621002242574264\n\nEpoch 487 | Loss: 1.1640\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9187    0.6825    0.7832      2501\n         1.0     0.1008    0.3708    0.1585       240\n\n    accuracy                         0.6552      2741\n   macro avg     0.5098    0.5267    0.4709      2741\nweighted avg     0.8471    0.6552    0.7285      2741\n\nTest Macro F1: 0.4708555823643654\n\nEpoch 488 | Loss: 1.1518\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9191    0.6673    0.7732      2501\n         1.0     0.1005    0.3875    0.1597       240\n\n    accuracy                         0.6428      2741\n   macro avg     0.5098    0.5274    0.4664      2741\nweighted avg     0.8474    0.6428    0.7195      2741\n\nTest Macro F1: 0.4664393986843113\n\nEpoch 489 | Loss: 1.1575\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9187    0.7097    0.8008      2501\n         1.0     0.1026    0.3458    0.1582       240\n\n    accuracy                         0.6779      2741\n   macro avg     0.5107    0.5278    0.4795      2741\nweighted avg     0.8473    0.6779    0.7445      2741\n\nTest Macro F1: 0.479529019828537\n\nEpoch 490 | Loss: 1.1640\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9183    0.7233    0.8092      2501\n         1.0     0.1025    0.3292    0.1563       240\n\n    accuracy                         0.6888      2741\n   macro avg     0.5104    0.5262    0.4827      2741\nweighted avg     0.8468    0.6888    0.7520      2741\n\nTest Macro F1: 0.4827479253596261\n\nEpoch 491 | Loss: 1.1483\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9195    0.6853    0.7853      2501\n         1.0     0.1026    0.3750    0.1611       240\n\n    accuracy                         0.6582      2741\n   macro avg     0.5111    0.5302    0.4732      2741\nweighted avg     0.8480    0.6582    0.7307      2741\n\nTest Macro F1: 0.47324192091195016\n\nEpoch 492 | Loss: 1.1634\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9186    0.5774    0.7091      2501\n         1.0     0.0958    0.4667    0.1590       240\n\n    accuracy                         0.5677      2741\n   macro avg     0.5072    0.5220    0.4340      2741\nweighted avg     0.8465    0.5677    0.6609      2741\n\nTest Macro F1: 0.4340188298819782\n\nEpoch 493 | Loss: 1.1557\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9183    0.5570    0.6934      2501\n         1.0     0.0948    0.4833    0.1585       240\n\n    accuracy                         0.5505      2741\n   macro avg     0.5065    0.5202    0.4259      2741\nweighted avg     0.8462    0.5505    0.6465      2741\n\nTest Macro F1: 0.4259248681479789\n\nEpoch 494 | Loss: 1.1715\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9196    0.6633    0.7707      2501\n         1.0     0.1014    0.3958    0.1614       240\n\n    accuracy                         0.6399      2741\n   macro avg     0.5105    0.5296    0.4661      2741\nweighted avg     0.8480    0.6399    0.7174      2741\n\nTest Macro F1: 0.4660795325030566\n\nEpoch 495 | Loss: 1.1575\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9181    0.7661    0.8352      2501\n         1.0     0.1055    0.2875    0.1544       240\n\n    accuracy                         0.7242      2741\n   macro avg     0.5118    0.5268    0.4948      2741\nweighted avg     0.8469    0.7242    0.7756      2741\n\nTest Macro F1: 0.4947923676003347\n\nEpoch 496 | Loss: 1.1797\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9193    0.7377    0.8185      2501\n         1.0     0.1063    0.3250    0.1602       240\n\n    accuracy                         0.7016      2741\n   macro avg     0.5128    0.5314    0.4894      2741\nweighted avg     0.8481    0.7016    0.7609      2741\n\nTest Macro F1: 0.4893545401376335\n\nEpoch 497 | Loss: 1.1634\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9192    0.6054    0.7300      2501\n         1.0     0.0978    0.4458    0.1604       240\n\n    accuracy                         0.5914      2741\n   macro avg     0.5085    0.5256    0.4452      2741\nweighted avg     0.8473    0.5914    0.6801      2741\n\nTest Macro F1: 0.4452050734517023\n\nEpoch 498 | Loss: 1.1588\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9202    0.6090    0.7329      2501\n         1.0     0.0994    0.4500    0.1629       240\n\n    accuracy                         0.5950      2741\n   macro avg     0.5098    0.5295    0.4479      2741\nweighted avg     0.8484    0.5950    0.6830      2741\n\nTest Macro F1: 0.4479060966209242\n\nEpoch 499 | Loss: 1.1707\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9189    0.8157    0.8642      2501\n         1.0     0.1152    0.2500    0.1577       240\n\n    accuracy                         0.7661      2741\n   macro avg     0.5170    0.5328    0.5110      2741\nweighted avg     0.8485    0.7661    0.8024      2741\n\nTest Macro F1: 0.5109554675185468\n\nEpoch 500 | Loss: 1.1563\nTest Report:\n               precision    recall  f1-score   support\n\n         0.0     0.9176    0.7841    0.8456      2501\n         1.0     0.1060    0.2667    0.1517       240\n\n    accuracy                         0.7388      2741\n   macro avg     0.5118    0.5254    0.4986      2741\nweighted avg     0.8466    0.7388    0.7849      2741\n\nTest Macro F1: 0.4986409405917324\nBest Score: 0.5242274810948271\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Plot\nplot_training_history(losses, macro_f1s)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:41:30.949759Z","iopub.execute_input":"2025-04-15T16:41:30.950102Z","iopub.status.idle":"2025-04-15T16:41:31.207877Z","shell.execute_reply.started":"2025-04-15T16:41:30.950062Z","shell.execute_reply":"2025-04-15T16:41:31.207207Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Evaluate\nval_report, val_f1, val_cm = evaluate(best_model, val_data)\ntest_report, test_f1, test_cm = evaluate(best_model, test_data)\n\nprint(\"Validation Results:\\n\", val_report, \"\\nMacro F1:\", val_f1)\nprint(\"Test Results:\\n\", test_report, \"\\nMacro F1:\", test_f1)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-15T16:43:37.849313Z","iopub.execute_input":"2025-04-15T16:43:37.850017Z","iopub.status.idle":"2025-04-15T16:43:37.912473Z","shell.execute_reply.started":"2025-04-15T16:43:37.849975Z","shell.execute_reply":"2025-04-15T16:43:37.911776Z"}},"outputs":[{"name":"stdout","text":"Validation Results:\n               precision    recall  f1-score   support\n\n         0.0     0.9623    0.8265    0.8892      1360\n         1.0     0.0484    0.2143    0.0789        56\n\n    accuracy                         0.8023      1416\n   macro avg     0.5054    0.5204    0.4841      1416\nweighted avg     0.9262    0.8023    0.8572      1416\n \nMacro F1: 0.4840939373750832\nTest Results:\n               precision    recall  f1-score   support\n\n         0.0     0.9182    0.8792    0.8983      2501\n         1.0     0.1272    0.1833    0.1502       240\n\n    accuracy                         0.8183      2741\n   macro avg     0.5227    0.5313    0.5242      2741\nweighted avg     0.8489    0.8183    0.8328      2741\n \nMacro F1: 0.5242274810948271\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Threshold tuning\nmetrics = tune_threshold(best_model, test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:43:52.014534Z","iopub.execute_input":"2025-04-15T16:43:52.014784Z","iopub.status.idle":"2025-04-15T16:43:52.507760Z","shell.execute_reply.started":"2025-04-15T16:43:52.014769Z","shell.execute_reply":"2025-04-15T16:43:52.506988Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# !zip -r file.zip /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:46:46.713339Z","iopub.execute_input":"2025-04-15T16:46:46.713906Z","iopub.status.idle":"2025-04-15T16:47:54.620625Z","shell.execute_reply.started":"2025-04-15T16:46:46.713889Z","shell.execute_reply":"2025-04-15T16:47:54.619924Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n  adding: kaggle/working/best_model.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/ (stored 0%)\n  adding: kaggle/working/checkpoints/model_epoch_130.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_340.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_350.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_410.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_50.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_200.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_190.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_500.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_180.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_430.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_420.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_470.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_300.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_100.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_170.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_310.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_440.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_480.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_90.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_250.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_330.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_280.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_380.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_150.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_10.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_210.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_320.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_360.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_20.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_450.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_240.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_60.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_120.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_220.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_290.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_390.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_110.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_370.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_140.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_270.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_30.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_70.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_40.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_400.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_460.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_80.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_230.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_490.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_160.pth (deflated 8%)\n  adding: kaggle/working/checkpoints/model_epoch_260.pth (deflated 8%)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}